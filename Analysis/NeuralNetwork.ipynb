{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4377, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('D:/Github/CVClassifier/X_points.csv', names=['x1', 'x2'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.654836</td>\n",
       "      <td>2.720399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.107258</td>\n",
       "      <td>2.724628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039140</td>\n",
       "      <td>3.152148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658564</td>\n",
       "      <td>1.222962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.236518</td>\n",
       "      <td>-0.738648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>3.308035</td>\n",
       "      <td>-1.339283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>3.418897</td>\n",
       "      <td>-2.380199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>2.267869</td>\n",
       "      <td>0.061415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>3.094274</td>\n",
       "      <td>-0.924682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>2.864549</td>\n",
       "      <td>-1.698894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4377 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2\n",
       "0    -0.654836  2.720399\n",
       "1     0.107258  2.724628\n",
       "2    -0.039140  3.152148\n",
       "3     0.658564  1.222962\n",
       "4    -1.236518 -0.738648\n",
       "...        ...       ...\n",
       "4372  3.308035 -1.339283\n",
       "4373  3.418897 -2.380199\n",
       "4374  2.267869  0.061415\n",
       "4375  3.094274 -0.924682\n",
       "4376  2.864549 -1.698894\n",
       "\n",
       "[4377 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4377 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0          Gerente\n",
       "1          Gerente\n",
       "2          Gerente\n",
       "3          Gerente\n",
       "4          Gerente\n",
       "...            ...\n",
       "4372  Especialista\n",
       "4373  Especialista\n",
       "4374  Especialista\n",
       "4375  Especialista\n",
       "4376  Especialista\n",
       "\n",
       "[4377 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv('D:/Github/CVClassifier/y_train.csv')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'Gerente': 0, 'Especialista': 1, 'Director': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4372    1\n",
       "4373    1\n",
       "4374    1\n",
       "4375    1\n",
       "4376    1\n",
       "Name: 0, Length: 4377, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train['0'].map(mapping)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('D:/Github/CVClassifier/X_points_test.csv', names=['x1', 'x2'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gerente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Especialista</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "0         Gerente\n",
       "1         Gerente\n",
       "2         Gerente\n",
       "3         Gerente\n",
       "4         Gerente\n",
       "..            ...\n",
       "241  Especialista\n",
       "242  Especialista\n",
       "243  Especialista\n",
       "244  Especialista\n",
       "245  Especialista\n",
       "\n",
       "[246 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv('D:/Github/CVClassifier/y_test_test.csv')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "241    1\n",
       "242    1\n",
       "243    1\n",
       "244    1\n",
       "245    1\n",
       "Name: label, Length: 246, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test['label'].map(mapping)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class ThresholdCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        X_val, y_val = self.validation_data\n",
    "        y_val_pred_prob = self.model.predict(X_val)\n",
    "        self.optimal_thresholds = self.find_optimal_thresholds(y_val, y_val_pred_prob)\n",
    "        print(f'Optimal thresholds: {self.optimal_thresholds}')\n",
    "\n",
    "    def find_optimal_thresholds(self, y_true, y_prob):\n",
    "        thresholds = {}\n",
    "        for i in range(y_prob.shape[1]):\n",
    "            precision, recall, thres = precision_recall_curve(y_true[:, i], y_prob[:, i])\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "            optimal_threshold = thres[np.argmax(f1_scores)]\n",
    "            thresholds[i] = optimal_threshold\n",
    "        return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.27986005, 1: 0.71200794, 2: 0.6267904}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{0: 0.27986005, 1: 0.71200794, 2: 0.6267904}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 0.27986005, 1: 0.71200794, 2: 0.6267904}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m771\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,035</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m396,035\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,035</span> (1.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m396,035\u001b[0m (1.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(512, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = to_categorical(y_test)\n",
    "y_train_encoded = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 24s - 5s/step - accuracy: 0.6093 - auc: 0.8294 - categorical_accuracy: 0.6093 - f1_score: 0.5310 - fn: 3072.0000 - fp: 45.0000 - loss: 0.4267 - precision: 0.9667 - recall: 0.2981 - tn: 8709.0000 - tp: 1305.0000 - val_accuracy: 0.5366 - val_auc: 0.7512 - val_categorical_accuracy: 0.5366 - val_f1_score: 0.5416 - val_fn: 170.0000 - val_fp: 51.0000 - val_loss: 0.9206 - val_precision: 0.5984 - val_recall: 0.3089 - val_tn: 441.0000 - val_tp: 76.0000\n",
      "Epoch 2/100\n",
      "5/5 - 1s - 116ms/step - accuracy: 0.8398 - auc: 0.9601 - categorical_accuracy: 0.8398 - f1_score: 0.8306 - fn: 1009.0000 - fp: 400.0000 - loss: 0.1329 - precision: 0.8938 - recall: 0.7695 - tn: 8354.0000 - tp: 3368.0000 - val_accuracy: 0.8293 - val_auc: 0.9177 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7749 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5683 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 3/100\n",
      "5/5 - 1s - 102ms/step - accuracy: 0.9237 - auc: 0.9845 - categorical_accuracy: 0.9237 - f1_score: 0.9239 - fn: 353.0000 - fp: 312.0000 - loss: 0.1040 - precision: 0.9280 - recall: 0.9194 - tn: 8442.0000 - tp: 4024.0000 - val_accuracy: 0.8211 - val_auc: 0.9100 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7712 - val_fn: 44.0000 - val_fp: 44.0000 - val_loss: 0.7185 - val_precision: 0.8211 - val_recall: 0.8211 - val_tn: 448.0000 - val_tp: 202.0000\n",
      "Epoch 4/100\n",
      "5/5 - 0s - 97ms/step - accuracy: 0.9194 - auc: 0.9786 - categorical_accuracy: 0.9194 - f1_score: 0.9186 - fn: 363.0000 - fp: 342.0000 - loss: 0.1038 - precision: 0.9215 - recall: 0.9171 - tn: 8412.0000 - tp: 4014.0000 - val_accuracy: 0.8252 - val_auc: 0.9233 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7673 - val_fn: 43.0000 - val_fp: 43.0000 - val_loss: 0.5659 - val_precision: 0.8252 - val_recall: 0.8252 - val_tn: 449.0000 - val_tp: 203.0000\n",
      "Epoch 5/100\n",
      "5/5 - 0s - 94ms/step - accuracy: 0.9257 - auc: 0.9861 - categorical_accuracy: 0.9257 - f1_score: 0.9256 - fn: 337.0000 - fp: 314.0000 - loss: 0.0928 - precision: 0.9279 - recall: 0.9230 - tn: 8440.0000 - tp: 4040.0000 - val_accuracy: 0.8171 - val_auc: 0.9177 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7672 - val_fn: 46.0000 - val_fp: 45.0000 - val_loss: 0.5794 - val_precision: 0.8163 - val_recall: 0.8130 - val_tn: 447.0000 - val_tp: 200.0000\n",
      "Epoch 6/100\n",
      "5/5 - 0s - 98ms/step - accuracy: 0.9173 - auc: 0.9827 - categorical_accuracy: 0.9173 - f1_score: 0.9164 - fn: 374.0000 - fp: 343.0000 - loss: 0.0905 - precision: 0.9211 - recall: 0.9146 - tn: 8411.0000 - tp: 4003.0000 - val_accuracy: 0.8130 - val_auc: 0.9265 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7628 - val_fn: 47.0000 - val_fp: 43.0000 - val_loss: 0.5280 - val_precision: 0.8223 - val_recall: 0.8089 - val_tn: 449.0000 - val_tp: 199.0000\n",
      "Epoch 7/100\n",
      "5/5 - 1s - 110ms/step - accuracy: 0.9223 - auc: 0.9857 - categorical_accuracy: 0.9223 - f1_score: 0.9218 - fn: 358.0000 - fp: 318.0000 - loss: 0.0883 - precision: 0.9267 - recall: 0.9182 - tn: 8436.0000 - tp: 4019.0000 - val_accuracy: 0.8089 - val_auc: 0.9258 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7618 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5292 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 8/100\n",
      "5/5 - 1s - 111ms/step - accuracy: 0.9216 - auc: 0.9849 - categorical_accuracy: 0.9216 - f1_score: 0.9208 - fn: 361.0000 - fp: 329.0000 - loss: 0.0869 - precision: 0.9243 - recall: 0.9175 - tn: 8425.0000 - tp: 4016.0000 - val_accuracy: 0.8049 - val_auc: 0.9259 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7581 - val_fn: 50.0000 - val_fp: 46.0000 - val_loss: 0.5337 - val_precision: 0.8099 - val_recall: 0.7967 - val_tn: 446.0000 - val_tp: 196.0000\n",
      "Epoch 9/100\n",
      "5/5 - 1s - 111ms/step - accuracy: 0.9219 - auc: 0.9852 - categorical_accuracy: 0.9219 - f1_score: 0.9210 - fn: 359.0000 - fp: 326.0000 - loss: 0.0867 - precision: 0.9250 - recall: 0.9180 - tn: 8428.0000 - tp: 4018.0000 - val_accuracy: 0.8130 - val_auc: 0.9338 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7647 - val_fn: 47.0000 - val_fp: 46.0000 - val_loss: 0.4944 - val_precision: 0.8122 - val_recall: 0.8089 - val_tn: 446.0000 - val_tp: 199.0000\n",
      "Epoch 10/100\n",
      "5/5 - 1s - 260ms/step - accuracy: 0.9205 - auc: 0.9851 - categorical_accuracy: 0.9205 - f1_score: 0.9197 - fn: 364.0000 - fp: 327.0000 - loss: 0.0880 - precision: 0.9247 - recall: 0.9168 - tn: 8427.0000 - tp: 4013.0000 - val_accuracy: 0.8171 - val_auc: 0.9321 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7673 - val_fn: 48.0000 - val_fp: 43.0000 - val_loss: 0.5076 - val_precision: 0.8216 - val_recall: 0.8049 - val_tn: 449.0000 - val_tp: 198.0000\n",
      "Epoch 11/100\n",
      "5/5 - 1s - 119ms/step - accuracy: 0.9225 - auc: 0.9851 - categorical_accuracy: 0.9225 - f1_score: 0.9218 - fn: 364.0000 - fp: 319.0000 - loss: 0.0875 - precision: 0.9264 - recall: 0.9168 - tn: 8435.0000 - tp: 4013.0000 - val_accuracy: 0.7886 - val_auc: 0.9201 - val_categorical_accuracy: 0.7886 - val_f1_score: 0.7451 - val_fn: 55.0000 - val_fp: 46.0000 - val_loss: 0.5586 - val_precision: 0.8059 - val_recall: 0.7764 - val_tn: 446.0000 - val_tp: 191.0000\n",
      "Epoch 12/100\n",
      "5/5 - 0s - 96ms/step - accuracy: 0.9180 - auc: 0.9842 - categorical_accuracy: 0.9180 - f1_score: 0.9168 - fn: 382.0000 - fp: 337.0000 - loss: 0.0862 - precision: 0.9222 - recall: 0.9127 - tn: 8417.0000 - tp: 3995.0000 - val_accuracy: 0.8293 - val_auc: 0.9346 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7769 - val_fn: 44.0000 - val_fp: 37.0000 - val_loss: 0.4876 - val_precision: 0.8452 - val_recall: 0.8211 - val_tn: 455.0000 - val_tp: 202.0000\n",
      "Epoch 13/100\n",
      "5/5 - 0s - 78ms/step - accuracy: 0.9264 - auc: 0.9861 - categorical_accuracy: 0.9264 - f1_score: 0.9258 - fn: 343.0000 - fp: 302.0000 - loss: 0.0879 - precision: 0.9304 - recall: 0.9216 - tn: 8452.0000 - tp: 4034.0000 - val_accuracy: 0.8008 - val_auc: 0.9203 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7575 - val_fn: 52.0000 - val_fp: 45.0000 - val_loss: 0.5539 - val_precision: 0.8117 - val_recall: 0.7886 - val_tn: 447.0000 - val_tp: 194.0000\n",
      "Epoch 14/100\n",
      "5/5 - 0s - 73ms/step - accuracy: 0.9207 - auc: 0.9846 - categorical_accuracy: 0.9207 - f1_score: 0.9198 - fn: 367.0000 - fp: 329.0000 - loss: 0.0863 - precision: 0.9242 - recall: 0.9162 - tn: 8425.0000 - tp: 4010.0000 - val_accuracy: 0.8130 - val_auc: 0.9312 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7601 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5131 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 15/100\n",
      "5/5 - 0s - 84ms/step - accuracy: 0.9244 - auc: 0.9853 - categorical_accuracy: 0.9244 - f1_score: 0.9237 - fn: 356.0000 - fp: 315.0000 - loss: 0.0859 - precision: 0.9274 - recall: 0.9187 - tn: 8439.0000 - tp: 4021.0000 - val_accuracy: 0.8008 - val_auc: 0.9282 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7515 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5224 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 16/100\n",
      "5/5 - 0s - 84ms/step - accuracy: 0.9239 - auc: 0.9857 - categorical_accuracy: 0.9239 - f1_score: 0.9233 - fn: 358.0000 - fp: 316.0000 - loss: 0.0856 - precision: 0.9271 - recall: 0.9182 - tn: 8438.0000 - tp: 4019.0000 - val_accuracy: 0.8089 - val_auc: 0.9309 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7588 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5120 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 17/100\n",
      "5/5 - 0s - 87ms/step - accuracy: 0.9253 - auc: 0.9861 - categorical_accuracy: 0.9253 - f1_score: 0.9245 - fn: 354.0000 - fp: 315.0000 - loss: 0.0845 - precision: 0.9274 - recall: 0.9191 - tn: 8439.0000 - tp: 4023.0000 - val_accuracy: 0.8008 - val_auc: 0.9280 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7554 - val_fn: 50.0000 - val_fp: 45.0000 - val_loss: 0.5243 - val_precision: 0.8133 - val_recall: 0.7967 - val_tn: 447.0000 - val_tp: 196.0000\n",
      "Epoch 18/100\n",
      "5/5 - 0s - 85ms/step - accuracy: 0.9207 - auc: 0.9857 - categorical_accuracy: 0.9207 - f1_score: 0.9198 - fn: 359.0000 - fp: 331.0000 - loss: 0.0845 - precision: 0.9239 - recall: 0.9180 - tn: 8423.0000 - tp: 4018.0000 - val_accuracy: 0.8089 - val_auc: 0.9315 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7563 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5119 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 19/100\n",
      "5/5 - 0s - 80ms/step - accuracy: 0.9221 - auc: 0.9867 - categorical_accuracy: 0.9221 - f1_score: 0.9214 - fn: 353.0000 - fp: 318.0000 - loss: 0.0840 - precision: 0.9268 - recall: 0.9194 - tn: 8436.0000 - tp: 4024.0000 - val_accuracy: 0.8008 - val_auc: 0.9219 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7584 - val_fn: 52.0000 - val_fp: 49.0000 - val_loss: 0.5560 - val_precision: 0.7984 - val_recall: 0.7886 - val_tn: 443.0000 - val_tp: 194.0000\n",
      "Epoch 20/100\n",
      "5/5 - 0s - 66ms/step - accuracy: 0.9166 - auc: 0.9843 - categorical_accuracy: 0.9166 - f1_score: 0.9153 - fn: 381.0000 - fp: 355.0000 - loss: 0.0857 - precision: 0.9184 - recall: 0.9130 - tn: 8399.0000 - tp: 3996.0000 - val_accuracy: 0.8252 - val_auc: 0.9335 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7691 - val_fn: 43.0000 - val_fp: 41.0000 - val_loss: 0.4985 - val_precision: 0.8320 - val_recall: 0.8252 - val_tn: 451.0000 - val_tp: 203.0000\n",
      "Epoch 21/100\n",
      "5/5 - 1s - 138ms/step - accuracy: 0.9264 - auc: 0.9868 - categorical_accuracy: 0.9264 - f1_score: 0.9259 - fn: 341.0000 - fp: 311.0000 - loss: 0.0855 - precision: 0.9285 - recall: 0.9221 - tn: 8443.0000 - tp: 4036.0000 - val_accuracy: 0.8008 - val_auc: 0.9220 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7584 - val_fn: 52.0000 - val_fp: 47.0000 - val_loss: 0.5503 - val_precision: 0.8050 - val_recall: 0.7886 - val_tn: 445.0000 - val_tp: 194.0000\n",
      "Epoch 22/100\n",
      "5/5 - 0s - 85ms/step - accuracy: 0.9178 - auc: 0.9846 - categorical_accuracy: 0.9178 - f1_score: 0.9166 - fn: 374.0000 - fp: 346.0000 - loss: 0.0853 - precision: 0.9204 - recall: 0.9146 - tn: 8408.0000 - tp: 4003.0000 - val_accuracy: 0.8293 - val_auc: 0.9323 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7777 - val_fn: 44.0000 - val_fp: 40.0000 - val_loss: 0.5061 - val_precision: 0.8347 - val_recall: 0.8211 - val_tn: 452.0000 - val_tp: 202.0000\n",
      "Epoch 23/100\n",
      "5/5 - 0s - 84ms/step - accuracy: 0.9255 - auc: 0.9857 - categorical_accuracy: 0.9255 - f1_score: 0.9249 - fn: 343.0000 - fp: 309.0000 - loss: 0.0859 - precision: 0.9289 - recall: 0.9216 - tn: 8445.0000 - tp: 4034.0000 - val_accuracy: 0.8171 - val_auc: 0.9305 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7673 - val_fn: 48.0000 - val_fp: 42.0000 - val_loss: 0.5189 - val_precision: 0.8250 - val_recall: 0.8049 - val_tn: 450.0000 - val_tp: 198.0000\n",
      "Epoch 24/100\n",
      "5/5 - 0s - 82ms/step - accuracy: 0.9212 - auc: 0.9860 - categorical_accuracy: 0.9212 - f1_score: 0.9204 - fn: 354.0000 - fp: 334.0000 - loss: 0.0844 - precision: 0.9233 - recall: 0.9191 - tn: 8420.0000 - tp: 4023.0000 - val_accuracy: 0.8171 - val_auc: 0.9323 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7673 - val_fn: 47.0000 - val_fp: 44.0000 - val_loss: 0.5125 - val_precision: 0.8189 - val_recall: 0.8089 - val_tn: 448.0000 - val_tp: 199.0000\n",
      "Epoch 25/100\n",
      "5/5 - 0s - 75ms/step - accuracy: 0.9244 - auc: 0.9864 - categorical_accuracy: 0.9244 - f1_score: 0.9236 - fn: 343.0000 - fp: 316.0000 - loss: 0.0841 - precision: 0.9274 - recall: 0.9216 - tn: 8438.0000 - tp: 4034.0000 - val_accuracy: 0.8130 - val_auc: 0.9320 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7621 - val_fn: 47.0000 - val_fp: 42.0000 - val_loss: 0.5147 - val_precision: 0.8257 - val_recall: 0.8089 - val_tn: 450.0000 - val_tp: 199.0000\n",
      "Epoch 26/100\n",
      "5/5 - 0s - 76ms/step - accuracy: 0.9255 - auc: 0.9867 - categorical_accuracy: 0.9255 - f1_score: 0.9248 - fn: 336.0000 - fp: 313.0000 - loss: 0.0839 - precision: 0.9281 - recall: 0.9232 - tn: 8441.0000 - tp: 4041.0000 - val_accuracy: 0.8089 - val_auc: 0.9289 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7639 - val_fn: 50.0000 - val_fp: 45.0000 - val_loss: 0.5188 - val_precision: 0.8133 - val_recall: 0.7967 - val_tn: 447.0000 - val_tp: 196.0000\n",
      "Epoch 27/100\n",
      "5/5 - 0s - 78ms/step - accuracy: 0.9214 - auc: 0.9859 - categorical_accuracy: 0.9214 - f1_score: 0.9204 - fn: 362.0000 - fp: 332.0000 - loss: 0.0834 - precision: 0.9236 - recall: 0.9173 - tn: 8422.0000 - tp: 4015.0000 - val_accuracy: 0.8211 - val_auc: 0.9295 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7763 - val_fn: 49.0000 - val_fp: 42.0000 - val_loss: 0.5203 - val_precision: 0.8243 - val_recall: 0.8008 - val_tn: 450.0000 - val_tp: 197.0000\n",
      "Epoch 28/100\n",
      "5/5 - 0s - 80ms/step - accuracy: 0.9219 - auc: 0.9855 - categorical_accuracy: 0.9219 - f1_score: 0.9209 - fn: 353.0000 - fp: 325.0000 - loss: 0.0838 - precision: 0.9253 - recall: 0.9194 - tn: 8429.0000 - tp: 4024.0000 - val_accuracy: 0.8252 - val_auc: 0.9304 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7799 - val_fn: 49.0000 - val_fp: 43.0000 - val_loss: 0.5148 - val_precision: 0.8208 - val_recall: 0.8008 - val_tn: 449.0000 - val_tp: 197.0000\n",
      "Epoch 29/100\n",
      "5/5 - 0s - 70ms/step - accuracy: 0.9232 - auc: 0.9864 - categorical_accuracy: 0.9232 - f1_score: 0.9225 - fn: 348.0000 - fp: 320.0000 - loss: 0.0838 - precision: 0.9264 - recall: 0.9205 - tn: 8434.0000 - tp: 4029.0000 - val_accuracy: 0.8089 - val_auc: 0.9283 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7569 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5260 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 30/100\n",
      "5/5 - 0s - 66ms/step - accuracy: 0.9237 - auc: 0.9855 - categorical_accuracy: 0.9237 - f1_score: 0.9230 - fn: 347.0000 - fp: 315.0000 - loss: 0.0839 - precision: 0.9275 - recall: 0.9207 - tn: 8439.0000 - tp: 4030.0000 - val_accuracy: 0.8171 - val_auc: 0.9293 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7688 - val_fn: 48.0000 - val_fp: 42.0000 - val_loss: 0.5240 - val_precision: 0.8250 - val_recall: 0.8049 - val_tn: 450.0000 - val_tp: 198.0000\n",
      "Epoch 31/100\n",
      "5/5 - 0s - 69ms/step - accuracy: 0.9225 - auc: 0.9858 - categorical_accuracy: 0.9225 - f1_score: 0.9217 - fn: 353.0000 - fp: 325.0000 - loss: 0.0828 - precision: 0.9253 - recall: 0.9194 - tn: 8429.0000 - tp: 4024.0000 - val_accuracy: 0.8252 - val_auc: 0.9334 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7775 - val_fn: 48.0000 - val_fp: 42.0000 - val_loss: 0.4980 - val_precision: 0.8250 - val_recall: 0.8049 - val_tn: 450.0000 - val_tp: 198.0000\n",
      "Epoch 32/100\n",
      "5/5 - 0s - 68ms/step - accuracy: 0.9225 - auc: 0.9870 - categorical_accuracy: 0.9225 - f1_score: 0.9218 - fn: 350.0000 - fp: 325.0000 - loss: 0.0849 - precision: 0.9253 - recall: 0.9200 - tn: 8429.0000 - tp: 4027.0000 - val_accuracy: 0.8171 - val_auc: 0.9292 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7688 - val_fn: 47.0000 - val_fp: 42.0000 - val_loss: 0.5247 - val_precision: 0.8257 - val_recall: 0.8089 - val_tn: 450.0000 - val_tp: 199.0000\n",
      "Epoch 33/100\n",
      "5/5 - 1s - 117ms/step - accuracy: 0.9219 - auc: 0.9863 - categorical_accuracy: 0.9219 - f1_score: 0.9210 - fn: 357.0000 - fp: 327.0000 - loss: 0.0829 - precision: 0.9248 - recall: 0.9184 - tn: 8427.0000 - tp: 4020.0000 - val_accuracy: 0.8211 - val_auc: 0.9336 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7692 - val_fn: 47.0000 - val_fp: 43.0000 - val_loss: 0.4993 - val_precision: 0.8223 - val_recall: 0.8089 - val_tn: 449.0000 - val_tp: 199.0000\n",
      "Epoch 34/100\n",
      "5/5 - 0s - 67ms/step - accuracy: 0.9264 - auc: 0.9867 - categorical_accuracy: 0.9264 - f1_score: 0.9259 - fn: 338.0000 - fp: 308.0000 - loss: 0.0836 - precision: 0.9291 - recall: 0.9228 - tn: 8446.0000 - tp: 4039.0000 - val_accuracy: 0.8130 - val_auc: 0.9269 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7696 - val_fn: 52.0000 - val_fp: 44.0000 - val_loss: 0.5332 - val_precision: 0.8151 - val_recall: 0.7886 - val_tn: 448.0000 - val_tp: 194.0000\n",
      "Epoch 35/100\n",
      "5/5 - 0s - 64ms/step - accuracy: 0.9196 - auc: 0.9854 - categorical_accuracy: 0.9196 - f1_score: 0.9185 - fn: 367.0000 - fp: 339.0000 - loss: 0.0830 - precision: 0.9221 - recall: 0.9162 - tn: 8415.0000 - tp: 4010.0000 - val_accuracy: 0.8211 - val_auc: 0.9316 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7706 - val_fn: 47.0000 - val_fp: 42.0000 - val_loss: 0.5104 - val_precision: 0.8257 - val_recall: 0.8089 - val_tn: 450.0000 - val_tp: 199.0000\n",
      "Epoch 36/100\n",
      "5/5 - 1s - 115ms/step - accuracy: 0.9248 - auc: 0.9863 - categorical_accuracy: 0.9248 - f1_score: 0.9241 - fn: 340.0000 - fp: 317.0000 - loss: 0.0841 - precision: 0.9272 - recall: 0.9223 - tn: 8437.0000 - tp: 4037.0000 - val_accuracy: 0.8130 - val_auc: 0.9290 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7659 - val_fn: 49.0000 - val_fp: 43.0000 - val_loss: 0.5245 - val_precision: 0.8208 - val_recall: 0.8008 - val_tn: 449.0000 - val_tp: 197.0000\n",
      "Epoch 37/100\n",
      "5/5 - 0s - 61ms/step - accuracy: 0.9180 - auc: 0.9853 - categorical_accuracy: 0.9180 - f1_score: 0.9168 - fn: 377.0000 - fp: 346.0000 - loss: 0.0839 - precision: 0.9204 - recall: 0.9139 - tn: 8408.0000 - tp: 4000.0000 - val_accuracy: 0.8211 - val_auc: 0.9351 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7706 - val_fn: 47.0000 - val_fp: 41.0000 - val_loss: 0.4925 - val_precision: 0.8292 - val_recall: 0.8089 - val_tn: 451.0000 - val_tp: 199.0000\n",
      "Epoch 38/100\n",
      "5/5 - 0s - 60ms/step - accuracy: 0.9230 - auc: 0.9868 - categorical_accuracy: 0.9230 - f1_score: 0.9222 - fn: 354.0000 - fp: 321.0000 - loss: 0.0843 - precision: 0.9261 - recall: 0.9191 - tn: 8433.0000 - tp: 4023.0000 - val_accuracy: 0.8049 - val_auc: 0.9265 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7611 - val_fn: 53.0000 - val_fp: 48.0000 - val_loss: 0.5361 - val_precision: 0.8008 - val_recall: 0.7846 - val_tn: 444.0000 - val_tp: 193.0000\n",
      "Epoch 39/100\n",
      "5/5 - 0s - 71ms/step - accuracy: 0.9214 - auc: 0.9851 - categorical_accuracy: 0.9214 - f1_score: 0.9203 - fn: 363.0000 - fp: 330.0000 - loss: 0.0838 - precision: 0.9240 - recall: 0.9171 - tn: 8424.0000 - tp: 4014.0000 - val_accuracy: 0.8130 - val_auc: 0.9350 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7633 - val_fn: 49.0000 - val_fp: 42.0000 - val_loss: 0.4922 - val_precision: 0.8243 - val_recall: 0.8008 - val_tn: 450.0000 - val_tp: 197.0000\n",
      "Epoch 40/100\n",
      "5/5 - 0s - 66ms/step - accuracy: 0.9241 - auc: 0.9872 - categorical_accuracy: 0.9241 - f1_score: 0.9235 - fn: 344.0000 - fp: 312.0000 - loss: 0.0832 - precision: 0.9282 - recall: 0.9214 - tn: 8442.0000 - tp: 4033.0000 - val_accuracy: 0.8171 - val_auc: 0.9285 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7683 - val_fn: 50.0000 - val_fp: 44.0000 - val_loss: 0.5257 - val_precision: 0.8167 - val_recall: 0.7967 - val_tn: 448.0000 - val_tp: 196.0000\n",
      "Epoch 41/100\n",
      "5/5 - 0s - 67ms/step - accuracy: 0.9232 - auc: 0.9859 - categorical_accuracy: 0.9232 - f1_score: 0.9224 - fn: 349.0000 - fp: 318.0000 - loss: 0.0842 - precision: 0.9268 - recall: 0.9203 - tn: 8436.0000 - tp: 4028.0000 - val_accuracy: 0.8171 - val_auc: 0.9270 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7697 - val_fn: 48.0000 - val_fp: 43.0000 - val_loss: 0.5243 - val_precision: 0.8216 - val_recall: 0.8049 - val_tn: 449.0000 - val_tp: 198.0000\n",
      "Epoch 42/100\n",
      "5/5 - 0s - 67ms/step - accuracy: 0.9235 - auc: 0.9860 - categorical_accuracy: 0.9235 - f1_score: 0.9226 - fn: 353.0000 - fp: 327.0000 - loss: 0.0831 - precision: 0.9248 - recall: 0.9194 - tn: 8427.0000 - tp: 4024.0000 - val_accuracy: 0.8089 - val_auc: 0.9312 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7611 - val_fn: 49.0000 - val_fp: 43.0000 - val_loss: 0.5058 - val_precision: 0.8208 - val_recall: 0.8008 - val_tn: 449.0000 - val_tp: 197.0000\n",
      "Epoch 43/100\n",
      "5/5 - 0s - 68ms/step - accuracy: 0.9230 - auc: 0.9865 - categorical_accuracy: 0.9230 - f1_score: 0.9222 - fn: 353.0000 - fp: 323.0000 - loss: 0.0829 - precision: 0.9257 - recall: 0.9194 - tn: 8431.0000 - tp: 4024.0000 - val_accuracy: 0.8008 - val_auc: 0.9308 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7525 - val_fn: 50.0000 - val_fp: 45.0000 - val_loss: 0.5122 - val_precision: 0.8133 - val_recall: 0.7967 - val_tn: 447.0000 - val_tp: 196.0000\n",
      "Epoch 44/100\n",
      "5/5 - 0s - 69ms/step - accuracy: 0.9225 - auc: 0.9858 - categorical_accuracy: 0.9225 - f1_score: 0.9217 - fn: 353.0000 - fp: 329.0000 - loss: 0.0836 - precision: 0.9244 - recall: 0.9194 - tn: 8425.0000 - tp: 4024.0000 - val_accuracy: 0.8089 - val_auc: 0.9321 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7609 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5072 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 45/100\n",
      "5/5 - 0s - 69ms/step - accuracy: 0.9214 - auc: 0.9857 - categorical_accuracy: 0.9214 - f1_score: 0.9206 - fn: 360.0000 - fp: 330.0000 - loss: 0.0840 - precision: 0.9241 - recall: 0.9178 - tn: 8424.0000 - tp: 4017.0000 - val_accuracy: 0.8252 - val_auc: 0.9340 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7763 - val_fn: 47.0000 - val_fp: 43.0000 - val_loss: 0.4967 - val_precision: 0.8223 - val_recall: 0.8089 - val_tn: 449.0000 - val_tp: 199.0000\n",
      "Epoch 46/100\n",
      "5/5 - 0s - 78ms/step - accuracy: 0.9273 - auc: 0.9871 - categorical_accuracy: 0.9273 - f1_score: 0.9267 - fn: 332.0000 - fp: 306.0000 - loss: 0.0826 - precision: 0.9297 - recall: 0.9241 - tn: 8448.0000 - tp: 4045.0000 - val_accuracy: 0.8089 - val_auc: 0.9277 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7636 - val_fn: 52.0000 - val_fp: 46.0000 - val_loss: 0.5188 - val_precision: 0.8083 - val_recall: 0.7886 - val_tn: 446.0000 - val_tp: 194.0000\n",
      "Epoch 47/100\n",
      "5/5 - 1s - 110ms/step - accuracy: 0.9191 - auc: 0.9859 - categorical_accuracy: 0.9191 - f1_score: 0.9181 - fn: 364.0000 - fp: 341.0000 - loss: 0.0839 - precision: 0.9217 - recall: 0.9168 - tn: 8413.0000 - tp: 4013.0000 - val_accuracy: 0.8252 - val_auc: 0.9308 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7739 - val_fn: 46.0000 - val_fp: 40.0000 - val_loss: 0.5074 - val_precision: 0.8333 - val_recall: 0.8130 - val_tn: 452.0000 - val_tp: 200.0000\n",
      "Epoch 48/100\n",
      "5/5 - 0s - 87ms/step - accuracy: 0.9255 - auc: 0.9865 - categorical_accuracy: 0.9255 - f1_score: 0.9249 - fn: 340.0000 - fp: 312.0000 - loss: 0.0837 - precision: 0.9283 - recall: 0.9223 - tn: 8442.0000 - tp: 4037.0000 - val_accuracy: 0.8089 - val_auc: 0.9247 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7618 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5489 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 49/100\n",
      "5/5 - 0s - 90ms/step - accuracy: 0.9216 - auc: 0.9853 - categorical_accuracy: 0.9216 - f1_score: 0.9207 - fn: 359.0000 - fp: 329.0000 - loss: 0.0829 - precision: 0.9243 - recall: 0.9180 - tn: 8425.0000 - tp: 4018.0000 - val_accuracy: 0.8171 - val_auc: 0.9304 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7648 - val_fn: 47.0000 - val_fp: 43.0000 - val_loss: 0.5103 - val_precision: 0.8223 - val_recall: 0.8089 - val_tn: 449.0000 - val_tp: 199.0000\n",
      "Epoch 50/100\n",
      "5/5 - 0s - 78ms/step - accuracy: 0.9283 - auc: 0.9874 - categorical_accuracy: 0.9283 - f1_score: 0.9277 - fn: 330.0000 - fp: 298.0000 - loss: 0.0823 - precision: 0.9314 - recall: 0.9246 - tn: 8456.0000 - tp: 4047.0000 - val_accuracy: 0.8171 - val_auc: 0.9297 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7708 - val_fn: 49.0000 - val_fp: 43.0000 - val_loss: 0.5174 - val_precision: 0.8208 - val_recall: 0.8008 - val_tn: 449.0000 - val_tp: 197.0000\n",
      "Epoch 51/100\n",
      "5/5 - 0s - 73ms/step - accuracy: 0.9219 - auc: 0.9851 - categorical_accuracy: 0.9219 - f1_score: 0.9209 - fn: 351.0000 - fp: 328.0000 - loss: 0.0832 - precision: 0.9247 - recall: 0.9198 - tn: 8426.0000 - tp: 4026.0000 - val_accuracy: 0.8171 - val_auc: 0.9337 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7655 - val_fn: 47.0000 - val_fp: 44.0000 - val_loss: 0.5019 - val_precision: 0.8189 - val_recall: 0.8089 - val_tn: 448.0000 - val_tp: 199.0000\n",
      "Epoch 52/100\n",
      "5/5 - 1s - 105ms/step - accuracy: 0.9278 - auc: 0.9879 - categorical_accuracy: 0.9278 - f1_score: 0.9275 - fn: 329.0000 - fp: 303.0000 - loss: 0.0835 - precision: 0.9304 - recall: 0.9248 - tn: 8451.0000 - tp: 4048.0000 - val_accuracy: 0.8211 - val_auc: 0.9298 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7717 - val_fn: 46.0000 - val_fp: 43.0000 - val_loss: 0.5158 - val_precision: 0.8230 - val_recall: 0.8130 - val_tn: 449.0000 - val_tp: 200.0000\n",
      "Epoch 53/100\n",
      "5/5 - 0s - 86ms/step - accuracy: 0.9221 - auc: 0.9862 - categorical_accuracy: 0.9221 - f1_score: 0.9212 - fn: 354.0000 - fp: 326.0000 - loss: 0.0822 - precision: 0.9250 - recall: 0.9191 - tn: 8428.0000 - tp: 4023.0000 - val_accuracy: 0.8211 - val_auc: 0.9293 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7720 - val_fn: 48.0000 - val_fp: 43.0000 - val_loss: 0.5177 - val_precision: 0.8216 - val_recall: 0.8049 - val_tn: 449.0000 - val_tp: 198.0000\n",
      "Epoch 54/100\n",
      "5/5 - 0s - 77ms/step - accuracy: 0.9267 - auc: 0.9863 - categorical_accuracy: 0.9267 - f1_score: 0.9260 - fn: 340.0000 - fp: 310.0000 - loss: 0.0822 - precision: 0.9287 - recall: 0.9223 - tn: 8444.0000 - tp: 4037.0000 - val_accuracy: 0.8252 - val_auc: 0.9317 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7763 - val_fn: 48.0000 - val_fp: 43.0000 - val_loss: 0.5002 - val_precision: 0.8216 - val_recall: 0.8049 - val_tn: 449.0000 - val_tp: 198.0000\n",
      "Epoch 55/100\n",
      "5/5 - 0s - 78ms/step - accuracy: 0.9271 - auc: 0.9873 - categorical_accuracy: 0.9271 - f1_score: 0.9266 - fn: 335.0000 - fp: 311.0000 - loss: 0.0834 - precision: 0.9286 - recall: 0.9235 - tn: 8443.0000 - tp: 4042.0000 - val_accuracy: 0.8171 - val_auc: 0.9288 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7683 - val_fn: 49.0000 - val_fp: 44.0000 - val_loss: 0.5252 - val_precision: 0.8174 - val_recall: 0.8008 - val_tn: 448.0000 - val_tp: 197.0000\n",
      "Epoch 56/100\n",
      "5/5 - 0s - 72ms/step - accuracy: 0.9257 - auc: 0.9864 - categorical_accuracy: 0.9257 - f1_score: 0.9251 - fn: 338.0000 - fp: 316.0000 - loss: 0.0839 - precision: 0.9274 - recall: 0.9228 - tn: 8438.0000 - tp: 4039.0000 - val_accuracy: 0.8171 - val_auc: 0.9276 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7673 - val_fn: 47.0000 - val_fp: 44.0000 - val_loss: 0.5367 - val_precision: 0.8189 - val_recall: 0.8089 - val_tn: 448.0000 - val_tp: 199.0000\n",
      "Epoch 57/100\n",
      "5/5 - 0s - 69ms/step - accuracy: 0.9230 - auc: 0.9864 - categorical_accuracy: 0.9230 - f1_score: 0.9222 - fn: 349.0000 - fp: 327.0000 - loss: 0.0822 - precision: 0.9249 - recall: 0.9203 - tn: 8427.0000 - tp: 4028.0000 - val_accuracy: 0.8211 - val_auc: 0.9305 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7717 - val_fn: 46.0000 - val_fp: 44.0000 - val_loss: 0.5134 - val_precision: 0.8197 - val_recall: 0.8130 - val_tn: 448.0000 - val_tp: 200.0000\n",
      "Epoch 58/100\n",
      "5/5 - 0s - 74ms/step - accuracy: 0.9285 - auc: 0.9880 - categorical_accuracy: 0.9285 - f1_score: 0.9281 - fn: 321.0000 - fp: 307.0000 - loss: 0.0822 - precision: 0.9296 - recall: 0.9267 - tn: 8447.0000 - tp: 4056.0000 - val_accuracy: 0.8171 - val_auc: 0.9283 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7702 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5256 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 59/100\n",
      "5/5 - 0s - 72ms/step - accuracy: 0.9225 - auc: 0.9851 - categorical_accuracy: 0.9225 - f1_score: 0.9217 - fn: 352.0000 - fp: 328.0000 - loss: 0.0827 - precision: 0.9246 - recall: 0.9196 - tn: 8426.0000 - tp: 4025.0000 - val_accuracy: 0.8171 - val_auc: 0.9293 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7683 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5173 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 60/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9283 - auc: 0.9874 - categorical_accuracy: 0.9283 - f1_score: 0.9278 - fn: 321.0000 - fp: 306.0000 - loss: 0.0824 - precision: 0.9298 - recall: 0.9267 - tn: 8448.0000 - tp: 4056.0000 - val_accuracy: 0.8211 - val_auc: 0.9286 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7752 - val_fn: 49.0000 - val_fp: 43.0000 - val_loss: 0.5262 - val_precision: 0.8208 - val_recall: 0.8008 - val_tn: 449.0000 - val_tp: 197.0000\n",
      "Epoch 61/100\n",
      "5/5 - 0s - 75ms/step - accuracy: 0.9203 - auc: 0.9851 - categorical_accuracy: 0.9203 - f1_score: 0.9192 - fn: 359.0000 - fp: 343.0000 - loss: 0.0833 - precision: 0.9213 - recall: 0.9180 - tn: 8411.0000 - tp: 4018.0000 - val_accuracy: 0.8171 - val_auc: 0.9276 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7695 - val_fn: 48.0000 - val_fp: 43.0000 - val_loss: 0.5296 - val_precision: 0.8216 - val_recall: 0.8049 - val_tn: 449.0000 - val_tp: 198.0000\n",
      "Epoch 62/100\n",
      "5/5 - 0s - 100ms/step - accuracy: 0.9260 - auc: 0.9873 - categorical_accuracy: 0.9260 - f1_score: 0.9254 - fn: 330.0000 - fp: 310.0000 - loss: 0.0820 - precision: 0.9289 - recall: 0.9246 - tn: 8444.0000 - tp: 4047.0000 - val_accuracy: 0.8171 - val_auc: 0.9324 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7683 - val_fn: 50.0000 - val_fp: 44.0000 - val_loss: 0.5007 - val_precision: 0.8167 - val_recall: 0.7967 - val_tn: 448.0000 - val_tp: 196.0000\n",
      "Epoch 63/100\n",
      "5/5 - 0s - 86ms/step - accuracy: 0.9248 - auc: 0.9865 - categorical_accuracy: 0.9248 - f1_score: 0.9241 - fn: 342.0000 - fp: 315.0000 - loss: 0.0811 - precision: 0.9276 - recall: 0.9219 - tn: 8439.0000 - tp: 4035.0000 - val_accuracy: 0.8130 - val_auc: 0.9279 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7672 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5253 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 64/100\n",
      "5/5 - 0s - 81ms/step - accuracy: 0.9280 - auc: 0.9865 - categorical_accuracy: 0.9280 - f1_score: 0.9274 - fn: 324.0000 - fp: 308.0000 - loss: 0.0816 - precision: 0.9294 - recall: 0.9260 - tn: 8446.0000 - tp: 4053.0000 - val_accuracy: 0.8130 - val_auc: 0.9337 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7596 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.4955 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 65/100\n",
      "5/5 - 1s - 113ms/step - accuracy: 0.9271 - auc: 0.9872 - categorical_accuracy: 0.9271 - f1_score: 0.9266 - fn: 330.0000 - fp: 311.0000 - loss: 0.0819 - precision: 0.9286 - recall: 0.9246 - tn: 8443.0000 - tp: 4047.0000 - val_accuracy: 0.8008 - val_auc: 0.9232 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7569 - val_fn: 51.0000 - val_fp: 48.0000 - val_loss: 0.5514 - val_precision: 0.8025 - val_recall: 0.7927 - val_tn: 444.0000 - val_tp: 195.0000\n",
      "Epoch 66/100\n",
      "5/5 - 0s - 96ms/step - accuracy: 0.9221 - auc: 0.9854 - categorical_accuracy: 0.9221 - f1_score: 0.9211 - fn: 355.0000 - fp: 334.0000 - loss: 0.0825 - precision: 0.9233 - recall: 0.9189 - tn: 8420.0000 - tp: 4022.0000 - val_accuracy: 0.8211 - val_auc: 0.9317 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7720 - val_fn: 46.0000 - val_fp: 43.0000 - val_loss: 0.5035 - val_precision: 0.8230 - val_recall: 0.8130 - val_tn: 449.0000 - val_tp: 200.0000\n",
      "Epoch 67/100\n",
      "5/5 - 0s - 84ms/step - accuracy: 0.9308 - auc: 0.9881 - categorical_accuracy: 0.9308 - f1_score: 0.9305 - fn: 311.0000 - fp: 297.0000 - loss: 0.0830 - precision: 0.9319 - recall: 0.9289 - tn: 8457.0000 - tp: 4066.0000 - val_accuracy: 0.8252 - val_auc: 0.9297 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7775 - val_fn: 47.0000 - val_fp: 42.0000 - val_loss: 0.5118 - val_precision: 0.8257 - val_recall: 0.8089 - val_tn: 450.0000 - val_tp: 199.0000\n",
      "Epoch 68/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9260 - auc: 0.9873 - categorical_accuracy: 0.9260 - f1_score: 0.9254 - fn: 333.0000 - fp: 317.0000 - loss: 0.0811 - precision: 0.9273 - recall: 0.9239 - tn: 8437.0000 - tp: 4044.0000 - val_accuracy: 0.8008 - val_auc: 0.9281 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7545 - val_fn: 51.0000 - val_fp: 45.0000 - val_loss: 0.5299 - val_precision: 0.8125 - val_recall: 0.7927 - val_tn: 447.0000 - val_tp: 195.0000\n",
      "Epoch 69/100\n",
      "5/5 - 0s - 78ms/step - accuracy: 0.9219 - auc: 0.9860 - categorical_accuracy: 0.9219 - f1_score: 0.9209 - fn: 346.0000 - fp: 328.0000 - loss: 0.0817 - precision: 0.9248 - recall: 0.9210 - tn: 8426.0000 - tp: 4031.0000 - val_accuracy: 0.8008 - val_auc: 0.9316 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7520 - val_fn: 51.0000 - val_fp: 46.0000 - val_loss: 0.5002 - val_precision: 0.8091 - val_recall: 0.7927 - val_tn: 446.0000 - val_tp: 195.0000\n",
      "Epoch 70/100\n",
      "5/5 - 0s - 72ms/step - accuracy: 0.9271 - auc: 0.9876 - categorical_accuracy: 0.9271 - f1_score: 0.9264 - fn: 326.0000 - fp: 307.0000 - loss: 0.0820 - precision: 0.9296 - recall: 0.9255 - tn: 8447.0000 - tp: 4051.0000 - val_accuracy: 0.7967 - val_auc: 0.9253 - val_categorical_accuracy: 0.7967 - val_f1_score: 0.7540 - val_fn: 52.0000 - val_fp: 47.0000 - val_loss: 0.5323 - val_precision: 0.8050 - val_recall: 0.7886 - val_tn: 445.0000 - val_tp: 194.0000\n",
      "Epoch 71/100\n",
      "5/5 - 0s - 70ms/step - accuracy: 0.9225 - auc: 0.9858 - categorical_accuracy: 0.9225 - f1_score: 0.9217 - fn: 347.0000 - fp: 324.0000 - loss: 0.0812 - precision: 0.9256 - recall: 0.9207 - tn: 8430.0000 - tp: 4030.0000 - val_accuracy: 0.8171 - val_auc: 0.9308 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7669 - val_fn: 46.0000 - val_fp: 43.0000 - val_loss: 0.5185 - val_precision: 0.8230 - val_recall: 0.8130 - val_tn: 449.0000 - val_tp: 200.0000\n",
      "Epoch 72/100\n",
      "5/5 - 0s - 67ms/step - accuracy: 0.9285 - auc: 0.9869 - categorical_accuracy: 0.9285 - f1_score: 0.9280 - fn: 324.0000 - fp: 307.0000 - loss: 0.0817 - precision: 0.9296 - recall: 0.9260 - tn: 8447.0000 - tp: 4053.0000 - val_accuracy: 0.8171 - val_auc: 0.9296 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7669 - val_fn: 46.0000 - val_fp: 44.0000 - val_loss: 0.5174 - val_precision: 0.8197 - val_recall: 0.8130 - val_tn: 448.0000 - val_tp: 200.0000\n",
      "Epoch 73/100\n",
      "5/5 - 0s - 70ms/step - accuracy: 0.9287 - auc: 0.9875 - categorical_accuracy: 0.9287 - f1_score: 0.9283 - fn: 315.0000 - fp: 305.0000 - loss: 0.0822 - precision: 0.9302 - recall: 0.9280 - tn: 8449.0000 - tp: 4062.0000 - val_accuracy: 0.8089 - val_auc: 0.9259 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7629 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5310 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 74/100\n",
      "5/5 - 0s - 64ms/step - accuracy: 0.9251 - auc: 0.9860 - categorical_accuracy: 0.9251 - f1_score: 0.9242 - fn: 343.0000 - fp: 325.0000 - loss: 0.0813 - precision: 0.9254 - recall: 0.9216 - tn: 8429.0000 - tp: 4034.0000 - val_accuracy: 0.8171 - val_auc: 0.9291 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7677 - val_fn: 46.0000 - val_fp: 43.0000 - val_loss: 0.5158 - val_precision: 0.8230 - val_recall: 0.8130 - val_tn: 449.0000 - val_tp: 200.0000\n",
      "Epoch 75/100\n",
      "5/5 - 0s - 63ms/step - accuracy: 0.9303 - auc: 0.9875 - categorical_accuracy: 0.9303 - f1_score: 0.9300 - fn: 311.0000 - fp: 302.0000 - loss: 0.0824 - precision: 0.9309 - recall: 0.9289 - tn: 8452.0000 - tp: 4066.0000 - val_accuracy: 0.8171 - val_auc: 0.9289 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7669 - val_fn: 46.0000 - val_fp: 43.0000 - val_loss: 0.5181 - val_precision: 0.8230 - val_recall: 0.8130 - val_tn: 449.0000 - val_tp: 200.0000\n",
      "Epoch 76/100\n",
      "5/5 - 0s - 90ms/step - accuracy: 0.9267 - auc: 0.9870 - categorical_accuracy: 0.9267 - f1_score: 0.9261 - fn: 328.0000 - fp: 314.0000 - loss: 0.0811 - precision: 0.9280 - recall: 0.9251 - tn: 8440.0000 - tp: 4049.0000 - val_accuracy: 0.8130 - val_auc: 0.9256 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7665 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5372 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 77/100\n",
      "5/5 - 0s - 65ms/step - accuracy: 0.9239 - auc: 0.9863 - categorical_accuracy: 0.9239 - f1_score: 0.9231 - fn: 339.0000 - fp: 328.0000 - loss: 0.0819 - precision: 0.9249 - recall: 0.9225 - tn: 8426.0000 - tp: 4038.0000 - val_accuracy: 0.8130 - val_auc: 0.9318 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7640 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5025 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 78/100\n",
      "5/5 - 0s - 68ms/step - accuracy: 0.9278 - auc: 0.9873 - categorical_accuracy: 0.9278 - f1_score: 0.9272 - fn: 324.0000 - fp: 305.0000 - loss: 0.0820 - precision: 0.9300 - recall: 0.9260 - tn: 8449.0000 - tp: 4053.0000 - val_accuracy: 0.8089 - val_auc: 0.9289 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7598 - val_fn: 50.0000 - val_fp: 45.0000 - val_loss: 0.5165 - val_precision: 0.8133 - val_recall: 0.7967 - val_tn: 447.0000 - val_tp: 196.0000\n",
      "Epoch 79/100\n",
      "5/5 - 0s - 71ms/step - accuracy: 0.9255 - auc: 0.9865 - categorical_accuracy: 0.9255 - f1_score: 0.9248 - fn: 331.0000 - fp: 321.0000 - loss: 0.0807 - precision: 0.9265 - recall: 0.9244 - tn: 8433.0000 - tp: 4046.0000 - val_accuracy: 0.8211 - val_auc: 0.9313 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7720 - val_fn: 45.0000 - val_fp: 43.0000 - val_loss: 0.5073 - val_precision: 0.8238 - val_recall: 0.8171 - val_tn: 449.0000 - val_tp: 201.0000\n",
      "Epoch 80/100\n",
      "5/5 - 0s - 68ms/step - accuracy: 0.9292 - auc: 0.9879 - categorical_accuracy: 0.9292 - f1_score: 0.9288 - fn: 318.0000 - fp: 305.0000 - loss: 0.0817 - precision: 0.9301 - recall: 0.9273 - tn: 8449.0000 - tp: 4059.0000 - val_accuracy: 0.8211 - val_auc: 0.9272 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7745 - val_fn: 46.0000 - val_fp: 43.0000 - val_loss: 0.5211 - val_precision: 0.8230 - val_recall: 0.8130 - val_tn: 449.0000 - val_tp: 200.0000\n",
      "Epoch 81/100\n",
      "5/5 - 0s - 72ms/step - accuracy: 0.9241 - auc: 0.9856 - categorical_accuracy: 0.9241 - f1_score: 0.9234 - fn: 340.0000 - fp: 320.0000 - loss: 0.0817 - precision: 0.9266 - recall: 0.9223 - tn: 8434.0000 - tp: 4037.0000 - val_accuracy: 0.8171 - val_auc: 0.9310 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7683 - val_fn: 47.0000 - val_fp: 44.0000 - val_loss: 0.5122 - val_precision: 0.8189 - val_recall: 0.8089 - val_tn: 448.0000 - val_tp: 199.0000\n",
      "Epoch 82/100\n",
      "5/5 - 0s - 77ms/step - accuracy: 0.9310 - auc: 0.9878 - categorical_accuracy: 0.9310 - f1_score: 0.9307 - fn: 307.0000 - fp: 300.0000 - loss: 0.0816 - precision: 0.9314 - recall: 0.9299 - tn: 8454.0000 - tp: 4070.0000 - val_accuracy: 0.8171 - val_auc: 0.9320 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7669 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5058 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 83/100\n",
      "5/5 - 0s - 71ms/step - accuracy: 0.9269 - auc: 0.9867 - categorical_accuracy: 0.9269 - f1_score: 0.9263 - fn: 326.0000 - fp: 315.0000 - loss: 0.0820 - precision: 0.9279 - recall: 0.9255 - tn: 8439.0000 - tp: 4051.0000 - val_accuracy: 0.7967 - val_auc: 0.9247 - val_categorical_accuracy: 0.7967 - val_f1_score: 0.7528 - val_fn: 52.0000 - val_fp: 48.0000 - val_loss: 0.5440 - val_precision: 0.8017 - val_recall: 0.7886 - val_tn: 444.0000 - val_tp: 194.0000\n",
      "Epoch 84/100\n",
      "5/5 - 0s - 73ms/step - accuracy: 0.9255 - auc: 0.9858 - categorical_accuracy: 0.9255 - f1_score: 0.9247 - fn: 335.0000 - fp: 323.0000 - loss: 0.0821 - precision: 0.9260 - recall: 0.9235 - tn: 8431.0000 - tp: 4042.0000 - val_accuracy: 0.8171 - val_auc: 0.9311 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7677 - val_fn: 46.0000 - val_fp: 45.0000 - val_loss: 0.5106 - val_precision: 0.8163 - val_recall: 0.8130 - val_tn: 447.0000 - val_tp: 200.0000\n",
      "Epoch 85/100\n",
      "5/5 - 0s - 76ms/step - accuracy: 0.9292 - auc: 0.9879 - categorical_accuracy: 0.9292 - f1_score: 0.9287 - fn: 317.0000 - fp: 301.0000 - loss: 0.0808 - precision: 0.9310 - recall: 0.9276 - tn: 8453.0000 - tp: 4060.0000 - val_accuracy: 0.8130 - val_auc: 0.9265 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7672 - val_fn: 50.0000 - val_fp: 46.0000 - val_loss: 0.5258 - val_precision: 0.8099 - val_recall: 0.7967 - val_tn: 446.0000 - val_tp: 196.0000\n",
      "Epoch 86/100\n",
      "5/5 - 0s - 76ms/step - accuracy: 0.9225 - auc: 0.9843 - categorical_accuracy: 0.9225 - f1_score: 0.9216 - fn: 351.0000 - fp: 329.0000 - loss: 0.0822 - precision: 0.9245 - recall: 0.9198 - tn: 8425.0000 - tp: 4026.0000 - val_accuracy: 0.8049 - val_auc: 0.9308 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7542 - val_fn: 50.0000 - val_fp: 46.0000 - val_loss: 0.5114 - val_precision: 0.8099 - val_recall: 0.7967 - val_tn: 446.0000 - val_tp: 196.0000\n",
      "Epoch 87/100\n",
      "5/5 - 0s - 76ms/step - accuracy: 0.9296 - auc: 0.9875 - categorical_accuracy: 0.9296 - f1_score: 0.9292 - fn: 313.0000 - fp: 303.0000 - loss: 0.0818 - precision: 0.9306 - recall: 0.9285 - tn: 8451.0000 - tp: 4064.0000 - val_accuracy: 0.8171 - val_auc: 0.9322 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7677 - val_fn: 49.0000 - val_fp: 44.0000 - val_loss: 0.5021 - val_precision: 0.8174 - val_recall: 0.8008 - val_tn: 448.0000 - val_tp: 197.0000\n",
      "Epoch 88/100\n",
      "5/5 - 1s - 117ms/step - accuracy: 0.9255 - auc: 0.9862 - categorical_accuracy: 0.9255 - f1_score: 0.9248 - fn: 332.0000 - fp: 320.0000 - loss: 0.0811 - precision: 0.9267 - recall: 0.9241 - tn: 8434.0000 - tp: 4045.0000 - val_accuracy: 0.7927 - val_auc: 0.9225 - val_categorical_accuracy: 0.7927 - val_f1_score: 0.7468 - val_fn: 52.0000 - val_fp: 50.0000 - val_loss: 0.5584 - val_precision: 0.7951 - val_recall: 0.7886 - val_tn: 442.0000 - val_tp: 194.0000\n",
      "Epoch 89/100\n",
      "5/5 - 0s - 76ms/step - accuracy: 0.9287 - auc: 0.9864 - categorical_accuracy: 0.9287 - f1_score: 0.9281 - fn: 326.0000 - fp: 305.0000 - loss: 0.0807 - precision: 0.9300 - recall: 0.9255 - tn: 8449.0000 - tp: 4051.0000 - val_accuracy: 0.8171 - val_auc: 0.9319 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7677 - val_fn: 48.0000 - val_fp: 43.0000 - val_loss: 0.4985 - val_precision: 0.8216 - val_recall: 0.8049 - val_tn: 449.0000 - val_tp: 198.0000\n",
      "Epoch 90/100\n",
      "5/5 - 0s - 79ms/step - accuracy: 0.9294 - auc: 0.9871 - categorical_accuracy: 0.9294 - f1_score: 0.9289 - fn: 320.0000 - fp: 307.0000 - loss: 0.0813 - precision: 0.9297 - recall: 0.9269 - tn: 8447.0000 - tp: 4057.0000 - val_accuracy: 0.7927 - val_auc: 0.9231 - val_categorical_accuracy: 0.7927 - val_f1_score: 0.7443 - val_fn: 52.0000 - val_fp: 49.0000 - val_loss: 0.5320 - val_precision: 0.7984 - val_recall: 0.7886 - val_tn: 443.0000 - val_tp: 194.0000\n",
      "Epoch 91/100\n",
      "5/5 - 0s - 82ms/step - accuracy: 0.9244 - auc: 0.9865 - categorical_accuracy: 0.9244 - f1_score: 0.9236 - fn: 337.0000 - fp: 324.0000 - loss: 0.0813 - precision: 0.9258 - recall: 0.9230 - tn: 8430.0000 - tp: 4040.0000 - val_accuracy: 0.8171 - val_auc: 0.9325 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7677 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.4968 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 92/100\n",
      "5/5 - 0s - 80ms/step - accuracy: 0.9305 - auc: 0.9879 - categorical_accuracy: 0.9305 - f1_score: 0.9301 - fn: 309.0000 - fp: 299.0000 - loss: 0.0810 - precision: 0.9315 - recall: 0.9294 - tn: 8455.0000 - tp: 4068.0000 - val_accuracy: 0.8130 - val_auc: 0.9292 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7647 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5210 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 93/100\n",
      "5/5 - 0s - 79ms/step - accuracy: 0.9273 - auc: 0.9864 - categorical_accuracy: 0.9273 - f1_score: 0.9267 - fn: 325.0000 - fp: 314.0000 - loss: 0.0805 - precision: 0.9281 - recall: 0.9257 - tn: 8440.0000 - tp: 4052.0000 - val_accuracy: 0.8089 - val_auc: 0.9292 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7604 - val_fn: 50.0000 - val_fp: 46.0000 - val_loss: 0.5151 - val_precision: 0.8099 - val_recall: 0.7967 - val_tn: 446.0000 - val_tp: 196.0000\n",
      "Epoch 94/100\n",
      "5/5 - 0s - 87ms/step - accuracy: 0.9267 - auc: 0.9871 - categorical_accuracy: 0.9267 - f1_score: 0.9260 - fn: 332.0000 - fp: 313.0000 - loss: 0.0803 - precision: 0.9282 - recall: 0.9241 - tn: 8441.0000 - tp: 4045.0000 - val_accuracy: 0.8008 - val_auc: 0.9282 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7516 - val_fn: 50.0000 - val_fp: 47.0000 - val_loss: 0.5159 - val_precision: 0.8066 - val_recall: 0.7967 - val_tn: 445.0000 - val_tp: 196.0000\n",
      "Epoch 95/100\n",
      "5/5 - 0s - 82ms/step - accuracy: 0.9257 - auc: 0.9873 - categorical_accuracy: 0.9257 - f1_score: 0.9251 - fn: 331.0000 - fp: 319.0000 - loss: 0.0807 - precision: 0.9269 - recall: 0.9244 - tn: 8435.0000 - tp: 4046.0000 - val_accuracy: 0.8089 - val_auc: 0.9300 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7584 - val_fn: 50.0000 - val_fp: 45.0000 - val_loss: 0.5092 - val_precision: 0.8133 - val_recall: 0.7967 - val_tn: 447.0000 - val_tp: 196.0000\n",
      "Epoch 96/100\n",
      "5/5 - 1s - 115ms/step - accuracy: 0.9262 - auc: 0.9867 - categorical_accuracy: 0.9262 - f1_score: 0.9256 - fn: 328.0000 - fp: 314.0000 - loss: 0.0809 - precision: 0.9280 - recall: 0.9251 - tn: 8440.0000 - tp: 4049.0000 - val_accuracy: 0.8171 - val_auc: 0.9294 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7683 - val_fn: 47.0000 - val_fp: 44.0000 - val_loss: 0.5237 - val_precision: 0.8189 - val_recall: 0.8089 - val_tn: 448.0000 - val_tp: 199.0000\n",
      "Epoch 97/100\n",
      "5/5 - 0s - 71ms/step - accuracy: 0.9273 - auc: 0.9871 - categorical_accuracy: 0.9273 - f1_score: 0.9268 - fn: 326.0000 - fp: 317.0000 - loss: 0.0806 - precision: 0.9274 - recall: 0.9255 - tn: 8437.0000 - tp: 4051.0000 - val_accuracy: 0.8130 - val_auc: 0.9322 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7647 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5033 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 98/100\n",
      "5/5 - 0s - 83ms/step - accuracy: 0.9273 - auc: 0.9876 - categorical_accuracy: 0.9273 - f1_score: 0.9268 - fn: 324.0000 - fp: 312.0000 - loss: 0.0812 - precision: 0.9285 - recall: 0.9260 - tn: 8442.0000 - tp: 4053.0000 - val_accuracy: 0.8008 - val_auc: 0.9258 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7583 - val_fn: 50.0000 - val_fp: 49.0000 - val_loss: 0.5321 - val_precision: 0.8000 - val_recall: 0.7967 - val_tn: 443.0000 - val_tp: 196.0000\n",
      "Epoch 99/100\n",
      "5/5 - 0s - 74ms/step - accuracy: 0.9230 - auc: 0.9866 - categorical_accuracy: 0.9230 - f1_score: 0.9221 - fn: 344.0000 - fp: 331.0000 - loss: 0.0809 - precision: 0.9242 - recall: 0.9214 - tn: 8423.0000 - tp: 4033.0000 - val_accuracy: 0.8049 - val_auc: 0.9303 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7580 - val_fn: 50.0000 - val_fp: 46.0000 - val_loss: 0.5113 - val_precision: 0.8099 - val_recall: 0.7967 - val_tn: 446.0000 - val_tp: 196.0000\n",
      "Epoch 100/100\n",
      "5/5 - 0s - 69ms/step - accuracy: 0.9246 - auc: 0.9873 - categorical_accuracy: 0.9246 - f1_score: 0.9240 - fn: 337.0000 - fp: 322.0000 - loss: 0.0810 - precision: 0.9262 - recall: 0.9230 - tn: 8432.0000 - tp: 4040.0000 - val_accuracy: 0.8089 - val_auc: 0.9289 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7636 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5175 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Optimal thresholds: {0: 0.19450633, 1: 0.49183455, 2: 0.85281575}\n"
     ]
    }
   ],
   "source": [
    "threshold_callback = ThresholdCallback(validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    \"accuracy\",\n",
    "    \"categorical_accuracy\",\n",
    "    \"f1_score\",\n",
    "    \"auc\"\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train_encoded,\n",
    "    batch_size=1024,\n",
    "    epochs=100,\n",
    "    verbose=2,\n",
    "    validation_data=(X_test, y_test_encoded),\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[threshold_callback]\n",
    ")\n",
    "\n",
    "model.save('classification_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Weighted F1 Score: 0.8503418082493585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90       163\n",
      "           1       0.81      0.77      0.79        39\n",
      "           2       0.93      0.57      0.70        44\n",
      "\n",
      "    accuracy                           0.86       246\n",
      "   macro avg       0.86      0.76      0.80       246\n",
      "weighted avg       0.86      0.86      0.85       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def apply_optimal_thresholds(y_prob, thresholds):\n",
    "    y_pred_adjusted = np.zeros_like(y_prob)\n",
    "    for i in range(y_prob.shape[1]):\n",
    "        y_pred_adjusted[:, i] = (y_prob[:, i] >= thresholds[i]).astype(int)\n",
    "    return y_pred_adjusted\n",
    "\n",
    "# After training is complete, get the optimal thresholds\n",
    "optimal_thresholds = threshold_callback.optimal_thresholds\n",
    "# optimal_thresholds = {0: 0.27986005, 1: 0.71200794, 2: 0.6267904}\n",
    "\n",
    "# Apply optimal thresholds to validation predictions\n",
    "y_val_pred_prob = model.predict(X_test)\n",
    "y_val_pred_adjusted = apply_optimal_thresholds(y_val_pred_prob, optimal_thresholds)\n",
    "\n",
    "# Convert adjusted predictions to class labels\n",
    "y_val_pred_labels = np.argmax(y_val_pred_adjusted, axis=1)\n",
    "y_val_labels = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Evaluate the adjusted predictions\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "f1 = f1_score(y_val_labels, y_val_pred_labels, average='weighted')\n",
    "print(f'Weighted F1 Score: {f1}')\n",
    "print(classification_report(y_val_labels, y_val_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val_labels, y_val_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Gerente', 'Especialista', 'Director'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350,435</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m350,435\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350,115</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m350,115\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = to_categorical(y_test)\n",
    "y_train_encoded = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 x1            x2\n",
      "count  4.377000e+03  4.377000e+03\n",
      "mean   1.545435e-15  2.077895e-16\n",
      "std    2.573576e+00  1.562630e+00\n",
      "min   -7.227873e+00 -5.540479e+00\n",
      "25%   -2.556524e+00 -1.154519e+00\n",
      "50%    3.682600e-01 -3.117578e-01\n",
      "75%    2.415409e+00  1.167579e+00\n",
      "max    5.676679e+00  5.133603e+00\n"
     ]
    }
   ],
   "source": [
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 16s - 3s/step - accuracy: 0.9356 - auc: 0.9895 - categorical_accuracy: 0.9356 - f1_score: 0.9355 - fn: 282.0000 - fp: 282.0000 - loss: 0.0827 - precision: 0.9356 - recall: 0.9356 - tn: 8472.0000 - tp: 4095.0000 - val_accuracy: 0.8252 - val_auc: 0.9350 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7739 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5306 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 2/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9319 - auc: 0.9886 - categorical_accuracy: 0.9319 - f1_score: 0.9314 - fn: 299.0000 - fp: 297.0000 - loss: 0.0775 - precision: 0.9321 - recall: 0.9317 - tn: 8457.0000 - tp: 4078.0000 - val_accuracy: 0.8130 - val_auc: 0.9304 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7640 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5535 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 3/100\n",
      "5/5 - 0s - 86ms/step - accuracy: 0.9255 - auc: 0.9869 - categorical_accuracy: 0.9255 - f1_score: 0.9248 - fn: 330.0000 - fp: 325.0000 - loss: 0.0796 - precision: 0.9257 - recall: 0.9246 - tn: 8429.0000 - tp: 4047.0000 - val_accuracy: 0.8089 - val_auc: 0.9289 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7590 - val_fn: 47.0000 - val_fp: 47.0000 - val_loss: 0.5460 - val_precision: 0.8089 - val_recall: 0.8089 - val_tn: 445.0000 - val_tp: 199.0000\n",
      "Epoch 4/100\n",
      "5/5 - 0s - 86ms/step - accuracy: 0.9269 - auc: 0.9875 - categorical_accuracy: 0.9269 - f1_score: 0.9262 - fn: 321.0000 - fp: 318.0000 - loss: 0.0782 - precision: 0.9273 - recall: 0.9267 - tn: 8436.0000 - tp: 4056.0000 - val_accuracy: 0.8089 - val_auc: 0.9298 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7590 - val_fn: 47.0000 - val_fp: 47.0000 - val_loss: 0.5292 - val_precision: 0.8089 - val_recall: 0.8089 - val_tn: 445.0000 - val_tp: 199.0000\n",
      "Epoch 5/100\n",
      "5/5 - 0s - 90ms/step - accuracy: 0.9278 - auc: 0.9877 - categorical_accuracy: 0.9278 - f1_score: 0.9272 - fn: 319.0000 - fp: 314.0000 - loss: 0.0785 - precision: 0.9282 - recall: 0.9271 - tn: 8440.0000 - tp: 4058.0000 - val_accuracy: 0.8089 - val_auc: 0.9302 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7590 - val_fn: 47.0000 - val_fp: 47.0000 - val_loss: 0.5211 - val_precision: 0.8089 - val_recall: 0.8089 - val_tn: 445.0000 - val_tp: 199.0000\n",
      "Epoch 6/100\n",
      "5/5 - 0s - 92ms/step - accuracy: 0.9303 - auc: 0.9880 - categorical_accuracy: 0.9303 - f1_score: 0.9298 - fn: 305.0000 - fp: 304.0000 - loss: 0.0778 - precision: 0.9305 - recall: 0.9303 - tn: 8450.0000 - tp: 4072.0000 - val_accuracy: 0.8089 - val_auc: 0.9304 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7590 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5217 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 7/100\n",
      "5/5 - 0s - 89ms/step - accuracy: 0.9308 - auc: 0.9879 - categorical_accuracy: 0.9308 - f1_score: 0.9303 - fn: 303.0000 - fp: 300.0000 - loss: 0.0773 - precision: 0.9314 - recall: 0.9308 - tn: 8454.0000 - tp: 4074.0000 - val_accuracy: 0.8089 - val_auc: 0.9304 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7575 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5232 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 8/100\n",
      "5/5 - 0s - 86ms/step - accuracy: 0.9292 - auc: 0.9880 - categorical_accuracy: 0.9292 - f1_score: 0.9286 - fn: 310.0000 - fp: 309.0000 - loss: 0.0779 - precision: 0.9294 - recall: 0.9292 - tn: 8445.0000 - tp: 4067.0000 - val_accuracy: 0.8089 - val_auc: 0.9296 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7590 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5271 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 9/100\n",
      "5/5 - 0s - 95ms/step - accuracy: 0.9294 - auc: 0.9876 - categorical_accuracy: 0.9294 - f1_score: 0.9289 - fn: 310.0000 - fp: 308.0000 - loss: 0.0784 - precision: 0.9296 - recall: 0.9292 - tn: 8446.0000 - tp: 4067.0000 - val_accuracy: 0.8089 - val_auc: 0.9320 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7590 - val_fn: 47.0000 - val_fp: 47.0000 - val_loss: 0.5172 - val_precision: 0.8089 - val_recall: 0.8089 - val_tn: 445.0000 - val_tp: 199.0000\n",
      "Epoch 10/100\n",
      "5/5 - 1s - 131ms/step - accuracy: 0.9289 - auc: 0.9876 - categorical_accuracy: 0.9289 - f1_score: 0.9284 - fn: 312.0000 - fp: 308.0000 - loss: 0.0783 - precision: 0.9296 - recall: 0.9287 - tn: 8446.0000 - tp: 4065.0000 - val_accuracy: 0.8130 - val_auc: 0.9344 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5029 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 11/100\n",
      "5/5 - 1s - 226ms/step - accuracy: 0.9294 - auc: 0.9880 - categorical_accuracy: 0.9294 - f1_score: 0.9288 - fn: 311.0000 - fp: 308.0000 - loss: 0.0772 - precision: 0.9296 - recall: 0.9289 - tn: 8446.0000 - tp: 4066.0000 - val_accuracy: 0.8130 - val_auc: 0.9358 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.4955 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 12/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9299 - auc: 0.9880 - categorical_accuracy: 0.9299 - f1_score: 0.9294 - fn: 307.0000 - fp: 307.0000 - loss: 0.0784 - precision: 0.9299 - recall: 0.9299 - tn: 8447.0000 - tp: 4070.0000 - val_accuracy: 0.8130 - val_auc: 0.9365 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7660 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.4900 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 13/100\n",
      "5/5 - 0s - 91ms/step - accuracy: 0.9296 - auc: 0.9877 - categorical_accuracy: 0.9296 - f1_score: 0.9292 - fn: 309.0000 - fp: 306.0000 - loss: 0.0778 - precision: 0.9300 - recall: 0.9294 - tn: 8448.0000 - tp: 4068.0000 - val_accuracy: 0.8130 - val_auc: 0.9350 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.4981 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 14/100\n",
      "5/5 - 1s - 110ms/step - accuracy: 0.9289 - auc: 0.9879 - categorical_accuracy: 0.9289 - f1_score: 0.9284 - fn: 312.0000 - fp: 308.0000 - loss: 0.0769 - precision: 0.9296 - recall: 0.9287 - tn: 8446.0000 - tp: 4065.0000 - val_accuracy: 0.8130 - val_auc: 0.9338 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5050 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 15/100\n",
      "5/5 - 0s - 95ms/step - accuracy: 0.9283 - auc: 0.9875 - categorical_accuracy: 0.9283 - f1_score: 0.9276 - fn: 316.0000 - fp: 309.0000 - loss: 0.0778 - precision: 0.9293 - recall: 0.9278 - tn: 8445.0000 - tp: 4061.0000 - val_accuracy: 0.8130 - val_auc: 0.9338 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 47.0000 - val_fp: 46.0000 - val_loss: 0.5051 - val_precision: 0.8122 - val_recall: 0.8089 - val_tn: 446.0000 - val_tp: 199.0000\n",
      "Epoch 16/100\n",
      "5/5 - 1s - 112ms/step - accuracy: 0.9301 - auc: 0.9876 - categorical_accuracy: 0.9301 - f1_score: 0.9295 - fn: 308.0000 - fp: 305.0000 - loss: 0.0772 - precision: 0.9303 - recall: 0.9296 - tn: 8449.0000 - tp: 4069.0000 - val_accuracy: 0.8171 - val_auc: 0.9345 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7718 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.4991 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 17/100\n",
      "5/5 - 1s - 105ms/step - accuracy: 0.9283 - auc: 0.9878 - categorical_accuracy: 0.9283 - f1_score: 0.9277 - fn: 318.0000 - fp: 312.0000 - loss: 0.0772 - precision: 0.9286 - recall: 0.9273 - tn: 8442.0000 - tp: 4059.0000 - val_accuracy: 0.8130 - val_auc: 0.9345 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.4994 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 18/100\n",
      "5/5 - 1s - 107ms/step - accuracy: 0.9305 - auc: 0.9885 - categorical_accuracy: 0.9305 - f1_score: 0.9300 - fn: 306.0000 - fp: 303.0000 - loss: 0.0772 - precision: 0.9307 - recall: 0.9301 - tn: 8451.0000 - tp: 4071.0000 - val_accuracy: 0.8171 - val_auc: 0.9353 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7718 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.4945 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 19/100\n",
      "5/5 - 0s - 99ms/step - accuracy: 0.9289 - auc: 0.9886 - categorical_accuracy: 0.9289 - f1_score: 0.9284 - fn: 313.0000 - fp: 308.0000 - loss: 0.0776 - precision: 0.9296 - recall: 0.9285 - tn: 8446.0000 - tp: 4064.0000 - val_accuracy: 0.8130 - val_auc: 0.9348 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.4970 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 20/100\n",
      "5/5 - 1s - 101ms/step - accuracy: 0.9303 - auc: 0.9883 - categorical_accuracy: 0.9303 - f1_score: 0.9298 - fn: 307.0000 - fp: 302.0000 - loss: 0.0775 - precision: 0.9309 - recall: 0.9299 - tn: 8452.0000 - tp: 4070.0000 - val_accuracy: 0.8130 - val_auc: 0.9337 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5052 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 21/100\n",
      "5/5 - 0s - 95ms/step - accuracy: 0.9285 - auc: 0.9875 - categorical_accuracy: 0.9285 - f1_score: 0.9279 - fn: 317.0000 - fp: 311.0000 - loss: 0.0772 - precision: 0.9288 - recall: 0.9276 - tn: 8443.0000 - tp: 4060.0000 - val_accuracy: 0.8089 - val_auc: 0.9333 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7631 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5091 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 22/100\n",
      "5/5 - 1s - 109ms/step - accuracy: 0.9278 - auc: 0.9869 - categorical_accuracy: 0.9278 - f1_score: 0.9272 - fn: 319.0000 - fp: 313.0000 - loss: 0.0780 - precision: 0.9284 - recall: 0.9271 - tn: 8441.0000 - tp: 4058.0000 - val_accuracy: 0.8089 - val_auc: 0.9322 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5116 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 23/100\n",
      "5/5 - 1s - 112ms/step - accuracy: 0.9299 - auc: 0.9877 - categorical_accuracy: 0.9299 - f1_score: 0.9293 - fn: 310.0000 - fp: 305.0000 - loss: 0.0771 - precision: 0.9302 - recall: 0.9292 - tn: 8449.0000 - tp: 4067.0000 - val_accuracy: 0.8089 - val_auc: 0.9327 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7631 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5053 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 24/100\n",
      "5/5 - 1s - 140ms/step - accuracy: 0.9292 - auc: 0.9876 - categorical_accuracy: 0.9292 - f1_score: 0.9287 - fn: 313.0000 - fp: 307.0000 - loss: 0.0787 - precision: 0.9298 - recall: 0.9285 - tn: 8447.0000 - tp: 4064.0000 - val_accuracy: 0.8130 - val_auc: 0.9351 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.4946 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 25/100\n",
      "5/5 - 1s - 123ms/step - accuracy: 0.9308 - auc: 0.9879 - categorical_accuracy: 0.9308 - f1_score: 0.9304 - fn: 307.0000 - fp: 303.0000 - loss: 0.0772 - precision: 0.9307 - recall: 0.9299 - tn: 8451.0000 - tp: 4070.0000 - val_accuracy: 0.8130 - val_auc: 0.9346 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.4963 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 26/100\n",
      "5/5 - 1s - 189ms/step - accuracy: 0.9296 - auc: 0.9880 - categorical_accuracy: 0.9296 - f1_score: 0.9291 - fn: 312.0000 - fp: 305.0000 - loss: 0.0778 - precision: 0.9302 - recall: 0.9287 - tn: 8449.0000 - tp: 4065.0000 - val_accuracy: 0.8130 - val_auc: 0.9336 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.4998 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 27/100\n",
      "5/5 - 1s - 235ms/step - accuracy: 0.9315 - auc: 0.9877 - categorical_accuracy: 0.9315 - f1_score: 0.9310 - fn: 301.0000 - fp: 297.0000 - loss: 0.0777 - precision: 0.9321 - recall: 0.9312 - tn: 8457.0000 - tp: 4076.0000 - val_accuracy: 0.8049 - val_auc: 0.9326 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5033 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 28/100\n",
      "5/5 - 1s - 169ms/step - accuracy: 0.9308 - auc: 0.9883 - categorical_accuracy: 0.9308 - f1_score: 0.9302 - fn: 306.0000 - fp: 302.0000 - loss: 0.0762 - precision: 0.9309 - recall: 0.9301 - tn: 8452.0000 - tp: 4071.0000 - val_accuracy: 0.8049 - val_auc: 0.9333 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5055 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 29/100\n",
      "5/5 - 1s - 141ms/step - accuracy: 0.9289 - auc: 0.9878 - categorical_accuracy: 0.9289 - f1_score: 0.9284 - fn: 315.0000 - fp: 304.0000 - loss: 0.0774 - precision: 0.9304 - recall: 0.9280 - tn: 8450.0000 - tp: 4062.0000 - val_accuracy: 0.8089 - val_auc: 0.9343 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5004 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 30/100\n",
      "5/5 - 1s - 143ms/step - accuracy: 0.9312 - auc: 0.9877 - categorical_accuracy: 0.9312 - f1_score: 0.9307 - fn: 305.0000 - fp: 300.0000 - loss: 0.0766 - precision: 0.9314 - recall: 0.9303 - tn: 8454.0000 - tp: 4072.0000 - val_accuracy: 0.8130 - val_auc: 0.9347 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7687 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.4985 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 31/100\n",
      "5/5 - 1s - 174ms/step - accuracy: 0.9294 - auc: 0.9879 - categorical_accuracy: 0.9294 - f1_score: 0.9288 - fn: 310.0000 - fp: 306.0000 - loss: 0.0766 - precision: 0.9300 - recall: 0.9292 - tn: 8448.0000 - tp: 4067.0000 - val_accuracy: 0.8130 - val_auc: 0.9351 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.4960 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 32/100\n",
      "5/5 - 1s - 119ms/step - accuracy: 0.9292 - auc: 0.9878 - categorical_accuracy: 0.9292 - f1_score: 0.9286 - fn: 311.0000 - fp: 305.0000 - loss: 0.0774 - precision: 0.9302 - recall: 0.9289 - tn: 8449.0000 - tp: 4066.0000 - val_accuracy: 0.8130 - val_auc: 0.9335 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7687 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5034 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 33/100\n",
      "5/5 - 1s - 129ms/step - accuracy: 0.9296 - auc: 0.9876 - categorical_accuracy: 0.9296 - f1_score: 0.9290 - fn: 310.0000 - fp: 305.0000 - loss: 0.0776 - precision: 0.9302 - recall: 0.9292 - tn: 8449.0000 - tp: 4067.0000 - val_accuracy: 0.8049 - val_auc: 0.9313 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5113 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 34/100\n",
      "5/5 - 1s - 118ms/step - accuracy: 0.9280 - auc: 0.9870 - categorical_accuracy: 0.9280 - f1_score: 0.9274 - fn: 318.0000 - fp: 313.0000 - loss: 0.0788 - precision: 0.9284 - recall: 0.9273 - tn: 8441.0000 - tp: 4059.0000 - val_accuracy: 0.8049 - val_auc: 0.9314 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5084 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 35/100\n",
      "5/5 - 1s - 102ms/step - accuracy: 0.9321 - auc: 0.9882 - categorical_accuracy: 0.9321 - f1_score: 0.9317 - fn: 300.0000 - fp: 295.0000 - loss: 0.0770 - precision: 0.9325 - recall: 0.9315 - tn: 8459.0000 - tp: 4077.0000 - val_accuracy: 0.8089 - val_auc: 0.9333 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5021 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 36/100\n",
      "5/5 - 0s - 99ms/step - accuracy: 0.9310 - auc: 0.9884 - categorical_accuracy: 0.9310 - f1_score: 0.9305 - fn: 305.0000 - fp: 302.0000 - loss: 0.0768 - precision: 0.9310 - recall: 0.9303 - tn: 8452.0000 - tp: 4072.0000 - val_accuracy: 0.8089 - val_auc: 0.9338 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.4998 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 37/100\n",
      "5/5 - 1s - 137ms/step - accuracy: 0.9331 - auc: 0.9877 - categorical_accuracy: 0.9331 - f1_score: 0.9326 - fn: 294.0000 - fp: 291.0000 - loss: 0.0775 - precision: 0.9335 - recall: 0.9328 - tn: 8463.0000 - tp: 4083.0000 - val_accuracy: 0.8089 - val_auc: 0.9335 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5006 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 38/100\n",
      "5/5 - 1s - 126ms/step - accuracy: 0.9294 - auc: 0.9880 - categorical_accuracy: 0.9294 - f1_score: 0.9288 - fn: 310.0000 - fp: 306.0000 - loss: 0.0779 - precision: 0.9300 - recall: 0.9292 - tn: 8448.0000 - tp: 4067.0000 - val_accuracy: 0.8130 - val_auc: 0.9337 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7687 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5004 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 39/100\n",
      "5/5 - 1s - 107ms/step - accuracy: 0.9308 - auc: 0.9883 - categorical_accuracy: 0.9308 - f1_score: 0.9303 - fn: 303.0000 - fp: 302.0000 - loss: 0.0758 - precision: 0.9310 - recall: 0.9308 - tn: 8452.0000 - tp: 4074.0000 - val_accuracy: 0.8130 - val_auc: 0.9333 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7687 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5031 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 40/100\n",
      "5/5 - 1s - 140ms/step - accuracy: 0.9267 - auc: 0.9879 - categorical_accuracy: 0.9267 - f1_score: 0.9261 - fn: 321.0000 - fp: 318.0000 - loss: 0.0782 - precision: 0.9273 - recall: 0.9267 - tn: 8436.0000 - tp: 4056.0000 - val_accuracy: 0.8130 - val_auc: 0.9328 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5034 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 41/100\n",
      "5/5 - 1s - 249ms/step - accuracy: 0.9310 - auc: 0.9880 - categorical_accuracy: 0.9310 - f1_score: 0.9305 - fn: 304.0000 - fp: 301.0000 - loss: 0.0761 - precision: 0.9312 - recall: 0.9305 - tn: 8453.0000 - tp: 4073.0000 - val_accuracy: 0.8130 - val_auc: 0.9325 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5019 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 42/100\n",
      "5/5 - 1s - 113ms/step - accuracy: 0.9308 - auc: 0.9880 - categorical_accuracy: 0.9308 - f1_score: 0.9303 - fn: 304.0000 - fp: 301.0000 - loss: 0.0764 - precision: 0.9312 - recall: 0.9305 - tn: 8453.0000 - tp: 4073.0000 - val_accuracy: 0.8171 - val_auc: 0.9326 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7724 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5037 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 43/100\n",
      "5/5 - 1s - 104ms/step - accuracy: 0.9310 - auc: 0.9880 - categorical_accuracy: 0.9310 - f1_score: 0.9305 - fn: 307.0000 - fp: 297.0000 - loss: 0.0775 - precision: 0.9320 - recall: 0.9299 - tn: 8457.0000 - tp: 4070.0000 - val_accuracy: 0.8089 - val_auc: 0.9324 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5031 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 44/100\n",
      "5/5 - 1s - 108ms/step - accuracy: 0.9296 - auc: 0.9877 - categorical_accuracy: 0.9296 - f1_score: 0.9291 - fn: 313.0000 - fp: 307.0000 - loss: 0.0776 - precision: 0.9298 - recall: 0.9285 - tn: 8447.0000 - tp: 4064.0000 - val_accuracy: 0.8049 - val_auc: 0.9320 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5054 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 45/100\n",
      "5/5 - 0s - 97ms/step - accuracy: 0.9305 - auc: 0.9879 - categorical_accuracy: 0.9305 - f1_score: 0.9300 - fn: 306.0000 - fp: 300.0000 - loss: 0.0774 - precision: 0.9314 - recall: 0.9301 - tn: 8454.0000 - tp: 4071.0000 - val_accuracy: 0.8089 - val_auc: 0.9321 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5018 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 46/100\n",
      "5/5 - 0s - 95ms/step - accuracy: 0.9310 - auc: 0.9882 - categorical_accuracy: 0.9310 - f1_score: 0.9305 - fn: 306.0000 - fp: 298.0000 - loss: 0.0775 - precision: 0.9318 - recall: 0.9301 - tn: 8456.0000 - tp: 4071.0000 - val_accuracy: 0.8130 - val_auc: 0.9325 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5000 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 47/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9292 - auc: 0.9879 - categorical_accuracy: 0.9292 - f1_score: 0.9287 - fn: 314.0000 - fp: 307.0000 - loss: 0.0769 - precision: 0.9297 - recall: 0.9283 - tn: 8447.0000 - tp: 4063.0000 - val_accuracy: 0.8130 - val_auc: 0.9333 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7674 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5008 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 48/100\n",
      "5/5 - 1s - 127ms/step - accuracy: 0.9319 - auc: 0.9882 - categorical_accuracy: 0.9319 - f1_score: 0.9315 - fn: 301.0000 - fp: 296.0000 - loss: 0.0763 - precision: 0.9323 - recall: 0.9312 - tn: 8458.0000 - tp: 4076.0000 - val_accuracy: 0.8049 - val_auc: 0.9331 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7588 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5041 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 49/100\n",
      "5/5 - 1s - 118ms/step - accuracy: 0.9305 - auc: 0.9877 - categorical_accuracy: 0.9305 - f1_score: 0.9300 - fn: 307.0000 - fp: 304.0000 - loss: 0.0770 - precision: 0.9305 - recall: 0.9299 - tn: 8450.0000 - tp: 4070.0000 - val_accuracy: 0.8089 - val_auc: 0.9322 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5083 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 50/100\n",
      "5/5 - 1s - 236ms/step - accuracy: 0.9296 - auc: 0.9872 - categorical_accuracy: 0.9296 - f1_score: 0.9291 - fn: 311.0000 - fp: 306.0000 - loss: 0.0768 - precision: 0.9300 - recall: 0.9289 - tn: 8448.0000 - tp: 4066.0000 - val_accuracy: 0.8049 - val_auc: 0.9325 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7588 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.5035 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 51/100\n",
      "5/5 - 0s - 95ms/step - accuracy: 0.9289 - auc: 0.9880 - categorical_accuracy: 0.9289 - f1_score: 0.9284 - fn: 313.0000 - fp: 311.0000 - loss: 0.0762 - precision: 0.9289 - recall: 0.9285 - tn: 8443.0000 - tp: 4064.0000 - val_accuracy: 0.8089 - val_auc: 0.9332 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7631 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.4994 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 52/100\n",
      "5/5 - 1s - 113ms/step - accuracy: 0.9294 - auc: 0.9876 - categorical_accuracy: 0.9294 - f1_score: 0.9288 - fn: 312.0000 - fp: 307.0000 - loss: 0.0774 - precision: 0.9298 - recall: 0.9287 - tn: 8447.0000 - tp: 4065.0000 - val_accuracy: 0.8089 - val_auc: 0.9330 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5000 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 53/100\n",
      "5/5 - 0s - 98ms/step - accuracy: 0.9294 - auc: 0.9876 - categorical_accuracy: 0.9294 - f1_score: 0.9288 - fn: 312.0000 - fp: 305.0000 - loss: 0.0772 - precision: 0.9302 - recall: 0.9287 - tn: 8449.0000 - tp: 4065.0000 - val_accuracy: 0.8049 - val_auc: 0.9328 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5038 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 54/100\n",
      "5/5 - 1s - 141ms/step - accuracy: 0.9299 - auc: 0.9879 - categorical_accuracy: 0.9299 - f1_score: 0.9293 - fn: 311.0000 - fp: 303.0000 - loss: 0.0773 - precision: 0.9306 - recall: 0.9289 - tn: 8451.0000 - tp: 4066.0000 - val_accuracy: 0.8049 - val_auc: 0.9334 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.4995 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 55/100\n",
      "5/5 - 0s - 97ms/step - accuracy: 0.9296 - auc: 0.9881 - categorical_accuracy: 0.9296 - f1_score: 0.9290 - fn: 310.0000 - fp: 306.0000 - loss: 0.0767 - precision: 0.9300 - recall: 0.9292 - tn: 8448.0000 - tp: 4067.0000 - val_accuracy: 0.8089 - val_auc: 0.9327 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.4992 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 56/100\n",
      "5/5 - 1s - 101ms/step - accuracy: 0.9292 - auc: 0.9884 - categorical_accuracy: 0.9292 - f1_score: 0.9286 - fn: 311.0000 - fp: 308.0000 - loss: 0.0760 - precision: 0.9296 - recall: 0.9289 - tn: 8446.0000 - tp: 4066.0000 - val_accuracy: 0.8049 - val_auc: 0.9317 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5047 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 57/100\n",
      "5/5 - 0s - 80ms/step - accuracy: 0.9292 - auc: 0.9880 - categorical_accuracy: 0.9292 - f1_score: 0.9286 - fn: 314.0000 - fp: 306.0000 - loss: 0.0760 - precision: 0.9300 - recall: 0.9283 - tn: 8448.0000 - tp: 4063.0000 - val_accuracy: 0.8049 - val_auc: 0.9316 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5079 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 58/100\n",
      "5/5 - 0s - 85ms/step - accuracy: 0.9292 - auc: 0.9873 - categorical_accuracy: 0.9292 - f1_score: 0.9286 - fn: 314.0000 - fp: 303.0000 - loss: 0.0780 - precision: 0.9306 - recall: 0.9283 - tn: 8451.0000 - tp: 4063.0000 - val_accuracy: 0.8089 - val_auc: 0.9321 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5063 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 59/100\n",
      "5/5 - 1s - 124ms/step - accuracy: 0.9289 - auc: 0.9877 - categorical_accuracy: 0.9289 - f1_score: 0.9285 - fn: 315.0000 - fp: 309.0000 - loss: 0.0771 - precision: 0.9293 - recall: 0.9280 - tn: 8445.0000 - tp: 4062.0000 - val_accuracy: 0.8089 - val_auc: 0.9316 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5053 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 60/100\n",
      "5/5 - 0s - 99ms/step - accuracy: 0.9305 - auc: 0.9876 - categorical_accuracy: 0.9305 - f1_score: 0.9301 - fn: 308.0000 - fp: 301.0000 - loss: 0.0775 - precision: 0.9311 - recall: 0.9296 - tn: 8453.0000 - tp: 4069.0000 - val_accuracy: 0.8089 - val_auc: 0.9312 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5054 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 61/100\n",
      "5/5 - 1s - 200ms/step - accuracy: 0.9305 - auc: 0.9876 - categorical_accuracy: 0.9305 - f1_score: 0.9300 - fn: 307.0000 - fp: 300.0000 - loss: 0.0767 - precision: 0.9314 - recall: 0.9299 - tn: 8454.0000 - tp: 4070.0000 - val_accuracy: 0.8049 - val_auc: 0.9310 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5064 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 62/100\n",
      "5/5 - 1s - 107ms/step - accuracy: 0.9283 - auc: 0.9877 - categorical_accuracy: 0.9283 - f1_score: 0.9277 - fn: 317.0000 - fp: 310.0000 - loss: 0.0771 - precision: 0.9291 - recall: 0.9276 - tn: 8444.0000 - tp: 4060.0000 - val_accuracy: 0.8049 - val_auc: 0.9319 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.5046 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 63/100\n",
      "5/5 - 0s - 90ms/step - accuracy: 0.9283 - auc: 0.9879 - categorical_accuracy: 0.9283 - f1_score: 0.9277 - fn: 317.0000 - fp: 310.0000 - loss: 0.0770 - precision: 0.9291 - recall: 0.9276 - tn: 8444.0000 - tp: 4060.0000 - val_accuracy: 0.8049 - val_auc: 0.9325 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5025 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 64/100\n",
      "5/5 - 1s - 106ms/step - accuracy: 0.9296 - auc: 0.9882 - categorical_accuracy: 0.9296 - f1_score: 0.9292 - fn: 309.0000 - fp: 306.0000 - loss: 0.0775 - precision: 0.9300 - recall: 0.9294 - tn: 8448.0000 - tp: 4068.0000 - val_accuracy: 0.8089 - val_auc: 0.9333 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5000 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 65/100\n",
      "5/5 - 0s - 84ms/step - accuracy: 0.9328 - auc: 0.9881 - categorical_accuracy: 0.9328 - f1_score: 0.9323 - fn: 297.0000 - fp: 291.0000 - loss: 0.0762 - precision: 0.9334 - recall: 0.9321 - tn: 8463.0000 - tp: 4080.0000 - val_accuracy: 0.8049 - val_auc: 0.9322 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5051 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 66/100\n",
      "5/5 - 1s - 122ms/step - accuracy: 0.9303 - auc: 0.9875 - categorical_accuracy: 0.9303 - f1_score: 0.9298 - fn: 306.0000 - fp: 303.0000 - loss: 0.0781 - precision: 0.9307 - recall: 0.9301 - tn: 8451.0000 - tp: 4071.0000 - val_accuracy: 0.8049 - val_auc: 0.9323 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5056 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 67/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9296 - auc: 0.9879 - categorical_accuracy: 0.9296 - f1_score: 0.9291 - fn: 312.0000 - fp: 307.0000 - loss: 0.0769 - precision: 0.9298 - recall: 0.9287 - tn: 8447.0000 - tp: 4065.0000 - val_accuracy: 0.8049 - val_auc: 0.9317 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5066 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 68/100\n",
      "5/5 - 1s - 101ms/step - accuracy: 0.9278 - auc: 0.9879 - categorical_accuracy: 0.9278 - f1_score: 0.9272 - fn: 318.0000 - fp: 310.0000 - loss: 0.0761 - precision: 0.9290 - recall: 0.9273 - tn: 8444.0000 - tp: 4059.0000 - val_accuracy: 0.8049 - val_auc: 0.9309 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 50.0000 - val_fp: 45.0000 - val_loss: 0.5080 - val_precision: 0.8133 - val_recall: 0.7967 - val_tn: 447.0000 - val_tp: 196.0000\n",
      "Epoch 69/100\n",
      "5/5 - 0s - 100ms/step - accuracy: 0.9292 - auc: 0.9878 - categorical_accuracy: 0.9292 - f1_score: 0.9286 - fn: 311.0000 - fp: 306.0000 - loss: 0.0770 - precision: 0.9300 - recall: 0.9289 - tn: 8448.0000 - tp: 4066.0000 - val_accuracy: 0.8049 - val_auc: 0.9310 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5062 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 70/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9303 - auc: 0.9882 - categorical_accuracy: 0.9303 - f1_score: 0.9298 - fn: 307.0000 - fp: 302.0000 - loss: 0.0760 - precision: 0.9309 - recall: 0.9299 - tn: 8452.0000 - tp: 4070.0000 - val_accuracy: 0.8089 - val_auc: 0.9322 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5032 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 71/100\n",
      "5/5 - 0s - 86ms/step - accuracy: 0.9294 - auc: 0.9885 - categorical_accuracy: 0.9294 - f1_score: 0.9289 - fn: 312.0000 - fp: 307.0000 - loss: 0.0758 - precision: 0.9298 - recall: 0.9287 - tn: 8447.0000 - tp: 4065.0000 - val_accuracy: 0.8049 - val_auc: 0.9321 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 48.0000 - val_fp: 47.0000 - val_loss: 0.5081 - val_precision: 0.8082 - val_recall: 0.8049 - val_tn: 445.0000 - val_tp: 198.0000\n",
      "Epoch 72/100\n",
      "5/5 - 0s - 91ms/step - accuracy: 0.9299 - auc: 0.9876 - categorical_accuracy: 0.9299 - f1_score: 0.9293 - fn: 307.0000 - fp: 305.0000 - loss: 0.0774 - precision: 0.9303 - recall: 0.9299 - tn: 8449.0000 - tp: 4070.0000 - val_accuracy: 0.8008 - val_auc: 0.9310 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5143 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 73/100\n",
      "5/5 - 1s - 108ms/step - accuracy: 0.9289 - auc: 0.9878 - categorical_accuracy: 0.9289 - f1_score: 0.9283 - fn: 314.0000 - fp: 307.0000 - loss: 0.0766 - precision: 0.9297 - recall: 0.9283 - tn: 8447.0000 - tp: 4063.0000 - val_accuracy: 0.8008 - val_auc: 0.9311 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5113 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 74/100\n",
      "5/5 - 1s - 112ms/step - accuracy: 0.9292 - auc: 0.9881 - categorical_accuracy: 0.9292 - f1_score: 0.9285 - fn: 312.0000 - fp: 308.0000 - loss: 0.0760 - precision: 0.9296 - recall: 0.9287 - tn: 8446.0000 - tp: 4065.0000 - val_accuracy: 0.8008 - val_auc: 0.9321 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5058 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 75/100\n",
      "5/5 - 1s - 106ms/step - accuracy: 0.9303 - auc: 0.9884 - categorical_accuracy: 0.9303 - f1_score: 0.9297 - fn: 312.0000 - fp: 305.0000 - loss: 0.0756 - precision: 0.9302 - recall: 0.9287 - tn: 8449.0000 - tp: 4065.0000 - val_accuracy: 0.8049 - val_auc: 0.9320 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5025 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 76/100\n",
      "5/5 - 1s - 117ms/step - accuracy: 0.9287 - auc: 0.9883 - categorical_accuracy: 0.9287 - f1_score: 0.9282 - fn: 314.0000 - fp: 311.0000 - loss: 0.0766 - precision: 0.9289 - recall: 0.9283 - tn: 8443.0000 - tp: 4063.0000 - val_accuracy: 0.8049 - val_auc: 0.9321 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5000 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 77/100\n",
      "5/5 - 1s - 111ms/step - accuracy: 0.9296 - auc: 0.9880 - categorical_accuracy: 0.9296 - f1_score: 0.9292 - fn: 308.0000 - fp: 305.0000 - loss: 0.0772 - precision: 0.9303 - recall: 0.9296 - tn: 8449.0000 - tp: 4069.0000 - val_accuracy: 0.8049 - val_auc: 0.9314 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5047 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 78/100\n",
      "5/5 - 1s - 127ms/step - accuracy: 0.9321 - auc: 0.9880 - categorical_accuracy: 0.9321 - f1_score: 0.9317 - fn: 303.0000 - fp: 294.0000 - loss: 0.0766 - precision: 0.9327 - recall: 0.9308 - tn: 8460.0000 - tp: 4074.0000 - val_accuracy: 0.8049 - val_auc: 0.9301 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5171 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 79/100\n",
      "5/5 - 1s - 133ms/step - accuracy: 0.9278 - auc: 0.9873 - categorical_accuracy: 0.9278 - f1_score: 0.9272 - fn: 322.0000 - fp: 313.0000 - loss: 0.0770 - precision: 0.9283 - recall: 0.9264 - tn: 8441.0000 - tp: 4055.0000 - val_accuracy: 0.8008 - val_auc: 0.9293 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5222 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 80/100\n",
      "5/5 - 1s - 107ms/step - accuracy: 0.9276 - auc: 0.9872 - categorical_accuracy: 0.9276 - f1_score: 0.9269 - fn: 319.0000 - fp: 316.0000 - loss: 0.0775 - precision: 0.9278 - recall: 0.9271 - tn: 8438.0000 - tp: 4058.0000 - val_accuracy: 0.8049 - val_auc: 0.9309 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5119 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 81/100\n",
      "5/5 - 1s - 125ms/step - accuracy: 0.9276 - auc: 0.9885 - categorical_accuracy: 0.9276 - f1_score: 0.9269 - fn: 319.0000 - fp: 312.0000 - loss: 0.0759 - precision: 0.9286 - recall: 0.9271 - tn: 8442.0000 - tp: 4058.0000 - val_accuracy: 0.8049 - val_auc: 0.9321 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 50.0000 - val_fp: 47.0000 - val_loss: 0.5064 - val_precision: 0.8066 - val_recall: 0.7967 - val_tn: 445.0000 - val_tp: 196.0000\n",
      "Epoch 82/100\n",
      "5/5 - 1s - 125ms/step - accuracy: 0.9296 - auc: 0.9882 - categorical_accuracy: 0.9296 - f1_score: 0.9291 - fn: 312.0000 - fp: 303.0000 - loss: 0.0760 - precision: 0.9306 - recall: 0.9287 - tn: 8451.0000 - tp: 4065.0000 - val_accuracy: 0.8049 - val_auc: 0.9316 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5108 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 83/100\n",
      "5/5 - 1s - 118ms/step - accuracy: 0.9305 - auc: 0.9886 - categorical_accuracy: 0.9305 - f1_score: 0.9300 - fn: 306.0000 - fp: 303.0000 - loss: 0.0761 - precision: 0.9307 - recall: 0.9301 - tn: 8451.0000 - tp: 4071.0000 - val_accuracy: 0.8008 - val_auc: 0.9310 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5162 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 84/100\n",
      "5/5 - 1s - 104ms/step - accuracy: 0.9285 - auc: 0.9877 - categorical_accuracy: 0.9285 - f1_score: 0.9278 - fn: 315.0000 - fp: 313.0000 - loss: 0.0768 - precision: 0.9285 - recall: 0.9280 - tn: 8441.0000 - tp: 4062.0000 - val_accuracy: 0.8049 - val_auc: 0.9312 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5119 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 85/100\n",
      "5/5 - 1s - 108ms/step - accuracy: 0.9303 - auc: 0.9884 - categorical_accuracy: 0.9303 - f1_score: 0.9298 - fn: 306.0000 - fp: 301.0000 - loss: 0.0757 - precision: 0.9312 - recall: 0.9301 - tn: 8453.0000 - tp: 4071.0000 - val_accuracy: 0.8049 - val_auc: 0.9324 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5052 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 86/100\n",
      "5/5 - 0s - 89ms/step - accuracy: 0.9292 - auc: 0.9880 - categorical_accuracy: 0.9292 - f1_score: 0.9286 - fn: 314.0000 - fp: 306.0000 - loss: 0.0772 - precision: 0.9300 - recall: 0.9283 - tn: 8448.0000 - tp: 4063.0000 - val_accuracy: 0.8049 - val_auc: 0.9316 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5074 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 87/100\n",
      "5/5 - 1s - 117ms/step - accuracy: 0.9299 - auc: 0.9880 - categorical_accuracy: 0.9299 - f1_score: 0.9293 - fn: 310.0000 - fp: 305.0000 - loss: 0.0770 - precision: 0.9302 - recall: 0.9292 - tn: 8449.0000 - tp: 4067.0000 - val_accuracy: 0.8008 - val_auc: 0.9303 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5151 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 88/100\n",
      "5/5 - 1s - 211ms/step - accuracy: 0.9292 - auc: 0.9880 - categorical_accuracy: 0.9292 - f1_score: 0.9285 - fn: 311.0000 - fp: 307.0000 - loss: 0.0757 - precision: 0.9298 - recall: 0.9289 - tn: 8447.0000 - tp: 4066.0000 - val_accuracy: 0.8008 - val_auc: 0.9305 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5143 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 89/100\n",
      "5/5 - 1s - 112ms/step - accuracy: 0.9280 - auc: 0.9878 - categorical_accuracy: 0.9280 - f1_score: 0.9274 - fn: 316.0000 - fp: 311.0000 - loss: 0.0770 - precision: 0.9289 - recall: 0.9278 - tn: 8443.0000 - tp: 4061.0000 - val_accuracy: 0.8049 - val_auc: 0.9308 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5129 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 90/100\n",
      "5/5 - 0s - 94ms/step - accuracy: 0.9287 - auc: 0.9876 - categorical_accuracy: 0.9287 - f1_score: 0.9281 - fn: 313.0000 - fp: 311.0000 - loss: 0.0767 - precision: 0.9289 - recall: 0.9285 - tn: 8443.0000 - tp: 4064.0000 - val_accuracy: 0.8008 - val_auc: 0.9306 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5140 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 91/100\n",
      "5/5 - 1s - 144ms/step - accuracy: 0.9285 - auc: 0.9877 - categorical_accuracy: 0.9285 - f1_score: 0.9279 - fn: 317.0000 - fp: 306.0000 - loss: 0.0773 - precision: 0.9299 - recall: 0.9276 - tn: 8448.0000 - tp: 4060.0000 - val_accuracy: 0.8008 - val_auc: 0.9311 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5129 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 92/100\n",
      "5/5 - 1s - 196ms/step - accuracy: 0.9303 - auc: 0.9881 - categorical_accuracy: 0.9303 - f1_score: 0.9297 - fn: 307.0000 - fp: 304.0000 - loss: 0.0762 - precision: 0.9305 - recall: 0.9299 - tn: 8450.0000 - tp: 4070.0000 - val_accuracy: 0.8008 - val_auc: 0.9307 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 49.0000 - val_loss: 0.5139 - val_precision: 0.8008 - val_recall: 0.8008 - val_tn: 443.0000 - val_tp: 197.0000\n",
      "Epoch 93/100\n",
      "5/5 - 1s - 262ms/step - accuracy: 0.9319 - auc: 0.9882 - categorical_accuracy: 0.9319 - f1_score: 0.9314 - fn: 304.0000 - fp: 297.0000 - loss: 0.0767 - precision: 0.9320 - recall: 0.9305 - tn: 8457.0000 - tp: 4073.0000 - val_accuracy: 0.8008 - val_auc: 0.9303 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7560 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5148 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 94/100\n",
      "5/5 - 1s - 110ms/step - accuracy: 0.9289 - auc: 0.9876 - categorical_accuracy: 0.9289 - f1_score: 0.9283 - fn: 317.0000 - fp: 309.0000 - loss: 0.0777 - precision: 0.9293 - recall: 0.9276 - tn: 8445.0000 - tp: 4060.0000 - val_accuracy: 0.8049 - val_auc: 0.9300 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5127 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 95/100\n",
      "5/5 - 0s - 87ms/step - accuracy: 0.9287 - auc: 0.9879 - categorical_accuracy: 0.9287 - f1_score: 0.9281 - fn: 317.0000 - fp: 310.0000 - loss: 0.0757 - precision: 0.9291 - recall: 0.9276 - tn: 8444.0000 - tp: 4060.0000 - val_accuracy: 0.8049 - val_auc: 0.9304 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5103 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 96/100\n",
      "5/5 - 1s - 104ms/step - accuracy: 0.9280 - auc: 0.9877 - categorical_accuracy: 0.9280 - f1_score: 0.9274 - fn: 322.0000 - fp: 314.0000 - loss: 0.0778 - precision: 0.9281 - recall: 0.9264 - tn: 8440.0000 - tp: 4055.0000 - val_accuracy: 0.8089 - val_auc: 0.9316 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7644 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5047 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 97/100\n",
      "5/5 - 1s - 105ms/step - accuracy: 0.9299 - auc: 0.9879 - categorical_accuracy: 0.9299 - f1_score: 0.9294 - fn: 309.0000 - fp: 304.0000 - loss: 0.0773 - precision: 0.9305 - recall: 0.9294 - tn: 8450.0000 - tp: 4068.0000 - val_accuracy: 0.8049 - val_auc: 0.9321 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 45.0000 - val_loss: 0.5047 - val_precision: 0.8140 - val_recall: 0.8008 - val_tn: 447.0000 - val_tp: 197.0000\n",
      "Epoch 98/100\n",
      "5/5 - 0s - 85ms/step - accuracy: 0.9294 - auc: 0.9881 - categorical_accuracy: 0.9294 - f1_score: 0.9288 - fn: 314.0000 - fp: 303.0000 - loss: 0.0764 - precision: 0.9306 - recall: 0.9283 - tn: 8451.0000 - tp: 4063.0000 - val_accuracy: 0.8049 - val_auc: 0.9300 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5153 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 99/100\n",
      "5/5 - 0s - 85ms/step - accuracy: 0.9273 - auc: 0.9876 - categorical_accuracy: 0.9273 - f1_score: 0.9267 - fn: 321.0000 - fp: 316.0000 - loss: 0.0774 - precision: 0.9277 - recall: 0.9267 - tn: 8438.0000 - tp: 4056.0000 - val_accuracy: 0.8049 - val_auc: 0.9299 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5167 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 100/100\n",
      "5/5 - 0s - 88ms/step - accuracy: 0.9283 - auc: 0.9878 - categorical_accuracy: 0.9283 - f1_score: 0.9276 - fn: 319.0000 - fp: 310.0000 - loss: 0.0765 - precision: 0.9290 - recall: 0.9271 - tn: 8444.0000 - tp: 4058.0000 - val_accuracy: 0.8049 - val_auc: 0.9300 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7602 - val_fn: 50.0000 - val_fp: 45.0000 - val_loss: 0.5113 - val_precision: 0.8133 - val_recall: 0.7967 - val_tn: 447.0000 - val_tp: 196.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x150f836de50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    \"accuracy\",\n",
    "    \"categorical_accuracy\",\n",
    "    \"f1_score\",\n",
    "    \"auc\"\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train_encoded,\n",
    "    batch_size=1024,\n",
    "    epochs=100,\n",
    "    verbose=2,\n",
    "    validation_data=(X_test, y_test_encoded),\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "def find_optimal_thresholds(y_true, y_prob):\n",
    "    thresholds = {}\n",
    "    for i in range(y_prob.shape[1]):\n",
    "        precision, recall, thres = precision_recall_curve(y_true[:, i], y_prob[:, i])\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "        optimal_threshold = thres[np.argmax(f1_scores)]\n",
    "        thresholds[i] = optimal_threshold\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions_baseline = model.predict(X_test, batch_size=2048)\n",
    "y_pred = np.argmax(test_predictions_baseline, axis=1)\n",
    "\n",
    "optimal_thresholds = find_optimal_thresholds(y_test_encoded, test_predictions_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.27986005, 1: 0.71200794, 2: 0.6267904}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {0: 0.27986005, 1: 0.71200794, 2: 0.6267904}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_optimal_thresholds(y_prob, thresholds):\n",
    "    y_pred_adjusted = np.zeros_like(y_prob)\n",
    "    for i in range(y_prob.shape[1]):\n",
    "        y_pred_adjusted[:, i] = (y_prob[:, i] >= thresholds[i]).astype(int)\n",
    "    return y_pred_adjusted\n",
    "\n",
    "y_pred_adjusted = apply_optimal_thresholds(test_predictions_baseline, class_weight)\n",
    "\n",
    "# Convert adjusted predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred_adjusted, axis=1)\n",
    "y_val_labels = np.argmax(y_test_encoded, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882261529320353"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_pred_labels, y_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.79860049e-01, 7.11661160e-01, 8.47874582e-03],\n",
       "       [9.99976754e-01, 4.05066952e-10, 2.32200291e-05],\n",
       "       [9.72288072e-01, 2.12554242e-02, 6.45650085e-03],\n",
       "       [9.98730838e-01, 5.07197365e-06, 1.26398553e-03],\n",
       "       [6.91369295e-01, 2.78343797e-01, 3.02868951e-02],\n",
       "       [9.99976516e-01, 3.67141539e-10, 2.34363342e-05],\n",
       "       [3.65761146e-02, 9.63423789e-01, 8.02501319e-08],\n",
       "       [9.07487333e-01, 1.46195395e-02, 7.78930634e-02],\n",
       "       [9.35681343e-01, 1.23664737e-02, 5.19521609e-02],\n",
       "       [8.90534103e-01, 9.71565768e-02, 1.23092448e-02],\n",
       "       [9.56974328e-01, 7.12855719e-03, 3.58971432e-02],\n",
       "       [9.81949151e-01, 1.63681654e-03, 1.64140631e-02],\n",
       "       [9.10884619e-01, 1.01669822e-02, 7.89484009e-02],\n",
       "       [9.87755477e-01, 6.96693081e-04, 1.15477787e-02],\n",
       "       [9.33619022e-01, 2.02800930e-02, 4.61007804e-02],\n",
       "       [5.72397172e-01, 7.19931313e-06, 4.27595586e-01],\n",
       "       [9.13759172e-01, 1.45315221e-02, 7.17092901e-02],\n",
       "       [9.06505585e-01, 1.03816269e-02, 8.31127986e-02],\n",
       "       [9.32160139e-01, 2.78353170e-02, 4.00045700e-02],\n",
       "       [5.33093452e-01, 6.03228591e-06, 4.66900438e-01],\n",
       "       [9.88639235e-01, 5.61089604e-04, 1.07996659e-02],\n",
       "       [5.57107747e-01, 4.02517647e-01, 4.03745808e-02],\n",
       "       [7.07755923e-01, 2.62647718e-01, 2.95963604e-02],\n",
       "       [9.89835799e-01, 3.96870280e-04, 9.76740476e-03],\n",
       "       [9.78350580e-01, 2.33487319e-03, 1.93144642e-02],\n",
       "       [6.68142259e-01, 3.02243382e-01, 2.96143387e-02],\n",
       "       [9.56324279e-01, 4.53074742e-03, 3.91449556e-02],\n",
       "       [9.98722613e-01, 2.66780739e-06, 1.27471087e-03],\n",
       "       [9.14674342e-01, 1.09447129e-02, 7.43809566e-02],\n",
       "       [9.40691948e-01, 7.77689321e-03, 5.15311733e-02],\n",
       "       [9.39729035e-01, 1.54958386e-02, 4.47750092e-02],\n",
       "       [8.89373302e-01, 3.40077244e-02, 7.66189769e-02],\n",
       "       [9.19435203e-01, 2.42354870e-02, 5.63293472e-02],\n",
       "       [5.16233802e-01, 1.00773514e-05, 4.83756125e-01],\n",
       "       [8.14837277e-01, 7.01176941e-06, 1.85155705e-01],\n",
       "       [7.59769738e-01, 6.07568290e-05, 2.40169466e-01],\n",
       "       [7.43536294e-01, 1.15196672e-05, 2.56452113e-01],\n",
       "       [9.27169621e-01, 8.28826614e-03, 6.45421892e-02],\n",
       "       [9.79811490e-01, 2.06432166e-03, 1.81241687e-02],\n",
       "       [8.41659963e-01, 3.68684159e-05, 1.58303201e-01],\n",
       "       [8.83980930e-01, 4.04411592e-02, 7.55778402e-02],\n",
       "       [3.17437857e-01, 5.55964070e-05, 6.82506621e-01],\n",
       "       [9.10998702e-01, 8.61216187e-02, 2.87968572e-03],\n",
       "       [9.18311834e-01, 2.65364051e-02, 5.51517792e-02],\n",
       "       [9.65381026e-01, 6.76947553e-03, 2.78494637e-02],\n",
       "       [9.08027947e-01, 1.09034972e-02, 8.10686648e-02],\n",
       "       [6.46212578e-01, 6.34907119e-05, 3.53724003e-01],\n",
       "       [9.64252055e-01, 4.38100984e-03, 3.13669965e-02],\n",
       "       [8.87880385e-01, 1.60211942e-03, 1.10517383e-01],\n",
       "       [9.46457803e-01, 1.28567759e-02, 4.06853370e-02],\n",
       "       [9.42473292e-01, 1.16721028e-02, 4.58545834e-02],\n",
       "       [9.84053016e-01, 1.22039893e-03, 1.47266975e-02],\n",
       "       [9.85408366e-01, 9.98646952e-04, 1.35930264e-02],\n",
       "       [9.99386191e-01, 5.42644159e-07, 6.13140059e-04],\n",
       "       [5.94820023e-01, 9.45330976e-06, 4.05170590e-01],\n",
       "       [9.98681128e-01, 3.15170450e-06, 1.31576031e-03],\n",
       "       [9.61428761e-01, 7.71837402e-03, 3.08528580e-02],\n",
       "       [8.89373302e-01, 3.40077244e-02, 7.66189769e-02],\n",
       "       [9.84647989e-01, 1.32127684e-02, 2.13917764e-03],\n",
       "       [9.91896927e-01, 2.31883969e-04, 7.87117798e-03],\n",
       "       [9.80935335e-01, 1.88137789e-03, 1.71832666e-02],\n",
       "       [4.47491437e-01, 1.06914500e-04, 5.52401602e-01],\n",
       "       [9.77993488e-01, 4.58280137e-03, 1.74237452e-02],\n",
       "       [8.61839890e-01, 3.70187638e-03, 1.34458244e-01],\n",
       "       [9.85974610e-01, 9.34635464e-04, 1.30906720e-02],\n",
       "       [8.92482460e-01, 7.85511509e-02, 2.89663170e-02],\n",
       "       [8.22599828e-01, 1.09941238e-05, 1.77389249e-01],\n",
       "       [9.31428671e-01, 9.15900897e-03, 5.94122186e-02],\n",
       "       [9.37419415e-01, 1.82556733e-02, 4.43249531e-02],\n",
       "       [8.03241611e-01, 1.01276775e-04, 1.96657091e-01],\n",
       "       [8.17864001e-01, 8.77450293e-06, 1.82127178e-01],\n",
       "       [7.07335472e-02, 1.31714986e-10, 9.29266453e-01],\n",
       "       [9.53421354e-01, 9.88607667e-03, 3.66925932e-02],\n",
       "       [9.10527110e-01, 4.87443320e-02, 4.07286398e-02],\n",
       "       [9.94425416e-01, 9.28141162e-05, 5.48173301e-03],\n",
       "       [9.68628228e-01, 4.53981431e-03, 2.68320460e-02],\n",
       "       [8.74759555e-01, 6.81589881e-04, 1.24558911e-01],\n",
       "       [8.87149334e-01, 1.28344009e-02, 1.00016318e-01],\n",
       "       [9.99398470e-01, 8.65289110e-07, 6.00673549e-04],\n",
       "       [4.69007403e-01, 2.06752679e-06, 5.30990481e-01],\n",
       "       [9.86778855e-01, 8.39832006e-04, 1.23813702e-02],\n",
       "       [9.24922645e-01, 6.61270395e-02, 8.95031355e-03],\n",
       "       [8.14426959e-01, 1.27611675e-05, 1.85560301e-01],\n",
       "       [8.10456574e-01, 9.51585116e-06, 1.89534009e-01],\n",
       "       [8.14476252e-01, 2.23100051e-05, 1.85501367e-01],\n",
       "       [9.08440053e-01, 1.13517428e-02, 8.02082419e-02],\n",
       "       [9.68751729e-01, 3.63426376e-03, 2.76139621e-02],\n",
       "       [9.50563312e-01, 1.06791761e-02, 3.87576148e-02],\n",
       "       [9.85247016e-01, 1.08760153e-03, 1.36653688e-02],\n",
       "       [9.97708321e-01, 1.05076078e-05, 2.28123646e-03],\n",
       "       [2.88370043e-01, 7.09264636e-01, 2.36533256e-03],\n",
       "       [9.06937540e-01, 8.17237347e-02, 1.13386754e-02],\n",
       "       [9.61758077e-01, 7.38128414e-03, 3.08606289e-02],\n",
       "       [9.73633945e-01, 3.20051704e-03, 2.31655724e-02],\n",
       "       [8.32197011e-01, 3.12295073e-04, 1.67490751e-01],\n",
       "       [8.95151973e-01, 9.17422548e-02, 1.31057333e-02],\n",
       "       [4.22140807e-01, 5.48441589e-01, 2.94176508e-02],\n",
       "       [8.01214635e-01, 4.16489820e-06, 1.98781163e-01],\n",
       "       [8.28550160e-01, 2.42319700e-04, 1.71207562e-01],\n",
       "       [9.14403200e-01, 1.35013396e-02, 7.20954612e-02],\n",
       "       [9.40920055e-01, 1.13277324e-02, 4.77522872e-02],\n",
       "       [8.82484317e-01, 3.93450930e-04, 1.17122233e-01],\n",
       "       [9.80160177e-01, 2.89954571e-03, 1.69403553e-02],\n",
       "       [9.29229379e-01, 1.11492798e-02, 5.96212931e-02],\n",
       "       [9.67835307e-01, 5.78816049e-03, 2.63765696e-02],\n",
       "       [5.96570432e-01, 2.77604329e-07, 4.03429329e-01],\n",
       "       [9.79526699e-01, 1.78275350e-02, 2.64579174e-03],\n",
       "       [6.01756215e-01, 2.56952826e-05, 3.98218095e-01],\n",
       "       [9.66184914e-01, 6.55913120e-03, 2.72559132e-02],\n",
       "       [9.17963028e-01, 2.35224850e-02, 5.85144460e-02],\n",
       "       [9.92017388e-01, 2.35428335e-04, 7.74714304e-03],\n",
       "       [8.51595104e-01, 3.51928466e-05, 1.48369595e-01],\n",
       "       [8.68167162e-01, 2.10007820e-02, 1.10832036e-01],\n",
       "       [9.85241830e-01, 1.06953247e-03, 1.36886844e-02],\n",
       "       [9.67245638e-01, 4.11831960e-03, 2.86360830e-02],\n",
       "       [9.88464803e-02, 1.66532621e-09, 9.01153505e-01],\n",
       "       [9.54559863e-01, 9.09619872e-03, 3.63439582e-02],\n",
       "       [1.46865085e-01, 8.52863789e-01, 2.71130528e-04],\n",
       "       [9.10595417e-01, 9.27525107e-03, 8.01293328e-02],\n",
       "       [9.99661803e-01, 1.37055210e-07, 3.38090264e-04],\n",
       "       [9.17854607e-01, 9.45915468e-03, 7.26862028e-02],\n",
       "       [9.18286800e-01, 1.62235685e-02, 6.54896945e-02],\n",
       "       [9.97251093e-01, 1.68783554e-05, 2.73197913e-03],\n",
       "       [9.99470770e-01, 4.44554530e-07, 5.28764329e-04],\n",
       "       [9.04452205e-01, 8.38520676e-02, 1.16956709e-02],\n",
       "       [9.72619653e-01, 4.25063260e-03, 2.31296737e-02],\n",
       "       [9.17662084e-01, 2.23485269e-02, 5.99893555e-02],\n",
       "       [9.65630651e-01, 5.11120725e-03, 2.92581972e-02],\n",
       "       [8.14002931e-01, 2.43825962e-05, 1.85972720e-01],\n",
       "       [3.11568111e-01, 3.76362259e-05, 6.88394189e-01],\n",
       "       [5.59648752e-01, 5.40432075e-06, 4.40345854e-01],\n",
       "       [9.01000440e-01, 1.23160137e-02, 8.66835564e-02],\n",
       "       [8.41755867e-01, 2.40660564e-04, 1.58003524e-01],\n",
       "       [9.03564811e-01, 9.75490827e-03, 8.66802633e-02],\n",
       "       [9.67416406e-01, 3.94862052e-03, 2.86349375e-02],\n",
       "       [9.10770595e-01, 9.07286443e-03, 8.01565349e-02],\n",
       "       [9.59289968e-01, 4.31953464e-03, 3.63904536e-02],\n",
       "       [7.78991461e-01, 7.50790132e-05, 2.20933467e-01],\n",
       "       [6.92768753e-01, 2.77627498e-01, 2.96037644e-02],\n",
       "       [7.59399056e-01, 1.19993701e-05, 2.40588889e-01],\n",
       "       [9.13421690e-01, 6.42398968e-02, 2.23384090e-02],\n",
       "       [9.09646392e-01, 7.40029812e-02, 1.63506009e-02],\n",
       "       [9.12106991e-01, 6.63624257e-02, 2.15305910e-02],\n",
       "       [8.89373302e-01, 3.40077244e-02, 7.66189769e-02],\n",
       "       [6.59159541e-01, 1.21165549e-05, 3.40828389e-01],\n",
       "       [7.73672044e-01, 2.54527095e-06, 2.26325393e-01],\n",
       "       [9.92380679e-01, 1.98124064e-04, 7.42112054e-03],\n",
       "       [7.63000727e-01, 2.31058285e-01, 5.94089832e-03],\n",
       "       [2.01985896e-01, 7.97779560e-01, 2.34551320e-04],\n",
       "       [8.37794363e-01, 2.02218853e-05, 1.62185490e-01],\n",
       "       [3.06331068e-01, 6.82687342e-01, 1.09815868e-02],\n",
       "       [8.17876995e-01, 4.96372668e-05, 1.82073355e-01],\n",
       "       [9.99204099e-01, 9.77682134e-07, 7.95016764e-04],\n",
       "       [9.56904233e-01, 4.56263404e-03, 3.85331139e-02],\n",
       "       [9.18821335e-01, 1.28328558e-02, 6.83457777e-02],\n",
       "       [9.76767480e-01, 2.94062262e-03, 2.02919040e-02],\n",
       "       [7.35236466e-01, 2.35882908e-01, 2.88805440e-02],\n",
       "       [8.94742787e-01, 1.29939197e-02, 9.22633260e-02],\n",
       "       [9.40814018e-01, 9.39551089e-03, 4.97905686e-02],\n",
       "       [9.98805046e-01, 3.13658938e-06, 1.19184831e-03],\n",
       "       [9.80090559e-01, 2.12151138e-03, 1.77879389e-02],\n",
       "       [9.22436714e-01, 1.06267948e-02, 6.69364780e-02],\n",
       "       [9.16362047e-01, 9.24919825e-03, 7.43888468e-02],\n",
       "       [1.14562973e-01, 5.41079093e-09, 8.85437012e-01],\n",
       "       [5.40364236e-02, 1.52478950e-11, 9.45963562e-01],\n",
       "       [1.68587238e-01, 1.43483575e-07, 8.31412673e-01],\n",
       "       [4.44000661e-01, 4.99229908e-01, 5.67694157e-02],\n",
       "       [1.07050758e-18, 0.00000000e+00, 1.00000000e+00],\n",
       "       [8.30806196e-01, 2.63454531e-05, 1.69167429e-01],\n",
       "       [7.81236112e-01, 4.94217011e-06, 2.18758941e-01],\n",
       "       [1.74667388e-01, 5.22028167e-12, 8.25332582e-01],\n",
       "       [2.73733463e-06, 7.30158560e-38, 9.99997258e-01],\n",
       "       [1.92772672e-02, 1.86166475e-14, 9.80722725e-01],\n",
       "       [8.47539186e-01, 3.28324910e-04, 1.52132437e-01],\n",
       "       [8.95159423e-01, 2.98705883e-03, 1.01853505e-01],\n",
       "       [9.61478233e-01, 8.06216244e-03, 3.04596145e-02],\n",
       "       [3.73196065e-01, 1.35181108e-05, 6.26790404e-01],\n",
       "       [8.57079029e-01, 7.31449691e-05, 1.42847747e-01],\n",
       "       [8.70483507e-09, 0.00000000e+00, 1.00000000e+00],\n",
       "       [4.94139493e-02, 7.96196529e-12, 9.50586021e-01],\n",
       "       [8.68658244e-05, 9.21771889e-30, 9.99913096e-01],\n",
       "       [1.77075970e-03, 3.24910212e-19, 9.98229206e-01],\n",
       "       [2.39761584e-02, 7.23744795e-14, 9.76023853e-01],\n",
       "       [5.28942347e-01, 2.61136074e-06, 4.71055090e-01],\n",
       "       [9.00375605e-01, 6.60949526e-03, 9.30149257e-02],\n",
       "       [2.73045844e-05, 6.69145974e-31, 9.99972701e-01],\n",
       "       [4.00476480e-24, 0.00000000e+00, 1.00000000e+00],\n",
       "       [9.56926703e-01, 9.62828379e-03, 3.34450267e-02],\n",
       "       [9.09350276e-01, 8.76589641e-02, 2.99070030e-03],\n",
       "       [1.22639038e-01, 9.61950697e-09, 8.77361000e-01],\n",
       "       [9.57400501e-01, 9.37767606e-03, 3.32218595e-02],\n",
       "       [3.11885506e-01, 6.70990825e-01, 1.71236806e-02],\n",
       "       [1.67372543e-02, 1.90287476e-14, 9.83262777e-01],\n",
       "       [9.85475957e-01, 1.02917373e-03, 1.34948399e-02],\n",
       "       [9.29703005e-03, 2.15323835e-16, 9.90702987e-01],\n",
       "       [1.55958652e-01, 8.43633056e-01, 4.08242835e-04],\n",
       "       [1.73505757e-03, 2.09921173e-21, 9.98264968e-01],\n",
       "       [3.30841438e-10, 0.00000000e+00, 1.00000000e+00],\n",
       "       [9.44599450e-01, 2.18031444e-02, 3.35974135e-02],\n",
       "       [6.36689924e-03, 1.98812662e-16, 9.93633032e-01],\n",
       "       [1.42713413e-01, 3.56483945e-08, 8.57286632e-01],\n",
       "       [9.18559611e-01, 7.88796041e-03, 7.35523254e-02],\n",
       "       [3.71284753e-01, 1.22072015e-06, 6.28714025e-01],\n",
       "       [2.64020241e-03, 1.85818486e-19, 9.97359812e-01],\n",
       "       [8.15378010e-01, 7.83508494e-06, 1.84614137e-01],\n",
       "       [2.79247731e-01, 1.65098845e-05, 7.20735729e-01],\n",
       "       [5.90646069e-15, 0.00000000e+00, 1.00000000e+00],\n",
       "       [3.97243127e-02, 9.60275531e-01, 1.23830247e-07],\n",
       "       [5.07513992e-03, 9.94924784e-01, 1.34337821e-12],\n",
       "       [3.55895042e-01, 6.14989758e-01, 2.91151293e-02],\n",
       "       [1.53516978e-01, 8.46109569e-01, 3.73424613e-04],\n",
       "       [2.78961379e-02, 9.72103894e-01, 1.66182463e-08],\n",
       "       [9.38215200e-03, 9.90617812e-01, 4.06224984e-11],\n",
       "       [5.99457063e-02, 9.40052986e-01, 1.31011370e-06],\n",
       "       [6.50940612e-02, 9.34903860e-01, 2.13500925e-06],\n",
       "       [5.51811218e-01, 4.07485247e-01, 4.07034606e-02],\n",
       "       [2.79623687e-01, 7.12007940e-01, 8.36830027e-03],\n",
       "       [6.25534281e-02, 9.37444866e-01, 1.72207365e-06],\n",
       "       [1.96785498e-02, 9.80321467e-01, 2.37398012e-09],\n",
       "       [1.02786072e-01, 8.97181571e-01, 3.23898021e-05],\n",
       "       [2.96209417e-02, 9.70378995e-01, 2.32456969e-08],\n",
       "       [1.42025771e-02, 9.85797465e-01, 3.87103044e-10],\n",
       "       [2.01707147e-02, 9.79829311e-01, 2.83159096e-09],\n",
       "       [8.62080976e-02, 9.13779795e-01, 1.21521880e-05],\n",
       "       [1.87579319e-01, 8.11560571e-01, 8.60175467e-04],\n",
       "       [8.16607941e-03, 9.91833925e-01, 1.87709050e-11],\n",
       "       [9.35470581e-01, 4.14114110e-02, 2.31180415e-02],\n",
       "       [7.19028413e-02, 9.28093374e-01, 3.79832954e-06],\n",
       "       [5.27257361e-02, 9.47273612e-01, 6.58833414e-07],\n",
       "       [5.71402729e-01, 4.25667614e-01, 2.92972242e-03],\n",
       "       [8.55213180e-02, 9.14467812e-01, 1.08719096e-05],\n",
       "       [2.89398115e-02, 9.71060157e-01, 2.06754631e-08],\n",
       "       [2.78401166e-01, 7.13555992e-01, 8.04280024e-03],\n",
       "       [6.90476358e-01, 2.80823052e-01, 2.87005864e-02],\n",
       "       [8.91068697e-01, 3.15896049e-02, 7.73416981e-02],\n",
       "       [1.62712857e-02, 9.83728707e-01, 8.62179883e-10],\n",
       "       [6.35175267e-03, 9.93648231e-01, 4.52923679e-12],\n",
       "       [8.86506796e-01, 9.86334980e-02, 1.48596577e-02],\n",
       "       [9.58589792e-01, 3.65704559e-02, 4.83967317e-03],\n",
       "       [2.72074598e-03, 9.97279227e-01, 2.98014550e-14],\n",
       "       [5.86727820e-02, 9.41326022e-01, 1.19268213e-06],\n",
       "       [6.51428699e-02, 9.34854984e-01, 2.15420209e-06],\n",
       "       [1.68732628e-02, 9.83126819e-01, 1.02393249e-09],\n",
       "       [6.50157332e-01, 3.17368478e-01, 3.24741825e-02],\n",
       "       [3.99977192e-02, 9.60002124e-01, 1.27386002e-07],\n",
       "       [7.99788594e-01, 1.94235429e-01, 5.97608881e-03]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 0, 0, 0,\n",
       "       2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 1, 2, 0, 2, 1, 2, 2,\n",
       "       0, 2, 2, 0, 2, 2, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760128419637622"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 - 36s - 12s/step - accuracy: 0.5067 - auc: 0.7231 - categorical_accuracy: 0.5067 - f1_score: 0.4814 - fn: 3069.0000 - fp: 588.0000 - loss: 2.1975 - precision: 0.6899 - recall: 0.2988 - tn: 8166.0000 - tp: 1308.0000 - val_accuracy: 0.7683 - val_auc: 0.8702 - val_categorical_accuracy: 0.7683 - val_f1_score: 0.7263 - val_fn: 144.0000 - val_fp: 35.0000 - val_loss: 2.0033 - val_precision: 0.7445 - val_recall: 0.4146 - val_tn: 457.0000 - val_tp: 102.0000\n",
      "Epoch 2/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.7999 - auc: 0.9315 - categorical_accuracy: 0.7999 - f1_score: 0.8018 - fn: 914.0000 - fp: 816.0000 - loss: 1.8630 - precision: 0.8093 - recall: 0.7912 - tn: 7938.0000 - tp: 3463.0000 - val_accuracy: 0.8171 - val_auc: 0.8773 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7673 - val_fn: 135.0000 - val_fp: 23.0000 - val_loss: 1.8780 - val_precision: 0.8284 - val_recall: 0.4512 - val_tn: 469.0000 - val_tp: 111.0000\n",
      "Epoch 3/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9043 - auc: 0.9750 - categorical_accuracy: 0.9043 - f1_score: 0.9058 - fn: 492.0000 - fp: 316.0000 - loss: 1.3748 - precision: 0.9248 - recall: 0.8876 - tn: 8438.0000 - tp: 3885.0000 - val_accuracy: 0.8171 - val_auc: 0.8933 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7671 - val_fn: 91.0000 - val_fp: 35.0000 - val_loss: 1.6898 - val_precision: 0.8158 - val_recall: 0.6301 - val_tn: 457.0000 - val_tp: 155.0000\n",
      "Epoch 4/500\n",
      "3/3 - 1s - 186ms/step - accuracy: 0.9120 - auc: 0.9769 - categorical_accuracy: 0.9120 - f1_score: 0.9131 - fn: 511.0000 - fp: 258.0000 - loss: 1.2778 - precision: 0.9374 - recall: 0.8833 - tn: 8496.0000 - tp: 3866.0000 - val_accuracy: 0.8089 - val_auc: 0.9035 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7592 - val_fn: 72.0000 - val_fp: 37.0000 - val_loss: 1.5569 - val_precision: 0.8246 - val_recall: 0.7073 - val_tn: 455.0000 - val_tp: 174.0000\n",
      "Epoch 5/500\n",
      "3/3 - 1s - 418ms/step - accuracy: 0.9203 - auc: 0.9788 - categorical_accuracy: 0.9203 - f1_score: 0.9206 - fn: 518.0000 - fp: 216.0000 - loss: 1.1873 - precision: 0.9470 - recall: 0.8817 - tn: 8538.0000 - tp: 3859.0000 - val_accuracy: 0.7886 - val_auc: 0.8946 - val_categorical_accuracy: 0.7886 - val_f1_score: 0.7384 - val_fn: 68.0000 - val_fp: 45.0000 - val_loss: 1.5022 - val_precision: 0.7982 - val_recall: 0.7236 - val_tn: 447.0000 - val_tp: 178.0000\n",
      "Epoch 6/500\n",
      "3/3 - 1s - 213ms/step - accuracy: 0.9269 - auc: 0.9805 - categorical_accuracy: 0.9269 - f1_score: 0.9270 - fn: 419.0000 - fp: 248.0000 - loss: 1.0806 - precision: 0.9410 - recall: 0.9043 - tn: 8506.0000 - tp: 3958.0000 - val_accuracy: 0.7927 - val_auc: 0.9127 - val_categorical_accuracy: 0.7927 - val_f1_score: 0.7418 - val_fn: 62.0000 - val_fp: 40.0000 - val_loss: 1.3516 - val_precision: 0.8214 - val_recall: 0.7480 - val_tn: 452.0000 - val_tp: 184.0000\n",
      "Epoch 7/500\n",
      "3/3 - 1s - 210ms/step - accuracy: 0.9267 - auc: 0.9807 - categorical_accuracy: 0.9267 - f1_score: 0.9272 - fn: 390.0000 - fp: 265.0000 - loss: 0.9913 - precision: 0.9377 - recall: 0.9109 - tn: 8489.0000 - tp: 3987.0000 - val_accuracy: 0.7927 - val_auc: 0.9033 - val_categorical_accuracy: 0.7927 - val_f1_score: 0.7418 - val_fn: 64.0000 - val_fp: 39.0000 - val_loss: 1.3269 - val_precision: 0.8235 - val_recall: 0.7398 - val_tn: 453.0000 - val_tp: 182.0000\n",
      "Epoch 8/500\n",
      "3/3 - 1s - 172ms/step - accuracy: 0.9294 - auc: 0.9832 - categorical_accuracy: 0.9294 - f1_score: 0.9296 - fn: 410.0000 - fp: 239.0000 - loss: 0.9083 - precision: 0.9432 - recall: 0.9063 - tn: 8515.0000 - tp: 3967.0000 - val_accuracy: 0.7967 - val_auc: 0.9107 - val_categorical_accuracy: 0.7967 - val_f1_score: 0.7453 - val_fn: 62.0000 - val_fp: 39.0000 - val_loss: 1.2286 - val_precision: 0.8251 - val_recall: 0.7480 - val_tn: 453.0000 - val_tp: 184.0000\n",
      "Epoch 9/500\n",
      "3/3 - 0s - 160ms/step - accuracy: 0.9273 - auc: 0.9818 - categorical_accuracy: 0.9273 - f1_score: 0.9274 - fn: 405.0000 - fp: 251.0000 - loss: 0.8429 - precision: 0.9406 - recall: 0.9075 - tn: 8503.0000 - tp: 3972.0000 - val_accuracy: 0.8089 - val_auc: 0.9124 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7561 - val_fn: 56.0000 - val_fp: 41.0000 - val_loss: 1.1474 - val_precision: 0.8225 - val_recall: 0.7724 - val_tn: 451.0000 - val_tp: 190.0000\n",
      "Epoch 10/500\n",
      "3/3 - 1s - 201ms/step - accuracy: 0.9276 - auc: 0.9824 - categorical_accuracy: 0.9276 - f1_score: 0.9275 - fn: 383.0000 - fp: 270.0000 - loss: 0.7734 - precision: 0.9367 - recall: 0.9125 - tn: 8484.0000 - tp: 3994.0000 - val_accuracy: 0.8171 - val_auc: 0.9188 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7666 - val_fn: 53.0000 - val_fp: 36.0000 - val_loss: 1.0704 - val_precision: 0.8428 - val_recall: 0.7846 - val_tn: 456.0000 - val_tp: 193.0000\n",
      "Epoch 11/500\n",
      "3/3 - 0s - 158ms/step - accuracy: 0.9285 - auc: 0.9840 - categorical_accuracy: 0.9285 - f1_score: 0.9285 - fn: 385.0000 - fp: 254.0000 - loss: 0.7133 - precision: 0.9402 - recall: 0.9120 - tn: 8500.0000 - tp: 3992.0000 - val_accuracy: 0.8415 - val_auc: 0.9267 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7872 - val_fn: 52.0000 - val_fp: 29.0000 - val_loss: 0.9905 - val_precision: 0.8700 - val_recall: 0.7886 - val_tn: 463.0000 - val_tp: 194.0000\n",
      "Epoch 12/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.9285 - auc: 0.9840 - categorical_accuracy: 0.9285 - f1_score: 0.9287 - fn: 385.0000 - fp: 252.0000 - loss: 0.6665 - precision: 0.9406 - recall: 0.9120 - tn: 8502.0000 - tp: 3992.0000 - val_accuracy: 0.8333 - val_auc: 0.9244 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7805 - val_fn: 50.0000 - val_fp: 32.0000 - val_loss: 0.9572 - val_precision: 0.8596 - val_recall: 0.7967 - val_tn: 460.0000 - val_tp: 196.0000\n",
      "Epoch 13/500\n",
      "3/3 - 0s - 160ms/step - accuracy: 0.9301 - auc: 0.9842 - categorical_accuracy: 0.9301 - f1_score: 0.9300 - fn: 366.0000 - fp: 259.0000 - loss: 0.6158 - precision: 0.9393 - recall: 0.9164 - tn: 8495.0000 - tp: 4011.0000 - val_accuracy: 0.8415 - val_auc: 0.9284 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7886 - val_fn: 51.0000 - val_fp: 32.0000 - val_loss: 0.8883 - val_precision: 0.8590 - val_recall: 0.7927 - val_tn: 460.0000 - val_tp: 195.0000\n",
      "Epoch 14/500\n",
      "3/3 - 1s - 173ms/step - accuracy: 0.9296 - auc: 0.9832 - categorical_accuracy: 0.9296 - f1_score: 0.9296 - fn: 352.0000 - fp: 279.0000 - loss: 0.5847 - precision: 0.9352 - recall: 0.9196 - tn: 8475.0000 - tp: 4025.0000 - val_accuracy: 0.8455 - val_auc: 0.9315 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7889 - val_fn: 45.0000 - val_fp: 31.0000 - val_loss: 0.8377 - val_precision: 0.8664 - val_recall: 0.8171 - val_tn: 461.0000 - val_tp: 201.0000\n",
      "Epoch 15/500\n",
      "3/3 - 0s - 159ms/step - accuracy: 0.9278 - auc: 0.9837 - categorical_accuracy: 0.9278 - f1_score: 0.9281 - fn: 341.0000 - fp: 296.0000 - loss: 0.5511 - precision: 0.9317 - recall: 0.9221 - tn: 8458.0000 - tp: 4036.0000 - val_accuracy: 0.8374 - val_auc: 0.9276 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7814 - val_fn: 46.0000 - val_fp: 33.0000 - val_loss: 0.8312 - val_precision: 0.8584 - val_recall: 0.8130 - val_tn: 459.0000 - val_tp: 200.0000\n",
      "Epoch 16/500\n",
      "3/3 - 0s - 163ms/step - accuracy: 0.9292 - auc: 0.9839 - categorical_accuracy: 0.9292 - f1_score: 0.9289 - fn: 343.0000 - fp: 293.0000 - loss: 0.5178 - precision: 0.9323 - recall: 0.9216 - tn: 8461.0000 - tp: 4034.0000 - val_accuracy: 0.8293 - val_auc: 0.9290 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7687 - val_fn: 51.0000 - val_fp: 32.0000 - val_loss: 0.8060 - val_precision: 0.8590 - val_recall: 0.7927 - val_tn: 460.0000 - val_tp: 195.0000\n",
      "Epoch 17/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9269 - auc: 0.9837 - categorical_accuracy: 0.9269 - f1_score: 0.9266 - fn: 363.0000 - fp: 289.0000 - loss: 0.4952 - precision: 0.9328 - recall: 0.9171 - tn: 8465.0000 - tp: 4014.0000 - val_accuracy: 0.8455 - val_auc: 0.9297 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7863 - val_fn: 45.0000 - val_fp: 33.0000 - val_loss: 0.7684 - val_precision: 0.8590 - val_recall: 0.8171 - val_tn: 459.0000 - val_tp: 201.0000\n",
      "Epoch 18/500\n",
      "3/3 - 1s - 270ms/step - accuracy: 0.9299 - auc: 0.9839 - categorical_accuracy: 0.9299 - f1_score: 0.9300 - fn: 339.0000 - fp: 283.0000 - loss: 0.4677 - precision: 0.9345 - recall: 0.9225 - tn: 8471.0000 - tp: 4038.0000 - val_accuracy: 0.8455 - val_auc: 0.9277 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7863 - val_fn: 42.0000 - val_fp: 33.0000 - val_loss: 0.7688 - val_precision: 0.8608 - val_recall: 0.8293 - val_tn: 459.0000 - val_tp: 204.0000\n",
      "Epoch 19/500\n",
      "3/3 - 1s - 226ms/step - accuracy: 0.9303 - auc: 0.9847 - categorical_accuracy: 0.9303 - f1_score: 0.9303 - fn: 341.0000 - fp: 272.0000 - loss: 0.4488 - precision: 0.9369 - recall: 0.9221 - tn: 8482.0000 - tp: 4036.0000 - val_accuracy: 0.8496 - val_auc: 0.9273 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7846 - val_fn: 46.0000 - val_fp: 33.0000 - val_loss: 0.7653 - val_precision: 0.8584 - val_recall: 0.8130 - val_tn: 459.0000 - val_tp: 200.0000\n",
      "Epoch 20/500\n",
      "3/3 - 1s - 355ms/step - accuracy: 0.9280 - auc: 0.9848 - categorical_accuracy: 0.9280 - f1_score: 0.9280 - fn: 344.0000 - fp: 287.0000 - loss: 0.4319 - precision: 0.9336 - recall: 0.9214 - tn: 8467.0000 - tp: 4033.0000 - val_accuracy: 0.8537 - val_auc: 0.9337 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7936 - val_fn: 46.0000 - val_fp: 31.0000 - val_loss: 0.7144 - val_precision: 0.8658 - val_recall: 0.8130 - val_tn: 461.0000 - val_tp: 200.0000\n",
      "Epoch 21/500\n",
      "3/3 - 1s - 208ms/step - accuracy: 0.9237 - auc: 0.9838 - categorical_accuracy: 0.9237 - f1_score: 0.9235 - fn: 356.0000 - fp: 320.0000 - loss: 0.4232 - precision: 0.9263 - recall: 0.9187 - tn: 8434.0000 - tp: 4021.0000 - val_accuracy: 0.8374 - val_auc: 0.9301 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7720 - val_fn: 45.0000 - val_fp: 33.0000 - val_loss: 0.7144 - val_precision: 0.8590 - val_recall: 0.8171 - val_tn: 459.0000 - val_tp: 201.0000\n",
      "Epoch 22/500\n",
      "3/3 - 1s - 220ms/step - accuracy: 0.9271 - auc: 0.9828 - categorical_accuracy: 0.9271 - f1_score: 0.9271 - fn: 333.0000 - fp: 299.0000 - loss: 0.4164 - precision: 0.9312 - recall: 0.9239 - tn: 8455.0000 - tp: 4044.0000 - val_accuracy: 0.8333 - val_auc: 0.9237 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7542 - val_fn: 47.0000 - val_fp: 35.0000 - val_loss: 0.7318 - val_precision: 0.8504 - val_recall: 0.8089 - val_tn: 457.0000 - val_tp: 199.0000\n",
      "Epoch 23/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9273 - auc: 0.9854 - categorical_accuracy: 0.9273 - f1_score: 0.9276 - fn: 344.0000 - fp: 299.0000 - loss: 0.3933 - precision: 0.9310 - recall: 0.9214 - tn: 8455.0000 - tp: 4033.0000 - val_accuracy: 0.8171 - val_auc: 0.9183 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7227 - val_fn: 48.0000 - val_fp: 40.0000 - val_loss: 0.7308 - val_precision: 0.8319 - val_recall: 0.8049 - val_tn: 452.0000 - val_tp: 198.0000\n",
      "Epoch 24/500\n",
      "3/3 - 1s - 173ms/step - accuracy: 0.9283 - auc: 0.9849 - categorical_accuracy: 0.9283 - f1_score: 0.9284 - fn: 338.0000 - fp: 290.0000 - loss: 0.3804 - precision: 0.9330 - recall: 0.9228 - tn: 8464.0000 - tp: 4039.0000 - val_accuracy: 0.8211 - val_auc: 0.9213 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7325 - val_fn: 48.0000 - val_fp: 37.0000 - val_loss: 0.7160 - val_precision: 0.8426 - val_recall: 0.8049 - val_tn: 455.0000 - val_tp: 198.0000\n",
      "Epoch 25/500\n",
      "3/3 - 0s - 152ms/step - accuracy: 0.9278 - auc: 0.9839 - categorical_accuracy: 0.9278 - f1_score: 0.9277 - fn: 338.0000 - fp: 293.0000 - loss: 0.3811 - precision: 0.9324 - recall: 0.9228 - tn: 8461.0000 - tp: 4039.0000 - val_accuracy: 0.7724 - val_auc: 0.9125 - val_categorical_accuracy: 0.7724 - val_f1_score: 0.6213 - val_fn: 56.0000 - val_fp: 52.0000 - val_loss: 0.7380 - val_precision: 0.7851 - val_recall: 0.7724 - val_tn: 440.0000 - val_tp: 190.0000\n",
      "Epoch 26/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9283 - auc: 0.9858 - categorical_accuracy: 0.9283 - f1_score: 0.9285 - fn: 324.0000 - fp: 306.0000 - loss: 0.3612 - precision: 0.9298 - recall: 0.9260 - tn: 8448.0000 - tp: 4053.0000 - val_accuracy: 0.7764 - val_auc: 0.9157 - val_categorical_accuracy: 0.7764 - val_f1_score: 0.6178 - val_fn: 56.0000 - val_fp: 54.0000 - val_loss: 0.7080 - val_precision: 0.7787 - val_recall: 0.7724 - val_tn: 438.0000 - val_tp: 190.0000\n",
      "Epoch 27/500\n",
      "3/3 - 1s - 181ms/step - accuracy: 0.9301 - auc: 0.9840 - categorical_accuracy: 0.9301 - f1_score: 0.9302 - fn: 309.0000 - fp: 300.0000 - loss: 0.3628 - precision: 0.9313 - recall: 0.9294 - tn: 8454.0000 - tp: 4068.0000 - val_accuracy: 0.7886 - val_auc: 0.9156 - val_categorical_accuracy: 0.7886 - val_f1_score: 0.6538 - val_fn: 54.0000 - val_fp: 51.0000 - val_loss: 0.6924 - val_precision: 0.7901 - val_recall: 0.7805 - val_tn: 441.0000 - val_tp: 192.0000\n",
      "Epoch 28/500\n",
      "3/3 - 1s - 185ms/step - accuracy: 0.9241 - auc: 0.9847 - categorical_accuracy: 0.9241 - f1_score: 0.9237 - fn: 339.0000 - fp: 322.0000 - loss: 0.3505 - precision: 0.9261 - recall: 0.9225 - tn: 8432.0000 - tp: 4038.0000 - val_accuracy: 0.7805 - val_auc: 0.9122 - val_categorical_accuracy: 0.7805 - val_f1_score: 0.6395 - val_fn: 57.0000 - val_fp: 53.0000 - val_loss: 0.7094 - val_precision: 0.7810 - val_recall: 0.7683 - val_tn: 439.0000 - val_tp: 189.0000\n",
      "Epoch 29/500\n",
      "3/3 - 0s - 163ms/step - accuracy: 0.9285 - auc: 0.9845 - categorical_accuracy: 0.9285 - f1_score: 0.9287 - fn: 328.0000 - fp: 307.0000 - loss: 0.3441 - precision: 0.9295 - recall: 0.9251 - tn: 8447.0000 - tp: 4049.0000 - val_accuracy: 0.7724 - val_auc: 0.9152 - val_categorical_accuracy: 0.7724 - val_f1_score: 0.6190 - val_fn: 57.0000 - val_fp: 55.0000 - val_loss: 0.6936 - val_precision: 0.7746 - val_recall: 0.7683 - val_tn: 437.0000 - val_tp: 189.0000\n",
      "Epoch 30/500\n",
      "3/3 - 0s - 154ms/step - accuracy: 0.9280 - auc: 0.9852 - categorical_accuracy: 0.9280 - f1_score: 0.9282 - fn: 325.0000 - fp: 305.0000 - loss: 0.3328 - precision: 0.9300 - recall: 0.9257 - tn: 8449.0000 - tp: 4052.0000 - val_accuracy: 0.7602 - val_auc: 0.8802 - val_categorical_accuracy: 0.7602 - val_f1_score: 0.5479 - val_fn: 59.0000 - val_fp: 57.0000 - val_loss: 0.7742 - val_precision: 0.7664 - val_recall: 0.7602 - val_tn: 435.0000 - val_tp: 187.0000\n",
      "Epoch 31/500\n",
      "3/3 - 1s - 195ms/step - accuracy: 0.9310 - auc: 0.9864 - categorical_accuracy: 0.9310 - f1_score: 0.9311 - fn: 321.0000 - fp: 287.0000 - loss: 0.3264 - precision: 0.9339 - recall: 0.9267 - tn: 8467.0000 - tp: 4056.0000 - val_accuracy: 0.7724 - val_auc: 0.9098 - val_categorical_accuracy: 0.7724 - val_f1_score: 0.5951 - val_fn: 56.0000 - val_fp: 54.0000 - val_loss: 0.6974 - val_precision: 0.7787 - val_recall: 0.7724 - val_tn: 438.0000 - val_tp: 190.0000\n",
      "Epoch 32/500\n",
      "3/3 - 1s - 200ms/step - accuracy: 0.9283 - auc: 0.9858 - categorical_accuracy: 0.9283 - f1_score: 0.9284 - fn: 320.0000 - fp: 306.0000 - loss: 0.3213 - precision: 0.9299 - recall: 0.9269 - tn: 8448.0000 - tp: 4057.0000 - val_accuracy: 0.7520 - val_auc: 0.8893 - val_categorical_accuracy: 0.7520 - val_f1_score: 0.5191 - val_fn: 62.0000 - val_fp: 61.0000 - val_loss: 0.7390 - val_precision: 0.7510 - val_recall: 0.7480 - val_tn: 431.0000 - val_tp: 184.0000\n",
      "Epoch 33/500\n",
      "3/3 - 1s - 174ms/step - accuracy: 0.9262 - auc: 0.9849 - categorical_accuracy: 0.9262 - f1_score: 0.9263 - fn: 340.0000 - fp: 305.0000 - loss: 0.3234 - precision: 0.9298 - recall: 0.9223 - tn: 8449.0000 - tp: 4037.0000 - val_accuracy: 0.8008 - val_auc: 0.9196 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.6841 - val_fn: 54.0000 - val_fp: 46.0000 - val_loss: 0.6617 - val_precision: 0.8067 - val_recall: 0.7805 - val_tn: 446.0000 - val_tp: 192.0000\n",
      "Epoch 34/500\n",
      "3/3 - 1s - 199ms/step - accuracy: 0.9308 - auc: 0.9863 - categorical_accuracy: 0.9308 - f1_score: 0.9308 - fn: 322.0000 - fp: 297.0000 - loss: 0.3094 - precision: 0.9318 - recall: 0.9264 - tn: 8457.0000 - tp: 4055.0000 - val_accuracy: 0.8171 - val_auc: 0.9274 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7227 - val_fn: 46.0000 - val_fp: 42.0000 - val_loss: 0.6195 - val_precision: 0.8264 - val_recall: 0.8130 - val_tn: 450.0000 - val_tp: 200.0000\n",
      "Epoch 35/500\n",
      "3/3 - 1s - 203ms/step - accuracy: 0.9287 - auc: 0.9860 - categorical_accuracy: 0.9287 - f1_score: 0.9288 - fn: 322.0000 - fp: 303.0000 - loss: 0.3065 - precision: 0.9305 - recall: 0.9264 - tn: 8451.0000 - tp: 4055.0000 - val_accuracy: 0.8374 - val_auc: 0.9272 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7666 - val_fn: 42.0000 - val_fp: 38.0000 - val_loss: 0.6298 - val_precision: 0.8430 - val_recall: 0.8293 - val_tn: 454.0000 - val_tp: 204.0000\n",
      "Epoch 36/500\n",
      "3/3 - 1s - 375ms/step - accuracy: 0.9280 - auc: 0.9856 - categorical_accuracy: 0.9280 - f1_score: 0.9278 - fn: 327.0000 - fp: 304.0000 - loss: 0.3058 - precision: 0.9302 - recall: 0.9253 - tn: 8450.0000 - tp: 4050.0000 - val_accuracy: 0.8089 - val_auc: 0.9194 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7055 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.6567 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 37/500\n",
      "3/3 - 1s - 192ms/step - accuracy: 0.9267 - auc: 0.9871 - categorical_accuracy: 0.9267 - f1_score: 0.9267 - fn: 332.0000 - fp: 309.0000 - loss: 0.3006 - precision: 0.9290 - recall: 0.9241 - tn: 8445.0000 - tp: 4045.0000 - val_accuracy: 0.8415 - val_auc: 0.9346 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7710 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.5973 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 38/500\n",
      "3/3 - 1s - 191ms/step - accuracy: 0.9292 - auc: 0.9853 - categorical_accuracy: 0.9292 - f1_score: 0.9292 - fn: 320.0000 - fp: 301.0000 - loss: 0.3034 - precision: 0.9309 - recall: 0.9269 - tn: 8453.0000 - tp: 4057.0000 - val_accuracy: 0.7927 - val_auc: 0.9215 - val_categorical_accuracy: 0.7927 - val_f1_score: 0.6700 - val_fn: 51.0000 - val_fp: 49.0000 - val_loss: 0.6265 - val_precision: 0.7992 - val_recall: 0.7927 - val_tn: 443.0000 - val_tp: 195.0000\n",
      "Epoch 39/500\n",
      "3/3 - 1s - 216ms/step - accuracy: 0.9280 - auc: 0.9846 - categorical_accuracy: 0.9280 - f1_score: 0.9283 - fn: 323.0000 - fp: 306.0000 - loss: 0.3043 - precision: 0.9298 - recall: 0.9262 - tn: 8448.0000 - tp: 4054.0000 - val_accuracy: 0.7805 - val_auc: 0.9193 - val_categorical_accuracy: 0.7805 - val_f1_score: 0.6495 - val_fn: 56.0000 - val_fp: 52.0000 - val_loss: 0.6258 - val_precision: 0.7851 - val_recall: 0.7724 - val_tn: 440.0000 - val_tp: 190.0000\n",
      "Epoch 40/500\n",
      "3/3 - 1s - 177ms/step - accuracy: 0.9253 - auc: 0.9855 - categorical_accuracy: 0.9253 - f1_score: 0.9257 - fn: 333.0000 - fp: 317.0000 - loss: 0.2952 - precision: 0.9273 - recall: 0.9239 - tn: 8437.0000 - tp: 4044.0000 - val_accuracy: 0.8049 - val_auc: 0.9259 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7020 - val_fn: 51.0000 - val_fp: 44.0000 - val_loss: 0.6263 - val_precision: 0.8159 - val_recall: 0.7927 - val_tn: 448.0000 - val_tp: 195.0000\n",
      "Epoch 41/500\n",
      "3/3 - 1s - 245ms/step - accuracy: 0.9292 - auc: 0.9859 - categorical_accuracy: 0.9292 - f1_score: 0.9290 - fn: 320.0000 - fp: 298.0000 - loss: 0.2919 - precision: 0.9316 - recall: 0.9269 - tn: 8456.0000 - tp: 4057.0000 - val_accuracy: 0.8130 - val_auc: 0.9267 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7168 - val_fn: 49.0000 - val_fp: 42.0000 - val_loss: 0.6043 - val_precision: 0.8243 - val_recall: 0.8008 - val_tn: 450.0000 - val_tp: 197.0000\n",
      "Epoch 42/500\n",
      "3/3 - 1s - 253ms/step - accuracy: 0.9301 - auc: 0.9860 - categorical_accuracy: 0.9301 - f1_score: 0.9302 - fn: 311.0000 - fp: 302.0000 - loss: 0.2859 - precision: 0.9309 - recall: 0.9289 - tn: 8452.0000 - tp: 4066.0000 - val_accuracy: 0.7846 - val_auc: 0.9229 - val_categorical_accuracy: 0.7846 - val_f1_score: 0.6537 - val_fn: 56.0000 - val_fp: 49.0000 - val_loss: 0.6072 - val_precision: 0.7950 - val_recall: 0.7724 - val_tn: 443.0000 - val_tp: 190.0000\n",
      "Epoch 43/500\n",
      "3/3 - 1s - 181ms/step - accuracy: 0.9239 - auc: 0.9851 - categorical_accuracy: 0.9239 - f1_score: 0.9241 - fn: 340.0000 - fp: 324.0000 - loss: 0.2916 - precision: 0.9257 - recall: 0.9223 - tn: 8430.0000 - tp: 4037.0000 - val_accuracy: 0.8130 - val_auc: 0.9247 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7142 - val_fn: 47.0000 - val_fp: 42.0000 - val_loss: 0.6112 - val_precision: 0.8257 - val_recall: 0.8089 - val_tn: 450.0000 - val_tp: 199.0000\n",
      "Epoch 44/500\n",
      "3/3 - 1s - 172ms/step - accuracy: 0.9273 - auc: 0.9851 - categorical_accuracy: 0.9273 - f1_score: 0.9271 - fn: 333.0000 - fp: 305.0000 - loss: 0.2863 - precision: 0.9299 - recall: 0.9239 - tn: 8449.0000 - tp: 4044.0000 - val_accuracy: 0.7967 - val_auc: 0.9169 - val_categorical_accuracy: 0.7967 - val_f1_score: 0.6749 - val_fn: 50.0000 - val_fp: 49.0000 - val_loss: 0.6290 - val_precision: 0.8000 - val_recall: 0.7967 - val_tn: 443.0000 - val_tp: 196.0000\n",
      "Epoch 45/500\n",
      "3/3 - 1s - 183ms/step - accuracy: 0.9264 - auc: 0.9841 - categorical_accuracy: 0.9264 - f1_score: 0.9268 - fn: 326.0000 - fp: 320.0000 - loss: 0.2920 - precision: 0.9268 - recall: 0.9255 - tn: 8434.0000 - tp: 4051.0000 - val_accuracy: 0.7642 - val_auc: 0.9070 - val_categorical_accuracy: 0.7642 - val_f1_score: 0.5739 - val_fn: 60.0000 - val_fp: 56.0000 - val_loss: 0.6717 - val_precision: 0.7686 - val_recall: 0.7561 - val_tn: 436.0000 - val_tp: 186.0000\n",
      "Epoch 46/500\n",
      "3/3 - 0s - 161ms/step - accuracy: 0.9235 - auc: 0.9832 - categorical_accuracy: 0.9235 - f1_score: 0.9241 - fn: 350.0000 - fp: 319.0000 - loss: 0.3018 - precision: 0.9266 - recall: 0.9200 - tn: 8435.0000 - tp: 4027.0000 - val_accuracy: 0.8415 - val_auc: 0.9395 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7784 - val_fn: 40.0000 - val_fp: 35.0000 - val_loss: 0.5558 - val_precision: 0.8548 - val_recall: 0.8374 - val_tn: 457.0000 - val_tp: 206.0000\n",
      "Epoch 47/500\n",
      "3/3 - 1s - 187ms/step - accuracy: 0.9257 - auc: 0.9845 - categorical_accuracy: 0.9257 - f1_score: 0.9254 - fn: 332.0000 - fp: 318.0000 - loss: 0.2879 - precision: 0.9271 - recall: 0.9241 - tn: 8436.0000 - tp: 4045.0000 - val_accuracy: 0.8252 - val_auc: 0.9226 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7318 - val_fn: 44.0000 - val_fp: 42.0000 - val_loss: 0.6007 - val_precision: 0.8279 - val_recall: 0.8211 - val_tn: 450.0000 - val_tp: 202.0000\n",
      "Epoch 48/500\n",
      "3/3 - 1s - 190ms/step - accuracy: 0.9241 - auc: 0.9845 - categorical_accuracy: 0.9241 - f1_score: 0.9246 - fn: 337.0000 - fp: 323.0000 - loss: 0.2873 - precision: 0.9260 - recall: 0.9230 - tn: 8431.0000 - tp: 4040.0000 - val_accuracy: 0.7764 - val_auc: 0.9161 - val_categorical_accuracy: 0.7764 - val_f1_score: 0.6332 - val_fn: 58.0000 - val_fp: 54.0000 - val_loss: 0.6337 - val_precision: 0.7769 - val_recall: 0.7642 - val_tn: 438.0000 - val_tp: 188.0000\n",
      "Epoch 49/500\n",
      "3/3 - 0s - 160ms/step - accuracy: 0.9257 - auc: 0.9864 - categorical_accuracy: 0.9257 - f1_score: 0.9258 - fn: 341.0000 - fp: 312.0000 - loss: 0.2786 - precision: 0.9282 - recall: 0.9221 - tn: 8442.0000 - tp: 4036.0000 - val_accuracy: 0.8455 - val_auc: 0.9327 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7782 - val_fn: 41.0000 - val_fp: 36.0000 - val_loss: 0.5608 - val_precision: 0.8506 - val_recall: 0.8333 - val_tn: 456.0000 - val_tp: 205.0000\n",
      "Epoch 50/500\n",
      "3/3 - 0s - 163ms/step - accuracy: 0.9278 - auc: 0.9850 - categorical_accuracy: 0.9278 - f1_score: 0.9277 - fn: 324.0000 - fp: 311.0000 - loss: 0.2810 - precision: 0.9287 - recall: 0.9260 - tn: 8443.0000 - tp: 4053.0000 - val_accuracy: 0.7886 - val_auc: 0.9154 - val_categorical_accuracy: 0.7886 - val_f1_score: 0.6605 - val_fn: 54.0000 - val_fp: 51.0000 - val_loss: 0.6134 - val_precision: 0.7901 - val_recall: 0.7805 - val_tn: 441.0000 - val_tp: 192.0000\n",
      "Epoch 51/500\n",
      "3/3 - 1s - 191ms/step - accuracy: 0.9267 - auc: 0.9854 - categorical_accuracy: 0.9267 - f1_score: 0.9270 - fn: 332.0000 - fp: 307.0000 - loss: 0.2780 - precision: 0.9295 - recall: 0.9241 - tn: 8447.0000 - tp: 4045.0000 - val_accuracy: 0.8293 - val_auc: 0.9256 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7466 - val_fn: 45.0000 - val_fp: 40.0000 - val_loss: 0.6077 - val_precision: 0.8340 - val_recall: 0.8171 - val_tn: 452.0000 - val_tp: 201.0000\n",
      "Epoch 52/500\n",
      "3/3 - 1s - 184ms/step - accuracy: 0.9253 - auc: 0.9856 - categorical_accuracy: 0.9253 - f1_score: 0.9253 - fn: 334.0000 - fp: 309.0000 - loss: 0.2752 - precision: 0.9290 - recall: 0.9237 - tn: 8445.0000 - tp: 4043.0000 - val_accuracy: 0.8293 - val_auc: 0.9241 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7467 - val_fn: 44.0000 - val_fp: 42.0000 - val_loss: 0.6008 - val_precision: 0.8279 - val_recall: 0.8211 - val_tn: 450.0000 - val_tp: 202.0000\n",
      "Epoch 53/500\n",
      "3/3 - 1s - 170ms/step - accuracy: 0.9296 - auc: 0.9860 - categorical_accuracy: 0.9296 - f1_score: 0.9298 - fn: 316.0000 - fp: 304.0000 - loss: 0.2684 - precision: 0.9304 - recall: 0.9278 - tn: 8450.0000 - tp: 4061.0000 - val_accuracy: 0.8089 - val_auc: 0.9090 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7113 - val_fn: 48.0000 - val_fp: 45.0000 - val_loss: 0.6583 - val_precision: 0.8148 - val_recall: 0.8049 - val_tn: 447.0000 - val_tp: 198.0000\n",
      "Epoch 54/500\n",
      "3/3 - 1s - 187ms/step - accuracy: 0.9239 - auc: 0.9854 - categorical_accuracy: 0.9239 - f1_score: 0.9236 - fn: 346.0000 - fp: 321.0000 - loss: 0.2726 - precision: 0.9262 - recall: 0.9210 - tn: 8433.0000 - tp: 4031.0000 - val_accuracy: 0.7846 - val_auc: 0.9216 - val_categorical_accuracy: 0.7846 - val_f1_score: 0.6553 - val_fn: 56.0000 - val_fp: 53.0000 - val_loss: 0.5910 - val_precision: 0.7819 - val_recall: 0.7724 - val_tn: 439.0000 - val_tp: 190.0000\n",
      "Epoch 55/500\n",
      "3/3 - 1s - 344ms/step - accuracy: 0.9273 - auc: 0.9844 - categorical_accuracy: 0.9273 - f1_score: 0.9276 - fn: 323.0000 - fp: 313.0000 - loss: 0.2804 - precision: 0.9283 - recall: 0.9262 - tn: 8441.0000 - tp: 4054.0000 - val_accuracy: 0.8008 - val_auc: 0.9080 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.6866 - val_fn: 52.0000 - val_fp: 49.0000 - val_loss: 0.6341 - val_precision: 0.7984 - val_recall: 0.7886 - val_tn: 443.0000 - val_tp: 194.0000\n",
      "Epoch 56/500\n",
      "3/3 - 1s - 184ms/step - accuracy: 0.9273 - auc: 0.9846 - categorical_accuracy: 0.9273 - f1_score: 0.9273 - fn: 326.0000 - fp: 308.0000 - loss: 0.2740 - precision: 0.9293 - recall: 0.9255 - tn: 8446.0000 - tp: 4051.0000 - val_accuracy: 0.8089 - val_auc: 0.9173 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7136 - val_fn: 49.0000 - val_fp: 42.0000 - val_loss: 0.6069 - val_precision: 0.8243 - val_recall: 0.8008 - val_tn: 450.0000 - val_tp: 197.0000\n",
      "Epoch 57/500\n",
      "3/3 - 1s - 168ms/step - accuracy: 0.9283 - auc: 0.9844 - categorical_accuracy: 0.9283 - f1_score: 0.9280 - fn: 320.0000 - fp: 305.0000 - loss: 0.2735 - precision: 0.9301 - recall: 0.9269 - tn: 8449.0000 - tp: 4057.0000 - val_accuracy: 0.7724 - val_auc: 0.9059 - val_categorical_accuracy: 0.7724 - val_f1_score: 0.6190 - val_fn: 56.0000 - val_fp: 56.0000 - val_loss: 0.6475 - val_precision: 0.7724 - val_recall: 0.7724 - val_tn: 436.0000 - val_tp: 190.0000\n",
      "Epoch 58/500\n",
      "3/3 - 1s - 229ms/step - accuracy: 0.9289 - auc: 0.9849 - categorical_accuracy: 0.9289 - f1_score: 0.9293 - fn: 314.0000 - fp: 307.0000 - loss: 0.2712 - precision: 0.9297 - recall: 0.9283 - tn: 8447.0000 - tp: 4063.0000 - val_accuracy: 0.8333 - val_auc: 0.9309 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7566 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5512 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 59/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.9299 - auc: 0.9851 - categorical_accuracy: 0.9299 - f1_score: 0.9299 - fn: 321.0000 - fp: 297.0000 - loss: 0.2699 - precision: 0.9318 - recall: 0.9267 - tn: 8457.0000 - tp: 4056.0000 - val_accuracy: 0.7764 - val_auc: 0.8961 - val_categorical_accuracy: 0.7764 - val_f1_score: 0.6178 - val_fn: 57.0000 - val_fp: 53.0000 - val_loss: 0.6727 - val_precision: 0.7810 - val_recall: 0.7683 - val_tn: 439.0000 - val_tp: 189.0000\n",
      "Epoch 60/500\n",
      "3/3 - 0s - 147ms/step - accuracy: 0.9294 - auc: 0.9860 - categorical_accuracy: 0.9294 - f1_score: 0.9297 - fn: 323.0000 - fp: 303.0000 - loss: 0.2739 - precision: 0.9305 - recall: 0.9262 - tn: 8451.0000 - tp: 4054.0000 - val_accuracy: 0.8333 - val_auc: 0.9317 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7542 - val_fn: 42.0000 - val_fp: 37.0000 - val_loss: 0.5403 - val_precision: 0.8465 - val_recall: 0.8293 - val_tn: 455.0000 - val_tp: 204.0000\n",
      "Epoch 61/500\n",
      "3/3 - 0s - 145ms/step - accuracy: 0.9289 - auc: 0.9854 - categorical_accuracy: 0.9289 - f1_score: 0.9291 - fn: 317.0000 - fp: 305.0000 - loss: 0.2687 - precision: 0.9301 - recall: 0.9276 - tn: 8449.0000 - tp: 4060.0000 - val_accuracy: 0.8049 - val_auc: 0.9228 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7019 - val_fn: 48.0000 - val_fp: 48.0000 - val_loss: 0.5814 - val_precision: 0.8049 - val_recall: 0.8049 - val_tn: 444.0000 - val_tp: 198.0000\n",
      "Epoch 62/500\n",
      "3/3 - 1s - 245ms/step - accuracy: 0.9241 - auc: 0.9839 - categorical_accuracy: 0.9241 - f1_score: 0.9241 - fn: 332.0000 - fp: 328.0000 - loss: 0.2778 - precision: 0.9250 - recall: 0.9241 - tn: 8426.0000 - tp: 4045.0000 - val_accuracy: 0.7683 - val_auc: 0.9078 - val_categorical_accuracy: 0.7683 - val_f1_score: 0.5979 - val_fn: 58.0000 - val_fp: 57.0000 - val_loss: 0.6291 - val_precision: 0.7673 - val_recall: 0.7642 - val_tn: 435.0000 - val_tp: 188.0000\n",
      "Epoch 63/500\n",
      "3/3 - 1s - 216ms/step - accuracy: 0.9271 - auc: 0.9858 - categorical_accuracy: 0.9271 - f1_score: 0.9272 - fn: 329.0000 - fp: 315.0000 - loss: 0.2649 - precision: 0.9278 - recall: 0.9248 - tn: 8439.0000 - tp: 4048.0000 - val_accuracy: 0.8374 - val_auc: 0.9309 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7665 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5369 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 64/500\n",
      "3/3 - 1s - 207ms/step - accuracy: 0.9276 - auc: 0.9853 - categorical_accuracy: 0.9276 - f1_score: 0.9276 - fn: 320.0000 - fp: 315.0000 - loss: 0.2648 - precision: 0.9280 - recall: 0.9269 - tn: 8439.0000 - tp: 4057.0000 - val_accuracy: 0.8008 - val_auc: 0.9143 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.6896 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.6027 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 65/500\n",
      "3/3 - 1s - 226ms/step - accuracy: 0.9301 - auc: 0.9859 - categorical_accuracy: 0.9301 - f1_score: 0.9303 - fn: 314.0000 - fp: 300.0000 - loss: 0.2589 - precision: 0.9312 - recall: 0.9283 - tn: 8454.0000 - tp: 4063.0000 - val_accuracy: 0.8333 - val_auc: 0.9262 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7542 - val_fn: 43.0000 - val_fp: 40.0000 - val_loss: 0.5621 - val_precision: 0.8354 - val_recall: 0.8252 - val_tn: 452.0000 - val_tp: 203.0000\n",
      "Epoch 66/500\n",
      "3/3 - 1s - 175ms/step - accuracy: 0.9223 - auc: 0.9859 - categorical_accuracy: 0.9223 - f1_score: 0.9224 - fn: 342.0000 - fp: 332.0000 - loss: 0.2593 - precision: 0.9240 - recall: 0.9219 - tn: 8422.0000 - tp: 4035.0000 - val_accuracy: 0.8008 - val_auc: 0.9151 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.6892 - val_fn: 49.0000 - val_fp: 46.0000 - val_loss: 0.6110 - val_precision: 0.8107 - val_recall: 0.8008 - val_tn: 446.0000 - val_tp: 197.0000\n",
      "Epoch 67/500\n",
      "3/3 - 1s - 171ms/step - accuracy: 0.9269 - auc: 0.9852 - categorical_accuracy: 0.9269 - f1_score: 0.9269 - fn: 329.0000 - fp: 311.0000 - loss: 0.2624 - precision: 0.9287 - recall: 0.9248 - tn: 8443.0000 - tp: 4048.0000 - val_accuracy: 0.8293 - val_auc: 0.9325 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7467 - val_fn: 43.0000 - val_fp: 41.0000 - val_loss: 0.5362 - val_precision: 0.8320 - val_recall: 0.8252 - val_tn: 451.0000 - val_tp: 203.0000\n",
      "Epoch 68/500\n",
      "3/3 - 1s - 191ms/step - accuracy: 0.9253 - auc: 0.9844 - categorical_accuracy: 0.9253 - f1_score: 0.9251 - fn: 336.0000 - fp: 314.0000 - loss: 0.2679 - precision: 0.9279 - recall: 0.9232 - tn: 8440.0000 - tp: 4041.0000 - val_accuracy: 0.7846 - val_auc: 0.9124 - val_categorical_accuracy: 0.7846 - val_f1_score: 0.6415 - val_fn: 53.0000 - val_fp: 53.0000 - val_loss: 0.6163 - val_precision: 0.7846 - val_recall: 0.7846 - val_tn: 439.0000 - val_tp: 193.0000\n",
      "Epoch 69/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9269 - auc: 0.9851 - categorical_accuracy: 0.9269 - f1_score: 0.9275 - fn: 328.0000 - fp: 316.0000 - loss: 0.2678 - precision: 0.9276 - recall: 0.9251 - tn: 8438.0000 - tp: 4049.0000 - val_accuracy: 0.8333 - val_auc: 0.9286 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7569 - val_fn: 42.0000 - val_fp: 38.0000 - val_loss: 0.5630 - val_precision: 0.8430 - val_recall: 0.8293 - val_tn: 454.0000 - val_tp: 204.0000\n",
      "Epoch 70/500\n",
      "3/3 - 0s - 163ms/step - accuracy: 0.9262 - auc: 0.9852 - categorical_accuracy: 0.9262 - f1_score: 0.9262 - fn: 329.0000 - fp: 316.0000 - loss: 0.2605 - precision: 0.9276 - recall: 0.9248 - tn: 8438.0000 - tp: 4048.0000 - val_accuracy: 0.8293 - val_auc: 0.9292 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7468 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5601 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 71/500\n",
      "3/3 - 1s - 226ms/step - accuracy: 0.9308 - auc: 0.9853 - categorical_accuracy: 0.9308 - f1_score: 0.9309 - fn: 308.0000 - fp: 297.0000 - loss: 0.2618 - precision: 0.9320 - recall: 0.9296 - tn: 8457.0000 - tp: 4069.0000 - val_accuracy: 0.8171 - val_auc: 0.9262 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7263 - val_fn: 48.0000 - val_fp: 44.0000 - val_loss: 0.5609 - val_precision: 0.8182 - val_recall: 0.8049 - val_tn: 448.0000 - val_tp: 198.0000\n",
      "Epoch 72/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9276 - auc: 0.9859 - categorical_accuracy: 0.9276 - f1_score: 0.9275 - fn: 326.0000 - fp: 307.0000 - loss: 0.2553 - precision: 0.9296 - recall: 0.9255 - tn: 8447.0000 - tp: 4051.0000 - val_accuracy: 0.8293 - val_auc: 0.9307 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7495 - val_fn: 43.0000 - val_fp: 41.0000 - val_loss: 0.5386 - val_precision: 0.8320 - val_recall: 0.8252 - val_tn: 451.0000 - val_tp: 203.0000\n",
      "Epoch 73/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.9296 - auc: 0.9853 - categorical_accuracy: 0.9296 - f1_score: 0.9298 - fn: 313.0000 - fp: 303.0000 - loss: 0.2554 - precision: 0.9306 - recall: 0.9285 - tn: 8451.0000 - tp: 4064.0000 - val_accuracy: 0.8211 - val_auc: 0.9219 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7376 - val_fn: 47.0000 - val_fp: 43.0000 - val_loss: 0.5709 - val_precision: 0.8223 - val_recall: 0.8089 - val_tn: 449.0000 - val_tp: 199.0000\n",
      "Epoch 74/500\n",
      "3/3 - 0s - 162ms/step - accuracy: 0.9299 - auc: 0.9859 - categorical_accuracy: 0.9299 - f1_score: 0.9299 - fn: 309.0000 - fp: 299.0000 - loss: 0.2519 - precision: 0.9315 - recall: 0.9294 - tn: 8455.0000 - tp: 4068.0000 - val_accuracy: 0.8293 - val_auc: 0.9324 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7467 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5349 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 75/500\n",
      "3/3 - 1s - 209ms/step - accuracy: 0.9276 - auc: 0.9863 - categorical_accuracy: 0.9276 - f1_score: 0.9276 - fn: 321.0000 - fp: 307.0000 - loss: 0.2503 - precision: 0.9296 - recall: 0.9267 - tn: 8447.0000 - tp: 4056.0000 - val_accuracy: 0.7846 - val_auc: 0.9132 - val_categorical_accuracy: 0.7846 - val_f1_score: 0.6471 - val_fn: 53.0000 - val_fp: 52.0000 - val_loss: 0.6034 - val_precision: 0.7878 - val_recall: 0.7846 - val_tn: 440.0000 - val_tp: 193.0000\n",
      "Epoch 76/500\n",
      "3/3 - 1s - 181ms/step - accuracy: 0.9244 - auc: 0.9850 - categorical_accuracy: 0.9244 - f1_score: 0.9246 - fn: 343.0000 - fp: 327.0000 - loss: 0.2639 - precision: 0.9250 - recall: 0.9216 - tn: 8427.0000 - tp: 4034.0000 - val_accuracy: 0.8374 - val_auc: 0.9287 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7636 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5494 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 77/500\n",
      "3/3 - 0s - 160ms/step - accuracy: 0.9287 - auc: 0.9852 - categorical_accuracy: 0.9287 - f1_score: 0.9290 - fn: 316.0000 - fp: 310.0000 - loss: 0.2587 - precision: 0.9291 - recall: 0.9278 - tn: 8444.0000 - tp: 4061.0000 - val_accuracy: 0.8455 - val_auc: 0.9256 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7759 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5572 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 78/500\n",
      "3/3 - 0s - 149ms/step - accuracy: 0.9283 - auc: 0.9861 - categorical_accuracy: 0.9283 - f1_score: 0.9287 - fn: 324.0000 - fp: 308.0000 - loss: 0.2559 - precision: 0.9294 - recall: 0.9260 - tn: 8446.0000 - tp: 4053.0000 - val_accuracy: 0.8455 - val_auc: 0.9358 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7789 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5272 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 79/500\n",
      "3/3 - 1s - 173ms/step - accuracy: 0.9257 - auc: 0.9857 - categorical_accuracy: 0.9257 - f1_score: 0.9260 - fn: 330.0000 - fp: 319.0000 - loss: 0.2591 - precision: 0.9269 - recall: 0.9246 - tn: 8435.0000 - tp: 4047.0000 - val_accuracy: 0.8537 - val_auc: 0.9355 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7976 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5318 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 80/500\n",
      "3/3 - 1s - 167ms/step - accuracy: 0.9292 - auc: 0.9853 - categorical_accuracy: 0.9292 - f1_score: 0.9291 - fn: 314.0000 - fp: 305.0000 - loss: 0.2591 - precision: 0.9302 - recall: 0.9283 - tn: 8449.0000 - tp: 4063.0000 - val_accuracy: 0.8293 - val_auc: 0.9259 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7519 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.5612 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 81/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9264 - auc: 0.9862 - categorical_accuracy: 0.9264 - f1_score: 0.9268 - fn: 327.0000 - fp: 314.0000 - loss: 0.2571 - precision: 0.9280 - recall: 0.9253 - tn: 8440.0000 - tp: 4050.0000 - val_accuracy: 0.8415 - val_auc: 0.9365 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7715 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5231 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 82/500\n",
      "3/3 - 0s - 135ms/step - accuracy: 0.9251 - auc: 0.9850 - categorical_accuracy: 0.9251 - f1_score: 0.9249 - fn: 336.0000 - fp: 324.0000 - loss: 0.2584 - precision: 0.9258 - recall: 0.9232 - tn: 8430.0000 - tp: 4041.0000 - val_accuracy: 0.8415 - val_auc: 0.9352 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7696 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5130 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 83/500\n",
      "3/3 - 1s - 223ms/step - accuracy: 0.9285 - auc: 0.9850 - categorical_accuracy: 0.9285 - f1_score: 0.9288 - fn: 318.0000 - fp: 308.0000 - loss: 0.2565 - precision: 0.9295 - recall: 0.9273 - tn: 8446.0000 - tp: 4059.0000 - val_accuracy: 0.8415 - val_auc: 0.9269 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7712 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5502 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 84/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9278 - auc: 0.9859 - categorical_accuracy: 0.9278 - f1_score: 0.9278 - fn: 322.0000 - fp: 313.0000 - loss: 0.2536 - precision: 0.9283 - recall: 0.9264 - tn: 8441.0000 - tp: 4055.0000 - val_accuracy: 0.8455 - val_auc: 0.9389 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7789 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5057 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 85/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9239 - auc: 0.9846 - categorical_accuracy: 0.9239 - f1_score: 0.9242 - fn: 346.0000 - fp: 324.0000 - loss: 0.2658 - precision: 0.9256 - recall: 0.9210 - tn: 8430.0000 - tp: 4031.0000 - val_accuracy: 0.8537 - val_auc: 0.9381 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7959 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5107 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 86/500\n",
      "3/3 - 0s - 152ms/step - accuracy: 0.9301 - auc: 0.9856 - categorical_accuracy: 0.9301 - f1_score: 0.9300 - fn: 323.0000 - fp: 297.0000 - loss: 0.2582 - precision: 0.9317 - recall: 0.9262 - tn: 8457.0000 - tp: 4054.0000 - val_accuracy: 0.8374 - val_auc: 0.9380 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7797 - val_fn: 41.0000 - val_fp: 38.0000 - val_loss: 0.5141 - val_precision: 0.8436 - val_recall: 0.8333 - val_tn: 454.0000 - val_tp: 205.0000\n",
      "Epoch 87/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9253 - auc: 0.9832 - categorical_accuracy: 0.9253 - f1_score: 0.9253 - fn: 333.0000 - fp: 320.0000 - loss: 0.2693 - precision: 0.9267 - recall: 0.9239 - tn: 8434.0000 - tp: 4044.0000 - val_accuracy: 0.8659 - val_auc: 0.9428 - val_categorical_accuracy: 0.8659 - val_f1_score: 0.8135 - val_fn: 34.0000 - val_fp: 33.0000 - val_loss: 0.4987 - val_precision: 0.8653 - val_recall: 0.8618 - val_tn: 459.0000 - val_tp: 212.0000\n",
      "Epoch 88/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9280 - auc: 0.9846 - categorical_accuracy: 0.9280 - f1_score: 0.9281 - fn: 320.0000 - fp: 309.0000 - loss: 0.2603 - precision: 0.9292 - recall: 0.9269 - tn: 8445.0000 - tp: 4057.0000 - val_accuracy: 0.7967 - val_auc: 0.9134 - val_categorical_accuracy: 0.7967 - val_f1_score: 0.7528 - val_fn: 54.0000 - val_fp: 48.0000 - val_loss: 0.6153 - val_precision: 0.8000 - val_recall: 0.7805 - val_tn: 444.0000 - val_tp: 192.0000\n",
      "Epoch 89/500\n",
      "3/3 - 0s - 135ms/step - accuracy: 0.9205 - auc: 0.9833 - categorical_accuracy: 0.9205 - f1_score: 0.9196 - fn: 352.0000 - fp: 344.0000 - loss: 0.2718 - precision: 0.9213 - recall: 0.9196 - tn: 8410.0000 - tp: 4025.0000 - val_accuracy: 0.8537 - val_auc: 0.9364 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7969 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5051 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 90/500\n",
      "3/3 - 0s - 150ms/step - accuracy: 0.9260 - auc: 0.9841 - categorical_accuracy: 0.9260 - f1_score: 0.9263 - fn: 326.0000 - fp: 323.0000 - loss: 0.2665 - precision: 0.9262 - recall: 0.9255 - tn: 8431.0000 - tp: 4051.0000 - val_accuracy: 0.8496 - val_auc: 0.9280 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7878 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5690 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 91/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9232 - auc: 0.9849 - categorical_accuracy: 0.9232 - f1_score: 0.9238 - fn: 340.0000 - fp: 325.0000 - loss: 0.2651 - precision: 0.9255 - recall: 0.9223 - tn: 8429.0000 - tp: 4037.0000 - val_accuracy: 0.8537 - val_auc: 0.9358 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7907 - val_fn: 36.0000 - val_fp: 34.0000 - val_loss: 0.5368 - val_precision: 0.8607 - val_recall: 0.8537 - val_tn: 458.0000 - val_tp: 210.0000\n",
      "Epoch 92/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9287 - auc: 0.9839 - categorical_accuracy: 0.9287 - f1_score: 0.9290 - fn: 323.0000 - fp: 310.0000 - loss: 0.2632 - precision: 0.9290 - recall: 0.9262 - tn: 8444.0000 - tp: 4054.0000 - val_accuracy: 0.8374 - val_auc: 0.9331 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7720 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5485 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 93/500\n",
      "3/3 - 0s - 149ms/step - accuracy: 0.9210 - auc: 0.9851 - categorical_accuracy: 0.9210 - f1_score: 0.9212 - fn: 368.0000 - fp: 327.0000 - loss: 0.2630 - precision: 0.9246 - recall: 0.9159 - tn: 8427.0000 - tp: 4009.0000 - val_accuracy: 0.8252 - val_auc: 0.9321 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7753 - val_fn: 46.0000 - val_fp: 39.0000 - val_loss: 0.5368 - val_precision: 0.8368 - val_recall: 0.8130 - val_tn: 453.0000 - val_tp: 200.0000\n",
      "Epoch 94/500\n",
      "3/3 - 0s - 134ms/step - accuracy: 0.9239 - auc: 0.9856 - categorical_accuracy: 0.9239 - f1_score: 0.9234 - fn: 346.0000 - fp: 317.0000 - loss: 0.2569 - precision: 0.9271 - recall: 0.9210 - tn: 8437.0000 - tp: 4031.0000 - val_accuracy: 0.8415 - val_auc: 0.9342 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7835 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5158 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 95/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9267 - auc: 0.9843 - categorical_accuracy: 0.9267 - f1_score: 0.9270 - fn: 326.0000 - fp: 308.0000 - loss: 0.2602 - precision: 0.9293 - recall: 0.9255 - tn: 8446.0000 - tp: 4051.0000 - val_accuracy: 0.8252 - val_auc: 0.9300 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7698 - val_fn: 44.0000 - val_fp: 42.0000 - val_loss: 0.5468 - val_precision: 0.8279 - val_recall: 0.8211 - val_tn: 450.0000 - val_tp: 202.0000\n",
      "Epoch 96/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9273 - auc: 0.9839 - categorical_accuracy: 0.9273 - f1_score: 0.9270 - fn: 333.0000 - fp: 315.0000 - loss: 0.2625 - precision: 0.9277 - recall: 0.9239 - tn: 8439.0000 - tp: 4044.0000 - val_accuracy: 0.8455 - val_auc: 0.9290 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7901 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.5412 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 97/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9280 - auc: 0.9861 - categorical_accuracy: 0.9280 - f1_score: 0.9283 - fn: 328.0000 - fp: 304.0000 - loss: 0.2511 - precision: 0.9302 - recall: 0.9251 - tn: 8450.0000 - tp: 4049.0000 - val_accuracy: 0.8496 - val_auc: 0.9322 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7888 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5317 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 98/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9292 - auc: 0.9854 - categorical_accuracy: 0.9292 - f1_score: 0.9294 - fn: 314.0000 - fp: 307.0000 - loss: 0.2539 - precision: 0.9297 - recall: 0.9283 - tn: 8447.0000 - tp: 4063.0000 - val_accuracy: 0.8496 - val_auc: 0.9300 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7956 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5507 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 99/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9262 - auc: 0.9846 - categorical_accuracy: 0.9262 - f1_score: 0.9261 - fn: 328.0000 - fp: 317.0000 - loss: 0.2621 - precision: 0.9274 - recall: 0.9251 - tn: 8437.0000 - tp: 4049.0000 - val_accuracy: 0.8333 - val_auc: 0.9333 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7775 - val_fn: 43.0000 - val_fp: 39.0000 - val_loss: 0.5398 - val_precision: 0.8388 - val_recall: 0.8252 - val_tn: 453.0000 - val_tp: 203.0000\n",
      "Epoch 100/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9260 - auc: 0.9848 - categorical_accuracy: 0.9260 - f1_score: 0.9257 - fn: 336.0000 - fp: 312.0000 - loss: 0.2670 - precision: 0.9283 - recall: 0.9232 - tn: 8442.0000 - tp: 4041.0000 - val_accuracy: 0.8455 - val_auc: 0.9366 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7844 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5143 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 101/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9228 - auc: 0.9826 - categorical_accuracy: 0.9228 - f1_score: 0.9227 - fn: 344.0000 - fp: 334.0000 - loss: 0.2813 - precision: 0.9235 - recall: 0.9214 - tn: 8420.0000 - tp: 4033.0000 - val_accuracy: 0.8415 - val_auc: 0.9342 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7776 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5300 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 102/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9310 - auc: 0.9846 - categorical_accuracy: 0.9310 - f1_score: 0.9313 - fn: 311.0000 - fp: 295.0000 - loss: 0.2581 - precision: 0.9324 - recall: 0.9289 - tn: 8459.0000 - tp: 4066.0000 - val_accuracy: 0.8333 - val_auc: 0.9171 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7682 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.5931 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 103/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9253 - auc: 0.9841 - categorical_accuracy: 0.9253 - f1_score: 0.9258 - fn: 333.0000 - fp: 324.0000 - loss: 0.2652 - precision: 0.9258 - recall: 0.9239 - tn: 8430.0000 - tp: 4044.0000 - val_accuracy: 0.8455 - val_auc: 0.9335 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7793 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5284 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 104/500\n",
      "3/3 - 0s - 134ms/step - accuracy: 0.9276 - auc: 0.9835 - categorical_accuracy: 0.9276 - f1_score: 0.9277 - fn: 324.0000 - fp: 315.0000 - loss: 0.2642 - precision: 0.9279 - recall: 0.9260 - tn: 8439.0000 - tp: 4053.0000 - val_accuracy: 0.8455 - val_auc: 0.9344 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7864 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5162 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 105/500\n",
      "3/3 - 1s - 188ms/step - accuracy: 0.9264 - auc: 0.9861 - categorical_accuracy: 0.9264 - f1_score: 0.9262 - fn: 327.0000 - fp: 318.0000 - loss: 0.2489 - precision: 0.9272 - recall: 0.9253 - tn: 8436.0000 - tp: 4050.0000 - val_accuracy: 0.8374 - val_auc: 0.9268 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7821 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5404 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 106/500\n",
      "3/3 - 0s - 132ms/step - accuracy: 0.9310 - auc: 0.9852 - categorical_accuracy: 0.9310 - f1_score: 0.9311 - fn: 311.0000 - fp: 296.0000 - loss: 0.2502 - precision: 0.9321 - recall: 0.9289 - tn: 8458.0000 - tp: 4066.0000 - val_accuracy: 0.8496 - val_auc: 0.9354 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7924 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5036 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 107/500\n",
      "3/3 - 0s - 129ms/step - accuracy: 0.9230 - auc: 0.9846 - categorical_accuracy: 0.9230 - f1_score: 0.9230 - fn: 339.0000 - fp: 330.0000 - loss: 0.2564 - precision: 0.9245 - recall: 0.9225 - tn: 8424.0000 - tp: 4038.0000 - val_accuracy: 0.8455 - val_auc: 0.9327 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7846 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5270 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 108/500\n",
      "3/3 - 0s - 155ms/step - accuracy: 0.9273 - auc: 0.9855 - categorical_accuracy: 0.9273 - f1_score: 0.9273 - fn: 327.0000 - fp: 305.0000 - loss: 0.2527 - precision: 0.9300 - recall: 0.9253 - tn: 8449.0000 - tp: 4050.0000 - val_accuracy: 0.8374 - val_auc: 0.9269 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7821 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5604 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 109/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9303 - auc: 0.9841 - categorical_accuracy: 0.9303 - f1_score: 0.9304 - fn: 313.0000 - fp: 293.0000 - loss: 0.2546 - precision: 0.9328 - recall: 0.9285 - tn: 8461.0000 - tp: 4064.0000 - val_accuracy: 0.8496 - val_auc: 0.9295 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7917 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5375 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 110/500\n",
      "3/3 - 1s - 168ms/step - accuracy: 0.9294 - auc: 0.9859 - categorical_accuracy: 0.9294 - f1_score: 0.9296 - fn: 315.0000 - fp: 299.0000 - loss: 0.2457 - precision: 0.9314 - recall: 0.9280 - tn: 8455.0000 - tp: 4062.0000 - val_accuracy: 0.8252 - val_auc: 0.9313 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7700 - val_fn: 46.0000 - val_fp: 40.0000 - val_loss: 0.5519 - val_precision: 0.8333 - val_recall: 0.8130 - val_tn: 452.0000 - val_tp: 200.0000\n",
      "Epoch 111/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9230 - auc: 0.9853 - categorical_accuracy: 0.9230 - f1_score: 0.9222 - fn: 349.0000 - fp: 321.0000 - loss: 0.2539 - precision: 0.9262 - recall: 0.9203 - tn: 8433.0000 - tp: 4028.0000 - val_accuracy: 0.8496 - val_auc: 0.9376 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7924 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5012 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 112/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9299 - auc: 0.9857 - categorical_accuracy: 0.9299 - f1_score: 0.9300 - fn: 313.0000 - fp: 300.0000 - loss: 0.2453 - precision: 0.9313 - recall: 0.9285 - tn: 8454.0000 - tp: 4064.0000 - val_accuracy: 0.8496 - val_auc: 0.9369 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7913 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5051 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 113/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9273 - auc: 0.9844 - categorical_accuracy: 0.9273 - f1_score: 0.9276 - fn: 326.0000 - fp: 312.0000 - loss: 0.2541 - precision: 0.9285 - recall: 0.9255 - tn: 8442.0000 - tp: 4051.0000 - val_accuracy: 0.8415 - val_auc: 0.9332 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7855 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5326 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 114/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9244 - auc: 0.9862 - categorical_accuracy: 0.9244 - f1_score: 0.9244 - fn: 337.0000 - fp: 323.0000 - loss: 0.2457 - precision: 0.9260 - recall: 0.9230 - tn: 8431.0000 - tp: 4040.0000 - val_accuracy: 0.8496 - val_auc: 0.9322 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7895 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5131 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 115/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9287 - auc: 0.9857 - categorical_accuracy: 0.9287 - f1_score: 0.9289 - fn: 320.0000 - fp: 311.0000 - loss: 0.2511 - precision: 0.9288 - recall: 0.9269 - tn: 8443.0000 - tp: 4057.0000 - val_accuracy: 0.8496 - val_auc: 0.9366 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7888 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5009 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 116/500\n",
      "3/3 - 0s - 132ms/step - accuracy: 0.9308 - auc: 0.9860 - categorical_accuracy: 0.9308 - f1_score: 0.9309 - fn: 308.0000 - fp: 302.0000 - loss: 0.2428 - precision: 0.9309 - recall: 0.9296 - tn: 8452.0000 - tp: 4069.0000 - val_accuracy: 0.8415 - val_auc: 0.9291 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7861 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5478 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 117/500\n",
      "3/3 - 0s - 134ms/step - accuracy: 0.9264 - auc: 0.9851 - categorical_accuracy: 0.9264 - f1_score: 0.9262 - fn: 326.0000 - fp: 319.0000 - loss: 0.2461 - precision: 0.9270 - recall: 0.9255 - tn: 8435.0000 - tp: 4051.0000 - val_accuracy: 0.8537 - val_auc: 0.9363 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7959 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5042 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 118/500\n",
      "3/3 - 0s - 135ms/step - accuracy: 0.9324 - auc: 0.9856 - categorical_accuracy: 0.9324 - f1_score: 0.9324 - fn: 302.0000 - fp: 291.0000 - loss: 0.2430 - precision: 0.9333 - recall: 0.9310 - tn: 8463.0000 - tp: 4075.0000 - val_accuracy: 0.8496 - val_auc: 0.9390 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7863 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.4897 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 119/500\n",
      "3/3 - 0s - 162ms/step - accuracy: 0.9273 - auc: 0.9862 - categorical_accuracy: 0.9273 - f1_score: 0.9274 - fn: 323.0000 - fp: 314.0000 - loss: 0.2423 - precision: 0.9281 - recall: 0.9262 - tn: 8440.0000 - tp: 4054.0000 - val_accuracy: 0.8455 - val_auc: 0.9352 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7759 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5077 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 120/500\n",
      "3/3 - 1s - 273ms/step - accuracy: 0.9269 - auc: 0.9855 - categorical_accuracy: 0.9269 - f1_score: 0.9275 - fn: 324.0000 - fp: 307.0000 - loss: 0.2480 - precision: 0.9296 - recall: 0.9260 - tn: 8447.0000 - tp: 4053.0000 - val_accuracy: 0.8537 - val_auc: 0.9366 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7959 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5094 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 121/500\n",
      "3/3 - 1s - 198ms/step - accuracy: 0.9255 - auc: 0.9856 - categorical_accuracy: 0.9255 - f1_score: 0.9253 - fn: 331.0000 - fp: 316.0000 - loss: 0.2458 - precision: 0.9276 - recall: 0.9244 - tn: 8438.0000 - tp: 4046.0000 - val_accuracy: 0.8415 - val_auc: 0.9352 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7861 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5098 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 122/500\n",
      "3/3 - 1s - 171ms/step - accuracy: 0.9310 - auc: 0.9864 - categorical_accuracy: 0.9310 - f1_score: 0.9312 - fn: 309.0000 - fp: 299.0000 - loss: 0.2394 - precision: 0.9315 - recall: 0.9294 - tn: 8455.0000 - tp: 4068.0000 - val_accuracy: 0.8496 - val_auc: 0.9369 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7931 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.5029 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 123/500\n",
      "3/3 - 1s - 168ms/step - accuracy: 0.9241 - auc: 0.9850 - categorical_accuracy: 0.9241 - f1_score: 0.9241 - fn: 335.0000 - fp: 327.0000 - loss: 0.2529 - precision: 0.9252 - recall: 0.9235 - tn: 8427.0000 - tp: 4042.0000 - val_accuracy: 0.8496 - val_auc: 0.9330 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7913 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5146 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 124/500\n",
      "3/3 - 0s - 155ms/step - accuracy: 0.9280 - auc: 0.9844 - categorical_accuracy: 0.9280 - f1_score: 0.9284 - fn: 322.0000 - fp: 309.0000 - loss: 0.2569 - precision: 0.9292 - recall: 0.9264 - tn: 8445.0000 - tp: 4055.0000 - val_accuracy: 0.8455 - val_auc: 0.9293 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7871 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5554 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 125/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9321 - auc: 0.9865 - categorical_accuracy: 0.9321 - f1_score: 0.9323 - fn: 303.0000 - fp: 292.0000 - loss: 0.2417 - precision: 0.9331 - recall: 0.9308 - tn: 8462.0000 - tp: 4074.0000 - val_accuracy: 0.8333 - val_auc: 0.9256 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7820 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5863 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 126/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9241 - auc: 0.9845 - categorical_accuracy: 0.9241 - f1_score: 0.9237 - fn: 345.0000 - fp: 325.0000 - loss: 0.2527 - precision: 0.9254 - recall: 0.9212 - tn: 8429.0000 - tp: 4032.0000 - val_accuracy: 0.8211 - val_auc: 0.9335 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7722 - val_fn: 46.0000 - val_fp: 41.0000 - val_loss: 0.5215 - val_precision: 0.8299 - val_recall: 0.8130 - val_tn: 451.0000 - val_tp: 200.0000\n",
      "Epoch 127/500\n",
      "3/3 - 0s - 151ms/step - accuracy: 0.9212 - auc: 0.9866 - categorical_accuracy: 0.9212 - f1_score: 0.9207 - fn: 357.0000 - fp: 329.0000 - loss: 0.2499 - precision: 0.9244 - recall: 0.9184 - tn: 8425.0000 - tp: 4020.0000 - val_accuracy: 0.8496 - val_auc: 0.9377 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7924 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5087 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 128/500\n",
      "3/3 - 0s - 162ms/step - accuracy: 0.9271 - auc: 0.9862 - categorical_accuracy: 0.9271 - f1_score: 0.9275 - fn: 324.0000 - fp: 310.0000 - loss: 0.2427 - precision: 0.9289 - recall: 0.9260 - tn: 8444.0000 - tp: 4053.0000 - val_accuracy: 0.8455 - val_auc: 0.9328 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7835 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5407 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 129/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9283 - auc: 0.9850 - categorical_accuracy: 0.9283 - f1_score: 0.9287 - fn: 316.0000 - fp: 310.0000 - loss: 0.2540 - precision: 0.9291 - recall: 0.9278 - tn: 8444.0000 - tp: 4061.0000 - val_accuracy: 0.8537 - val_auc: 0.9313 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7983 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5542 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 130/500\n",
      "3/3 - 1s - 200ms/step - accuracy: 0.9296 - auc: 0.9853 - categorical_accuracy: 0.9296 - f1_score: 0.9298 - fn: 309.0000 - fp: 305.0000 - loss: 0.2486 - precision: 0.9303 - recall: 0.9294 - tn: 8449.0000 - tp: 4068.0000 - val_accuracy: 0.8496 - val_auc: 0.9360 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7808 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5117 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 131/500\n",
      "3/3 - 0s - 154ms/step - accuracy: 0.9278 - auc: 0.9839 - categorical_accuracy: 0.9278 - f1_score: 0.9282 - fn: 322.0000 - fp: 307.0000 - loss: 0.2600 - precision: 0.9296 - recall: 0.9264 - tn: 8447.0000 - tp: 4055.0000 - val_accuracy: 0.8252 - val_auc: 0.9279 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7656 - val_fn: 44.0000 - val_fp: 43.0000 - val_loss: 0.5816 - val_precision: 0.8245 - val_recall: 0.8211 - val_tn: 449.0000 - val_tp: 202.0000\n",
      "Epoch 132/500\n",
      "3/3 - 0s - 159ms/step - accuracy: 0.9257 - auc: 0.9840 - categorical_accuracy: 0.9257 - f1_score: 0.9256 - fn: 327.0000 - fp: 321.0000 - loss: 0.2588 - precision: 0.9266 - recall: 0.9253 - tn: 8433.0000 - tp: 4050.0000 - val_accuracy: 0.8455 - val_auc: 0.9351 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7815 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5130 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 133/500\n",
      "3/3 - 0s - 159ms/step - accuracy: 0.9280 - auc: 0.9848 - categorical_accuracy: 0.9280 - f1_score: 0.9283 - fn: 321.0000 - fp: 303.0000 - loss: 0.2568 - precision: 0.9305 - recall: 0.9267 - tn: 8451.0000 - tp: 4056.0000 - val_accuracy: 0.8496 - val_auc: 0.9357 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7906 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5037 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 134/500\n",
      "3/3 - 1s - 248ms/step - accuracy: 0.9262 - auc: 0.9865 - categorical_accuracy: 0.9262 - f1_score: 0.9261 - fn: 331.0000 - fp: 309.0000 - loss: 0.2448 - precision: 0.9290 - recall: 0.9244 - tn: 8445.0000 - tp: 4046.0000 - val_accuracy: 0.8374 - val_auc: 0.9277 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7863 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5740 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 135/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9264 - auc: 0.9848 - categorical_accuracy: 0.9264 - f1_score: 0.9263 - fn: 326.0000 - fp: 321.0000 - loss: 0.2552 - precision: 0.9266 - recall: 0.9255 - tn: 8433.0000 - tp: 4051.0000 - val_accuracy: 0.8455 - val_auc: 0.9368 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7863 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5105 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 136/500\n",
      "3/3 - 0s - 161ms/step - accuracy: 0.9331 - auc: 0.9858 - categorical_accuracy: 0.9331 - f1_score: 0.9332 - fn: 304.0000 - fp: 289.0000 - loss: 0.2424 - precision: 0.9337 - recall: 0.9305 - tn: 8465.0000 - tp: 4073.0000 - val_accuracy: 0.8455 - val_auc: 0.9373 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7838 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5045 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 137/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9285 - auc: 0.9859 - categorical_accuracy: 0.9285 - f1_score: 0.9286 - fn: 317.0000 - fp: 304.0000 - loss: 0.2418 - precision: 0.9303 - recall: 0.9276 - tn: 8450.0000 - tp: 4060.0000 - val_accuracy: 0.8455 - val_auc: 0.9380 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7811 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5142 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 138/500\n",
      "3/3 - 0s - 135ms/step - accuracy: 0.9246 - auc: 0.9860 - categorical_accuracy: 0.9246 - f1_score: 0.9247 - fn: 337.0000 - fp: 325.0000 - loss: 0.2491 - precision: 0.9255 - recall: 0.9230 - tn: 8429.0000 - tp: 4040.0000 - val_accuracy: 0.8415 - val_auc: 0.9386 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7756 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.4990 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 139/500\n",
      "3/3 - 1s - 188ms/step - accuracy: 0.9271 - auc: 0.9857 - categorical_accuracy: 0.9271 - f1_score: 0.9272 - fn: 325.0000 - fp: 314.0000 - loss: 0.2439 - precision: 0.9281 - recall: 0.9257 - tn: 8440.0000 - tp: 4052.0000 - val_accuracy: 0.8537 - val_auc: 0.9381 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7898 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.4985 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 140/500\n",
      "3/3 - 1s - 241ms/step - accuracy: 0.9287 - auc: 0.9862 - categorical_accuracy: 0.9287 - f1_score: 0.9288 - fn: 314.0000 - fp: 306.0000 - loss: 0.2406 - precision: 0.9300 - recall: 0.9283 - tn: 8448.0000 - tp: 4063.0000 - val_accuracy: 0.8333 - val_auc: 0.9360 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7750 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5114 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 141/500\n",
      "3/3 - 1s - 329ms/step - accuracy: 0.9232 - auc: 0.9851 - categorical_accuracy: 0.9232 - f1_score: 0.9230 - fn: 341.0000 - fp: 327.0000 - loss: 0.2483 - precision: 0.9251 - recall: 0.9221 - tn: 8427.0000 - tp: 4036.0000 - val_accuracy: 0.8537 - val_auc: 0.9341 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7959 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5152 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 142/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9285 - auc: 0.9854 - categorical_accuracy: 0.9285 - f1_score: 0.9288 - fn: 320.0000 - fp: 306.0000 - loss: 0.2435 - precision: 0.9299 - recall: 0.9269 - tn: 8448.0000 - tp: 4057.0000 - val_accuracy: 0.8455 - val_auc: 0.9367 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7881 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.4995 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 143/500\n",
      "3/3 - 0s - 152ms/step - accuracy: 0.9246 - auc: 0.9835 - categorical_accuracy: 0.9246 - f1_score: 0.9246 - fn: 339.0000 - fp: 323.0000 - loss: 0.2561 - precision: 0.9259 - recall: 0.9225 - tn: 8431.0000 - tp: 4038.0000 - val_accuracy: 0.8008 - val_auc: 0.9284 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7548 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5551 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 144/500\n",
      "3/3 - 0s - 159ms/step - accuracy: 0.9235 - auc: 0.9855 - categorical_accuracy: 0.9235 - f1_score: 0.9230 - fn: 346.0000 - fp: 322.0000 - loss: 0.2474 - precision: 0.9260 - recall: 0.9210 - tn: 8432.0000 - tp: 4031.0000 - val_accuracy: 0.8293 - val_auc: 0.9329 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7742 - val_fn: 43.0000 - val_fp: 40.0000 - val_loss: 0.5313 - val_precision: 0.8354 - val_recall: 0.8252 - val_tn: 452.0000 - val_tp: 203.0000\n",
      "Epoch 145/500\n",
      "3/3 - 0s - 165ms/step - accuracy: 0.9267 - auc: 0.9853 - categorical_accuracy: 0.9267 - f1_score: 0.9270 - fn: 328.0000 - fp: 314.0000 - loss: 0.2486 - precision: 0.9280 - recall: 0.9251 - tn: 8440.0000 - tp: 4049.0000 - val_accuracy: 0.8455 - val_auc: 0.9285 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7929 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5887 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 146/500\n",
      "3/3 - 0s - 138ms/step - accuracy: 0.9262 - auc: 0.9836 - categorical_accuracy: 0.9262 - f1_score: 0.9265 - fn: 325.0000 - fp: 321.0000 - loss: 0.2621 - precision: 0.9266 - recall: 0.9257 - tn: 8433.0000 - tp: 4052.0000 - val_accuracy: 0.8333 - val_auc: 0.9275 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7820 - val_fn: 41.0000 - val_fp: 41.0000 - val_loss: 0.5699 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 451.0000 - val_tp: 205.0000\n",
      "Epoch 147/500\n",
      "3/3 - 0s - 134ms/step - accuracy: 0.9244 - auc: 0.9858 - categorical_accuracy: 0.9244 - f1_score: 0.9242 - fn: 339.0000 - fp: 321.0000 - loss: 0.2485 - precision: 0.9264 - recall: 0.9225 - tn: 8433.0000 - tp: 4038.0000 - val_accuracy: 0.8333 - val_auc: 0.9345 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7823 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5145 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 148/500\n",
      "3/3 - 0s - 134ms/step - accuracy: 0.9255 - auc: 0.9846 - categorical_accuracy: 0.9255 - f1_score: 0.9256 - fn: 333.0000 - fp: 318.0000 - loss: 0.2544 - precision: 0.9271 - recall: 0.9239 - tn: 8436.0000 - tp: 4044.0000 - val_accuracy: 0.8374 - val_auc: 0.9332 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7848 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.5332 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 149/500\n",
      "3/3 - 0s - 127ms/step - accuracy: 0.9276 - auc: 0.9857 - categorical_accuracy: 0.9276 - f1_score: 0.9279 - fn: 320.0000 - fp: 312.0000 - loss: 0.2453 - precision: 0.9286 - recall: 0.9269 - tn: 8442.0000 - tp: 4057.0000 - val_accuracy: 0.8049 - val_auc: 0.9287 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7525 - val_fn: 48.0000 - val_fp: 47.0000 - val_loss: 0.5569 - val_precision: 0.8082 - val_recall: 0.8049 - val_tn: 445.0000 - val_tp: 198.0000\n",
      "Epoch 150/500\n",
      "3/3 - 0s - 128ms/step - accuracy: 0.9278 - auc: 0.9848 - categorical_accuracy: 0.9278 - f1_score: 0.9277 - fn: 324.0000 - fp: 308.0000 - loss: 0.2496 - precision: 0.9294 - recall: 0.9260 - tn: 8446.0000 - tp: 4053.0000 - val_accuracy: 0.8293 - val_auc: 0.9313 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7747 - val_fn: 45.0000 - val_fp: 42.0000 - val_loss: 0.5525 - val_precision: 0.8272 - val_recall: 0.8171 - val_tn: 450.0000 - val_tp: 201.0000\n",
      "Epoch 151/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9296 - auc: 0.9862 - categorical_accuracy: 0.9296 - f1_score: 0.9298 - fn: 318.0000 - fp: 303.0000 - loss: 0.2401 - precision: 0.9305 - recall: 0.9273 - tn: 8451.0000 - tp: 4059.0000 - val_accuracy: 0.8415 - val_auc: 0.9346 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7839 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5280 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 152/500\n",
      "3/3 - 0s - 131ms/step - accuracy: 0.9303 - auc: 0.9865 - categorical_accuracy: 0.9303 - f1_score: 0.9306 - fn: 307.0000 - fp: 295.0000 - loss: 0.2403 - precision: 0.9324 - recall: 0.9299 - tn: 8459.0000 - tp: 4070.0000 - val_accuracy: 0.8171 - val_auc: 0.9229 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7684 - val_fn: 45.0000 - val_fp: 44.0000 - val_loss: 0.6204 - val_precision: 0.8204 - val_recall: 0.8171 - val_tn: 448.0000 - val_tp: 201.0000\n",
      "Epoch 153/500\n",
      "3/3 - 0s - 138ms/step - accuracy: 0.9296 - auc: 0.9850 - categorical_accuracy: 0.9296 - f1_score: 0.9294 - fn: 311.0000 - fp: 301.0000 - loss: 0.2503 - precision: 0.9311 - recall: 0.9289 - tn: 8453.0000 - tp: 4066.0000 - val_accuracy: 0.8333 - val_auc: 0.9359 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7739 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5390 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 154/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9271 - auc: 0.9855 - categorical_accuracy: 0.9271 - f1_score: 0.9275 - fn: 327.0000 - fp: 315.0000 - loss: 0.2462 - precision: 0.9278 - recall: 0.9253 - tn: 8439.0000 - tp: 4050.0000 - val_accuracy: 0.8333 - val_auc: 0.9342 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7805 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.5567 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 155/500\n",
      "3/3 - 0s - 145ms/step - accuracy: 0.9232 - auc: 0.9847 - categorical_accuracy: 0.9232 - f1_score: 0.9231 - fn: 337.0000 - fp: 329.0000 - loss: 0.2542 - precision: 0.9247 - recall: 0.9230 - tn: 8425.0000 - tp: 4040.0000 - val_accuracy: 0.8211 - val_auc: 0.9302 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7722 - val_fn: 44.0000 - val_fp: 44.0000 - val_loss: 0.6206 - val_precision: 0.8211 - val_recall: 0.8211 - val_tn: 448.0000 - val_tp: 202.0000\n",
      "Epoch 156/500\n",
      "3/3 - 0s - 166ms/step - accuracy: 0.9264 - auc: 0.9853 - categorical_accuracy: 0.9264 - f1_score: 0.9263 - fn: 324.0000 - fp: 317.0000 - loss: 0.2445 - precision: 0.9275 - recall: 0.9260 - tn: 8437.0000 - tp: 4053.0000 - val_accuracy: 0.8455 - val_auc: 0.9274 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7871 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5941 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 157/500\n",
      "3/3 - 0s - 150ms/step - accuracy: 0.9287 - auc: 0.9832 - categorical_accuracy: 0.9287 - f1_score: 0.9291 - fn: 313.0000 - fp: 308.0000 - loss: 0.2616 - precision: 0.9296 - recall: 0.9285 - tn: 8446.0000 - tp: 4064.0000 - val_accuracy: 0.8171 - val_auc: 0.9216 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7627 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.6923 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 158/500\n",
      "3/3 - 1s - 189ms/step - accuracy: 0.9273 - auc: 0.9840 - categorical_accuracy: 0.9273 - f1_score: 0.9271 - fn: 323.0000 - fp: 307.0000 - loss: 0.2600 - precision: 0.9296 - recall: 0.9262 - tn: 8447.0000 - tp: 4054.0000 - val_accuracy: 0.8455 - val_auc: 0.9255 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7898 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.6728 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 159/500\n",
      "3/3 - 0s - 163ms/step - accuracy: 0.9271 - auc: 0.9850 - categorical_accuracy: 0.9271 - f1_score: 0.9272 - fn: 322.0000 - fp: 309.0000 - loss: 0.2495 - precision: 0.9292 - recall: 0.9264 - tn: 8445.0000 - tp: 4055.0000 - val_accuracy: 0.8455 - val_auc: 0.9291 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7928 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5954 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 160/500\n",
      "3/3 - 0s - 151ms/step - accuracy: 0.9269 - auc: 0.9860 - categorical_accuracy: 0.9269 - f1_score: 0.9267 - fn: 327.0000 - fp: 315.0000 - loss: 0.2468 - precision: 0.9278 - recall: 0.9253 - tn: 8439.0000 - tp: 4050.0000 - val_accuracy: 0.8333 - val_auc: 0.9244 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7823 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.6766 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 161/500\n",
      "3/3 - 1s - 176ms/step - accuracy: 0.9283 - auc: 0.9854 - categorical_accuracy: 0.9283 - f1_score: 0.9283 - fn: 316.0000 - fp: 308.0000 - loss: 0.2486 - precision: 0.9295 - recall: 0.9278 - tn: 8446.0000 - tp: 4061.0000 - val_accuracy: 0.8496 - val_auc: 0.9278 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7955 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5978 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 162/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9299 - auc: 0.9859 - categorical_accuracy: 0.9299 - f1_score: 0.9302 - fn: 309.0000 - fp: 304.0000 - loss: 0.2450 - precision: 0.9305 - recall: 0.9294 - tn: 8450.0000 - tp: 4068.0000 - val_accuracy: 0.8455 - val_auc: 0.9301 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7881 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5979 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 163/500\n",
      "3/3 - 0s - 155ms/step - accuracy: 0.9317 - auc: 0.9863 - categorical_accuracy: 0.9317 - f1_score: 0.9319 - fn: 303.0000 - fp: 296.0000 - loss: 0.2433 - precision: 0.9323 - recall: 0.9308 - tn: 8458.0000 - tp: 4074.0000 - val_accuracy: 0.8496 - val_auc: 0.9320 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7940 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5846 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 164/500\n",
      "3/3 - 0s - 145ms/step - accuracy: 0.9296 - auc: 0.9857 - categorical_accuracy: 0.9296 - f1_score: 0.9297 - fn: 312.0000 - fp: 307.0000 - loss: 0.2421 - precision: 0.9298 - recall: 0.9287 - tn: 8447.0000 - tp: 4065.0000 - val_accuracy: 0.8374 - val_auc: 0.9363 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7848 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5267 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 165/500\n",
      "3/3 - 1s - 199ms/step - accuracy: 0.9210 - auc: 0.9843 - categorical_accuracy: 0.9210 - f1_score: 0.9208 - fn: 350.0000 - fp: 341.0000 - loss: 0.2566 - precision: 0.9219 - recall: 0.9200 - tn: 8413.0000 - tp: 4027.0000 - val_accuracy: 0.8415 - val_auc: 0.9340 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7840 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.5366 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 166/500\n",
      "3/3 - 0s - 159ms/step - accuracy: 0.9303 - auc: 0.9855 - categorical_accuracy: 0.9303 - f1_score: 0.9304 - fn: 310.0000 - fp: 298.0000 - loss: 0.2412 - precision: 0.9317 - recall: 0.9292 - tn: 8456.0000 - tp: 4067.0000 - val_accuracy: 0.8415 - val_auc: 0.9255 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7886 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.6361 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 167/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9294 - auc: 0.9853 - categorical_accuracy: 0.9294 - f1_score: 0.9294 - fn: 314.0000 - fp: 302.0000 - loss: 0.2476 - precision: 0.9308 - recall: 0.9283 - tn: 8452.0000 - tp: 4063.0000 - val_accuracy: 0.8415 - val_auc: 0.9212 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7875 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.6641 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 168/500\n",
      "3/3 - 0s - 154ms/step - accuracy: 0.9287 - auc: 0.9870 - categorical_accuracy: 0.9287 - f1_score: 0.9288 - fn: 317.0000 - fp: 300.0000 - loss: 0.2362 - precision: 0.9312 - recall: 0.9276 - tn: 8454.0000 - tp: 4060.0000 - val_accuracy: 0.8293 - val_auc: 0.9262 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7699 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.6127 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 169/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9287 - auc: 0.9861 - categorical_accuracy: 0.9287 - f1_score: 0.9290 - fn: 318.0000 - fp: 305.0000 - loss: 0.2423 - precision: 0.9301 - recall: 0.9273 - tn: 8449.0000 - tp: 4059.0000 - val_accuracy: 0.7967 - val_auc: 0.9211 - val_categorical_accuracy: 0.7967 - val_f1_score: 0.7490 - val_fn: 50.0000 - val_fp: 50.0000 - val_loss: 0.6717 - val_precision: 0.7967 - val_recall: 0.7967 - val_tn: 442.0000 - val_tp: 196.0000\n",
      "Epoch 170/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9203 - auc: 0.9853 - categorical_accuracy: 0.9203 - f1_score: 0.9196 - fn: 355.0000 - fp: 345.0000 - loss: 0.2515 - precision: 0.9210 - recall: 0.9189 - tn: 8409.0000 - tp: 4022.0000 - val_accuracy: 0.8333 - val_auc: 0.9292 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7738 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.6110 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 171/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9267 - auc: 0.9851 - categorical_accuracy: 0.9267 - f1_score: 0.9272 - fn: 325.0000 - fp: 319.0000 - loss: 0.2469 - precision: 0.9270 - recall: 0.9257 - tn: 8435.0000 - tp: 4052.0000 - val_accuracy: 0.8252 - val_auc: 0.9238 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7737 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.6353 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 172/500\n",
      "3/3 - 1s - 199ms/step - accuracy: 0.9271 - auc: 0.9856 - categorical_accuracy: 0.9271 - f1_score: 0.9269 - fn: 326.0000 - fp: 307.0000 - loss: 0.2440 - precision: 0.9296 - recall: 0.9255 - tn: 8447.0000 - tp: 4051.0000 - val_accuracy: 0.8374 - val_auc: 0.9251 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7863 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5916 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 173/500\n",
      "3/3 - 1s - 248ms/step - accuracy: 0.9276 - auc: 0.9866 - categorical_accuracy: 0.9276 - f1_score: 0.9278 - fn: 320.0000 - fp: 314.0000 - loss: 0.2390 - precision: 0.9282 - recall: 0.9269 - tn: 8440.0000 - tp: 4057.0000 - val_accuracy: 0.8415 - val_auc: 0.9298 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7872 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5622 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 174/500\n",
      "3/3 - 1s - 169ms/step - accuracy: 0.9292 - auc: 0.9857 - categorical_accuracy: 0.9292 - f1_score: 0.9293 - fn: 313.0000 - fp: 306.0000 - loss: 0.2420 - precision: 0.9300 - recall: 0.9285 - tn: 8448.0000 - tp: 4064.0000 - val_accuracy: 0.8049 - val_auc: 0.9241 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7535 - val_fn: 48.0000 - val_fp: 48.0000 - val_loss: 0.6203 - val_precision: 0.8049 - val_recall: 0.8049 - val_tn: 444.0000 - val_tp: 198.0000\n",
      "Epoch 175/500\n",
      "3/3 - 0s - 151ms/step - accuracy: 0.9287 - auc: 0.9859 - categorical_accuracy: 0.9287 - f1_score: 0.9285 - fn: 313.0000 - fp: 305.0000 - loss: 0.2442 - precision: 0.9302 - recall: 0.9285 - tn: 8449.0000 - tp: 4064.0000 - val_accuracy: 0.8171 - val_auc: 0.9297 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7633 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.5613 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 176/500\n",
      "3/3 - 1s - 225ms/step - accuracy: 0.9305 - auc: 0.9860 - categorical_accuracy: 0.9305 - f1_score: 0.9307 - fn: 307.0000 - fp: 299.0000 - loss: 0.2383 - precision: 0.9316 - recall: 0.9299 - tn: 8455.0000 - tp: 4070.0000 - val_accuracy: 0.8293 - val_auc: 0.9344 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7746 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.5214 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 177/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9285 - auc: 0.9854 - categorical_accuracy: 0.9285 - f1_score: 0.9284 - fn: 317.0000 - fp: 306.0000 - loss: 0.2425 - precision: 0.9299 - recall: 0.9276 - tn: 8448.0000 - tp: 4060.0000 - val_accuracy: 0.8171 - val_auc: 0.9316 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7688 - val_fn: 46.0000 - val_fp: 44.0000 - val_loss: 0.5412 - val_precision: 0.8197 - val_recall: 0.8130 - val_tn: 448.0000 - val_tp: 200.0000\n",
      "Epoch 178/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9317 - auc: 0.9865 - categorical_accuracy: 0.9317 - f1_score: 0.9316 - fn: 302.0000 - fp: 290.0000 - loss: 0.2332 - precision: 0.9336 - recall: 0.9310 - tn: 8464.0000 - tp: 4075.0000 - val_accuracy: 0.8455 - val_auc: 0.9321 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7901 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5365 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 179/500\n",
      "3/3 - 1s - 276ms/step - accuracy: 0.9308 - auc: 0.9854 - categorical_accuracy: 0.9308 - f1_score: 0.9310 - fn: 307.0000 - fp: 303.0000 - loss: 0.2393 - precision: 0.9307 - recall: 0.9299 - tn: 8451.0000 - tp: 4070.0000 - val_accuracy: 0.8496 - val_auc: 0.9350 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7891 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5080 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 180/500\n",
      "3/3 - 1s - 179ms/step - accuracy: 0.9312 - auc: 0.9872 - categorical_accuracy: 0.9312 - f1_score: 0.9314 - fn: 306.0000 - fp: 296.0000 - loss: 0.2306 - precision: 0.9322 - recall: 0.9301 - tn: 8458.0000 - tp: 4071.0000 - val_accuracy: 0.8211 - val_auc: 0.9317 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7652 - val_fn: 45.0000 - val_fp: 43.0000 - val_loss: 0.5280 - val_precision: 0.8238 - val_recall: 0.8171 - val_tn: 449.0000 - val_tp: 201.0000\n",
      "Epoch 181/500\n",
      "3/3 - 1s - 197ms/step - accuracy: 0.9269 - auc: 0.9868 - categorical_accuracy: 0.9269 - f1_score: 0.9267 - fn: 325.0000 - fp: 315.0000 - loss: 0.2379 - precision: 0.9279 - recall: 0.9257 - tn: 8439.0000 - tp: 4052.0000 - val_accuracy: 0.8537 - val_auc: 0.9369 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7967 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.4979 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 182/500\n",
      "3/3 - 0s - 149ms/step - accuracy: 0.9241 - auc: 0.9861 - categorical_accuracy: 0.9241 - f1_score: 0.9241 - fn: 336.0000 - fp: 327.0000 - loss: 0.2376 - precision: 0.9251 - recall: 0.9232 - tn: 8427.0000 - tp: 4041.0000 - val_accuracy: 0.8537 - val_auc: 0.9375 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7998 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.4922 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 183/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9219 - auc: 0.9847 - categorical_accuracy: 0.9219 - f1_score: 0.9216 - fn: 346.0000 - fp: 338.0000 - loss: 0.2505 - precision: 0.9226 - recall: 0.9210 - tn: 8416.0000 - tp: 4031.0000 - val_accuracy: 0.8455 - val_auc: 0.9349 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7834 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5001 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 184/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9287 - auc: 0.9850 - categorical_accuracy: 0.9287 - f1_score: 0.9291 - fn: 320.0000 - fp: 308.0000 - loss: 0.2433 - precision: 0.9294 - recall: 0.9269 - tn: 8446.0000 - tp: 4057.0000 - val_accuracy: 0.8415 - val_auc: 0.9376 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7839 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5058 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 185/500\n",
      "3/3 - 0s - 149ms/step - accuracy: 0.9257 - auc: 0.9854 - categorical_accuracy: 0.9257 - f1_score: 0.9255 - fn: 329.0000 - fp: 321.0000 - loss: 0.2434 - precision: 0.9265 - recall: 0.9248 - tn: 8433.0000 - tp: 4048.0000 - val_accuracy: 0.8496 - val_auc: 0.9375 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7931 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5156 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 186/500\n",
      "3/3 - 0s - 152ms/step - accuracy: 0.9287 - auc: 0.9851 - categorical_accuracy: 0.9287 - f1_score: 0.9291 - fn: 318.0000 - fp: 310.0000 - loss: 0.2475 - precision: 0.9290 - recall: 0.9273 - tn: 8444.0000 - tp: 4059.0000 - val_accuracy: 0.8455 - val_auc: 0.9378 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7781 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5116 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 187/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9262 - auc: 0.9846 - categorical_accuracy: 0.9262 - f1_score: 0.9263 - fn: 327.0000 - fp: 317.0000 - loss: 0.2529 - precision: 0.9274 - recall: 0.9253 - tn: 8437.0000 - tp: 4050.0000 - val_accuracy: 0.8455 - val_auc: 0.9357 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7898 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5252 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 188/500\n",
      "3/3 - 1s - 198ms/step - accuracy: 0.9262 - auc: 0.9859 - categorical_accuracy: 0.9262 - f1_score: 0.9260 - fn: 328.0000 - fp: 312.0000 - loss: 0.2436 - precision: 0.9285 - recall: 0.9251 - tn: 8442.0000 - tp: 4049.0000 - val_accuracy: 0.8455 - val_auc: 0.9382 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7783 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.4972 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 189/500\n",
      "3/3 - 1s - 210ms/step - accuracy: 0.9241 - auc: 0.9830 - categorical_accuracy: 0.9241 - f1_score: 0.9242 - fn: 340.0000 - fp: 328.0000 - loss: 0.2632 - precision: 0.9249 - recall: 0.9223 - tn: 8426.0000 - tp: 4037.0000 - val_accuracy: 0.8455 - val_auc: 0.9391 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7845 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.4957 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 190/500\n",
      "3/3 - 1s - 239ms/step - accuracy: 0.9326 - auc: 0.9863 - categorical_accuracy: 0.9326 - f1_score: 0.9327 - fn: 300.0000 - fp: 291.0000 - loss: 0.2417 - precision: 0.9334 - recall: 0.9315 - tn: 8463.0000 - tp: 4077.0000 - val_accuracy: 0.8130 - val_auc: 0.9289 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7540 - val_fn: 47.0000 - val_fp: 46.0000 - val_loss: 0.5518 - val_precision: 0.8122 - val_recall: 0.8089 - val_tn: 446.0000 - val_tp: 199.0000\n",
      "Epoch 191/500\n",
      "3/3 - 1s - 226ms/step - accuracy: 0.9271 - auc: 0.9858 - categorical_accuracy: 0.9271 - f1_score: 0.9272 - fn: 326.0000 - fp: 313.0000 - loss: 0.2484 - precision: 0.9283 - recall: 0.9255 - tn: 8441.0000 - tp: 4051.0000 - val_accuracy: 0.8415 - val_auc: 0.9341 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7776 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5266 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 192/500\n",
      "3/3 - 0s - 147ms/step - accuracy: 0.9310 - auc: 0.9854 - categorical_accuracy: 0.9310 - f1_score: 0.9313 - fn: 308.0000 - fp: 296.0000 - loss: 0.2478 - precision: 0.9322 - recall: 0.9296 - tn: 8458.0000 - tp: 4069.0000 - val_accuracy: 0.8374 - val_auc: 0.9309 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7790 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5300 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 193/500\n",
      "3/3 - 1s - 190ms/step - accuracy: 0.9280 - auc: 0.9860 - categorical_accuracy: 0.9280 - f1_score: 0.9279 - fn: 322.0000 - fp: 302.0000 - loss: 0.2450 - precision: 0.9307 - recall: 0.9264 - tn: 8452.0000 - tp: 4055.0000 - val_accuracy: 0.8374 - val_auc: 0.9324 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7800 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5322 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 194/500\n",
      "3/3 - 0s - 148ms/step - accuracy: 0.9273 - auc: 0.9862 - categorical_accuracy: 0.9273 - f1_score: 0.9271 - fn: 328.0000 - fp: 308.0000 - loss: 0.2435 - precision: 0.9293 - recall: 0.9251 - tn: 8446.0000 - tp: 4049.0000 - val_accuracy: 0.8577 - val_auc: 0.9380 - val_categorical_accuracy: 0.8577 - val_f1_score: 0.7952 - val_fn: 35.0000 - val_fp: 35.0000 - val_loss: 0.4922 - val_precision: 0.8577 - val_recall: 0.8577 - val_tn: 457.0000 - val_tp: 211.0000\n",
      "Epoch 195/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9207 - auc: 0.9858 - categorical_accuracy: 0.9207 - f1_score: 0.9214 - fn: 351.0000 - fp: 342.0000 - loss: 0.2494 - precision: 0.9217 - recall: 0.9198 - tn: 8412.0000 - tp: 4026.0000 - val_accuracy: 0.8455 - val_auc: 0.9378 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7876 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5154 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 196/500\n",
      "3/3 - 0s - 150ms/step - accuracy: 0.9230 - auc: 0.9860 - categorical_accuracy: 0.9230 - f1_score: 0.9227 - fn: 346.0000 - fp: 330.0000 - loss: 0.2470 - precision: 0.9243 - recall: 0.9210 - tn: 8424.0000 - tp: 4031.0000 - val_accuracy: 0.8374 - val_auc: 0.9311 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7813 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5451 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 197/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9280 - auc: 0.9861 - categorical_accuracy: 0.9280 - f1_score: 0.9282 - fn: 323.0000 - fp: 312.0000 - loss: 0.2443 - precision: 0.9285 - recall: 0.9262 - tn: 8442.0000 - tp: 4054.0000 - val_accuracy: 0.8496 - val_auc: 0.9363 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7913 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5097 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 198/500\n",
      "3/3 - 1s - 195ms/step - accuracy: 0.9267 - auc: 0.9865 - categorical_accuracy: 0.9267 - f1_score: 0.9268 - fn: 330.0000 - fp: 309.0000 - loss: 0.2380 - precision: 0.9291 - recall: 0.9246 - tn: 8445.0000 - tp: 4047.0000 - val_accuracy: 0.8171 - val_auc: 0.9315 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7609 - val_fn: 46.0000 - val_fp: 42.0000 - val_loss: 0.5524 - val_precision: 0.8264 - val_recall: 0.8130 - val_tn: 450.0000 - val_tp: 200.0000\n",
      "Epoch 199/500\n",
      "3/3 - 0s - 162ms/step - accuracy: 0.9271 - auc: 0.9855 - categorical_accuracy: 0.9271 - f1_score: 0.9271 - fn: 322.0000 - fp: 312.0000 - loss: 0.2451 - precision: 0.9286 - recall: 0.9264 - tn: 8442.0000 - tp: 4055.0000 - val_accuracy: 0.8496 - val_auc: 0.9333 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7940 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5381 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 200/500\n",
      "3/3 - 0s - 160ms/step - accuracy: 0.9278 - auc: 0.9855 - categorical_accuracy: 0.9278 - f1_score: 0.9278 - fn: 322.0000 - fp: 312.0000 - loss: 0.2412 - precision: 0.9286 - recall: 0.9264 - tn: 8442.0000 - tp: 4055.0000 - val_accuracy: 0.8455 - val_auc: 0.9303 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7898 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5654 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 201/500\n",
      "3/3 - 1s - 180ms/step - accuracy: 0.9315 - auc: 0.9870 - categorical_accuracy: 0.9315 - f1_score: 0.9315 - fn: 305.0000 - fp: 294.0000 - loss: 0.2337 - precision: 0.9327 - recall: 0.9303 - tn: 8460.0000 - tp: 4072.0000 - val_accuracy: 0.8496 - val_auc: 0.9299 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7913 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5827 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 202/500\n",
      "3/3 - 0s - 155ms/step - accuracy: 0.9262 - auc: 0.9851 - categorical_accuracy: 0.9262 - f1_score: 0.9266 - fn: 325.0000 - fp: 317.0000 - loss: 0.2454 - precision: 0.9274 - recall: 0.9257 - tn: 8437.0000 - tp: 4052.0000 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7792 - val_fn: 41.0000 - val_fp: 41.0000 - val_loss: 0.5885 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 451.0000 - val_tp: 205.0000\n",
      "Epoch 203/500\n",
      "3/3 - 0s - 147ms/step - accuracy: 0.9257 - auc: 0.9855 - categorical_accuracy: 0.9257 - f1_score: 0.9253 - fn: 334.0000 - fp: 317.0000 - loss: 0.2431 - precision: 0.9273 - recall: 0.9237 - tn: 8437.0000 - tp: 4043.0000 - val_accuracy: 0.8374 - val_auc: 0.9320 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7832 - val_fn: 43.0000 - val_fp: 40.0000 - val_loss: 0.5286 - val_precision: 0.8354 - val_recall: 0.8252 - val_tn: 452.0000 - val_tp: 203.0000\n",
      "Epoch 204/500\n",
      "3/3 - 1s - 168ms/step - accuracy: 0.9283 - auc: 0.9861 - categorical_accuracy: 0.9283 - f1_score: 0.9282 - fn: 329.0000 - fp: 302.0000 - loss: 0.2463 - precision: 0.9306 - recall: 0.9248 - tn: 8452.0000 - tp: 4048.0000 - val_accuracy: 0.8415 - val_auc: 0.9340 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7795 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5369 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 205/500\n",
      "3/3 - 1s - 171ms/step - accuracy: 0.9280 - auc: 0.9868 - categorical_accuracy: 0.9280 - f1_score: 0.9282 - fn: 318.0000 - fp: 309.0000 - loss: 0.2359 - precision: 0.9293 - recall: 0.9273 - tn: 8445.0000 - tp: 4059.0000 - val_accuracy: 0.8455 - val_auc: 0.9308 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7869 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.6170 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 206/500\n",
      "3/3 - 1s - 180ms/step - accuracy: 0.9283 - auc: 0.9847 - categorical_accuracy: 0.9283 - f1_score: 0.9286 - fn: 316.0000 - fp: 312.0000 - loss: 0.2520 - precision: 0.9287 - recall: 0.9278 - tn: 8442.0000 - tp: 4061.0000 - val_accuracy: 0.8496 - val_auc: 0.9311 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7913 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5779 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 207/500\n",
      "3/3 - 1s - 223ms/step - accuracy: 0.9235 - auc: 0.9858 - categorical_accuracy: 0.9235 - f1_score: 0.9240 - fn: 340.0000 - fp: 329.0000 - loss: 0.2415 - precision: 0.9246 - recall: 0.9223 - tn: 8425.0000 - tp: 4037.0000 - val_accuracy: 0.8293 - val_auc: 0.9325 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7771 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.5445 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 208/500\n",
      "3/3 - 1s - 336ms/step - accuracy: 0.9239 - auc: 0.9851 - categorical_accuracy: 0.9239 - f1_score: 0.9237 - fn: 341.0000 - fp: 328.0000 - loss: 0.2469 - precision: 0.9248 - recall: 0.9221 - tn: 8426.0000 - tp: 4036.0000 - val_accuracy: 0.8333 - val_auc: 0.9349 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7809 - val_fn: 42.0000 - val_fp: 39.0000 - val_loss: 0.5231 - val_precision: 0.8395 - val_recall: 0.8293 - val_tn: 453.0000 - val_tp: 204.0000\n",
      "Epoch 209/500\n",
      "3/3 - 1s - 429ms/step - accuracy: 0.9251 - auc: 0.9851 - categorical_accuracy: 0.9251 - f1_score: 0.9251 - fn: 339.0000 - fp: 319.0000 - loss: 0.2498 - precision: 0.9268 - recall: 0.9225 - tn: 8435.0000 - tp: 4038.0000 - val_accuracy: 0.8496 - val_auc: 0.9373 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7989 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5219 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 210/500\n",
      "3/3 - 1s - 363ms/step - accuracy: 0.9267 - auc: 0.9862 - categorical_accuracy: 0.9267 - f1_score: 0.9266 - fn: 326.0000 - fp: 310.0000 - loss: 0.2379 - precision: 0.9289 - recall: 0.9255 - tn: 8444.0000 - tp: 4051.0000 - val_accuracy: 0.8130 - val_auc: 0.9272 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7645 - val_fn: 47.0000 - val_fp: 46.0000 - val_loss: 0.6540 - val_precision: 0.8122 - val_recall: 0.8089 - val_tn: 446.0000 - val_tp: 199.0000\n",
      "Epoch 211/500\n",
      "3/3 - 1s - 249ms/step - accuracy: 0.9296 - auc: 0.9850 - categorical_accuracy: 0.9296 - f1_score: 0.9292 - fn: 311.0000 - fp: 304.0000 - loss: 0.2517 - precision: 0.9304 - recall: 0.9289 - tn: 8450.0000 - tp: 4066.0000 - val_accuracy: 0.8415 - val_auc: 0.9358 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7821 - val_fn: 39.0000 - val_fp: 36.0000 - val_loss: 0.5228 - val_precision: 0.8519 - val_recall: 0.8415 - val_tn: 456.0000 - val_tp: 207.0000\n",
      "Epoch 212/500\n",
      "3/3 - 1s - 215ms/step - accuracy: 0.9289 - auc: 0.9859 - categorical_accuracy: 0.9289 - f1_score: 0.9292 - fn: 312.0000 - fp: 308.0000 - loss: 0.2401 - precision: 0.9296 - recall: 0.9287 - tn: 8446.0000 - tp: 4065.0000 - val_accuracy: 0.8415 - val_auc: 0.9358 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7839 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5151 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 213/500\n",
      "3/3 - 1s - 273ms/step - accuracy: 0.9296 - auc: 0.9863 - categorical_accuracy: 0.9296 - f1_score: 0.9295 - fn: 313.0000 - fp: 300.0000 - loss: 0.2400 - precision: 0.9313 - recall: 0.9285 - tn: 8454.0000 - tp: 4064.0000 - val_accuracy: 0.8333 - val_auc: 0.9290 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7760 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5455 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 214/500\n",
      "3/3 - 1s - 210ms/step - accuracy: 0.9299 - auc: 0.9859 - categorical_accuracy: 0.9299 - f1_score: 0.9299 - fn: 314.0000 - fp: 305.0000 - loss: 0.2411 - precision: 0.9302 - recall: 0.9283 - tn: 8449.0000 - tp: 4063.0000 - val_accuracy: 0.8537 - val_auc: 0.9273 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7937 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5540 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 215/500\n",
      "3/3 - 2s - 512ms/step - accuracy: 0.9294 - auc: 0.9863 - categorical_accuracy: 0.9294 - f1_score: 0.9298 - fn: 310.0000 - fp: 306.0000 - loss: 0.2371 - precision: 0.9300 - recall: 0.9292 - tn: 8448.0000 - tp: 4067.0000 - val_accuracy: 0.8211 - val_auc: 0.9236 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7695 - val_fn: 47.0000 - val_fp: 44.0000 - val_loss: 0.5945 - val_precision: 0.8189 - val_recall: 0.8089 - val_tn: 448.0000 - val_tp: 199.0000\n",
      "Epoch 216/500\n",
      "3/3 - 1s - 264ms/step - accuracy: 0.9264 - auc: 0.9850 - categorical_accuracy: 0.9264 - f1_score: 0.9265 - fn: 328.0000 - fp: 314.0000 - loss: 0.2486 - precision: 0.9280 - recall: 0.9251 - tn: 8440.0000 - tp: 4049.0000 - val_accuracy: 0.8496 - val_auc: 0.9344 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7913 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5205 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 217/500\n",
      "3/3 - 1s - 258ms/step - accuracy: 0.9278 - auc: 0.9862 - categorical_accuracy: 0.9278 - f1_score: 0.9282 - fn: 321.0000 - fp: 310.0000 - loss: 0.2379 - precision: 0.9290 - recall: 0.9267 - tn: 8444.0000 - tp: 4056.0000 - val_accuracy: 0.8171 - val_auc: 0.9332 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7598 - val_fn: 46.0000 - val_fp: 45.0000 - val_loss: 0.5265 - val_precision: 0.8163 - val_recall: 0.8130 - val_tn: 447.0000 - val_tp: 200.0000\n",
      "Epoch 218/500\n",
      "3/3 - 1s - 209ms/step - accuracy: 0.9319 - auc: 0.9864 - categorical_accuracy: 0.9319 - f1_score: 0.9318 - fn: 303.0000 - fp: 294.0000 - loss: 0.2334 - precision: 0.9327 - recall: 0.9308 - tn: 8460.0000 - tp: 4074.0000 - val_accuracy: 0.8374 - val_auc: 0.9352 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7795 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5130 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 219/500\n",
      "3/3 - 1s - 204ms/step - accuracy: 0.9276 - auc: 0.9869 - categorical_accuracy: 0.9276 - f1_score: 0.9278 - fn: 320.0000 - fp: 307.0000 - loss: 0.2332 - precision: 0.9297 - recall: 0.9269 - tn: 8447.0000 - tp: 4057.0000 - val_accuracy: 0.8496 - val_auc: 0.9322 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7873 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5114 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 220/500\n",
      "3/3 - 1s - 256ms/step - accuracy: 0.9264 - auc: 0.9865 - categorical_accuracy: 0.9264 - f1_score: 0.9268 - fn: 326.0000 - fp: 315.0000 - loss: 0.2399 - precision: 0.9279 - recall: 0.9255 - tn: 8439.0000 - tp: 4051.0000 - val_accuracy: 0.8089 - val_auc: 0.9318 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7553 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5377 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 221/500\n",
      "3/3 - 1s - 268ms/step - accuracy: 0.9228 - auc: 0.9860 - categorical_accuracy: 0.9228 - f1_score: 0.9223 - fn: 344.0000 - fp: 333.0000 - loss: 0.2388 - precision: 0.9237 - recall: 0.9214 - tn: 8421.0000 - tp: 4033.0000 - val_accuracy: 0.8537 - val_auc: 0.9354 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7910 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.5327 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 222/500\n",
      "3/3 - 1s - 285ms/step - accuracy: 0.9280 - auc: 0.9848 - categorical_accuracy: 0.9280 - f1_score: 0.9285 - fn: 316.0000 - fp: 312.0000 - loss: 0.2399 - precision: 0.9287 - recall: 0.9278 - tn: 8442.0000 - tp: 4061.0000 - val_accuracy: 0.8537 - val_auc: 0.9359 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7967 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5050 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 223/500\n",
      "3/3 - 1s - 361ms/step - accuracy: 0.9262 - auc: 0.9856 - categorical_accuracy: 0.9262 - f1_score: 0.9262 - fn: 326.0000 - fp: 319.0000 - loss: 0.2381 - precision: 0.9270 - recall: 0.9255 - tn: 8435.0000 - tp: 4051.0000 - val_accuracy: 0.8293 - val_auc: 0.9317 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7729 - val_fn: 43.0000 - val_fp: 40.0000 - val_loss: 0.5247 - val_precision: 0.8354 - val_recall: 0.8252 - val_tn: 452.0000 - val_tp: 203.0000\n",
      "Epoch 224/500\n",
      "3/3 - 1s - 256ms/step - accuracy: 0.9301 - auc: 0.9859 - categorical_accuracy: 0.9301 - f1_score: 0.9300 - fn: 313.0000 - fp: 302.0000 - loss: 0.2388 - precision: 0.9308 - recall: 0.9285 - tn: 8452.0000 - tp: 4064.0000 - val_accuracy: 0.8537 - val_auc: 0.9337 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7936 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.5117 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 225/500\n",
      "3/3 - 1s - 206ms/step - accuracy: 0.9273 - auc: 0.9869 - categorical_accuracy: 0.9273 - f1_score: 0.9276 - fn: 320.0000 - fp: 315.0000 - loss: 0.2314 - precision: 0.9280 - recall: 0.9269 - tn: 8439.0000 - tp: 4057.0000 - val_accuracy: 0.8577 - val_auc: 0.9329 - val_categorical_accuracy: 0.8577 - val_f1_score: 0.7995 - val_fn: 35.0000 - val_fp: 35.0000 - val_loss: 0.5309 - val_precision: 0.8577 - val_recall: 0.8577 - val_tn: 457.0000 - val_tp: 211.0000\n",
      "Epoch 226/500\n",
      "3/3 - 1s - 222ms/step - accuracy: 0.9326 - auc: 0.9866 - categorical_accuracy: 0.9326 - f1_score: 0.9328 - fn: 299.0000 - fp: 290.0000 - loss: 0.2340 - precision: 0.9336 - recall: 0.9317 - tn: 8464.0000 - tp: 4078.0000 - val_accuracy: 0.8496 - val_auc: 0.9346 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7909 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5325 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 227/500\n",
      "3/3 - 1s - 234ms/step - accuracy: 0.9280 - auc: 0.9857 - categorical_accuracy: 0.9280 - f1_score: 0.9280 - fn: 321.0000 - fp: 307.0000 - loss: 0.2388 - precision: 0.9296 - recall: 0.9267 - tn: 8447.0000 - tp: 4056.0000 - val_accuracy: 0.8455 - val_auc: 0.9356 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7833 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5073 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 228/500\n",
      "3/3 - 1s - 254ms/step - accuracy: 0.9253 - auc: 0.9849 - categorical_accuracy: 0.9253 - f1_score: 0.9258 - fn: 335.0000 - fp: 324.0000 - loss: 0.2448 - precision: 0.9258 - recall: 0.9235 - tn: 8430.0000 - tp: 4042.0000 - val_accuracy: 0.8374 - val_auc: 0.9396 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7677 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.4942 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 229/500\n",
      "3/3 - 1s - 167ms/step - accuracy: 0.9308 - auc: 0.9869 - categorical_accuracy: 0.9308 - f1_score: 0.9308 - fn: 306.0000 - fp: 299.0000 - loss: 0.2268 - precision: 0.9316 - recall: 0.9301 - tn: 8455.0000 - tp: 4071.0000 - val_accuracy: 0.8293 - val_auc: 0.9306 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7684 - val_fn: 43.0000 - val_fp: 41.0000 - val_loss: 0.5356 - val_precision: 0.8320 - val_recall: 0.8252 - val_tn: 451.0000 - val_tp: 203.0000\n",
      "Epoch 230/500\n",
      "3/3 - 1s - 256ms/step - accuracy: 0.9255 - auc: 0.9850 - categorical_accuracy: 0.9255 - f1_score: 0.9255 - fn: 327.0000 - fp: 324.0000 - loss: 0.2449 - precision: 0.9259 - recall: 0.9253 - tn: 8430.0000 - tp: 4050.0000 - val_accuracy: 0.8577 - val_auc: 0.9355 - val_categorical_accuracy: 0.8577 - val_f1_score: 0.7995 - val_fn: 35.0000 - val_fp: 35.0000 - val_loss: 0.4989 - val_precision: 0.8577 - val_recall: 0.8577 - val_tn: 457.0000 - val_tp: 211.0000\n",
      "Epoch 231/500\n",
      "3/3 - 1s - 226ms/step - accuracy: 0.9301 - auc: 0.9858 - categorical_accuracy: 0.9301 - f1_score: 0.9303 - fn: 309.0000 - fp: 299.0000 - loss: 0.2415 - precision: 0.9315 - recall: 0.9294 - tn: 8455.0000 - tp: 4068.0000 - val_accuracy: 0.8537 - val_auc: 0.9319 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7959 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5200 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 232/500\n",
      "3/3 - 1s - 189ms/step - accuracy: 0.9319 - auc: 0.9855 - categorical_accuracy: 0.9319 - f1_score: 0.9322 - fn: 302.0000 - fp: 298.0000 - loss: 0.2342 - precision: 0.9319 - recall: 0.9310 - tn: 8456.0000 - tp: 4075.0000 - val_accuracy: 0.8537 - val_auc: 0.9309 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7963 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5589 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 233/500\n",
      "3/3 - 1s - 187ms/step - accuracy: 0.9292 - auc: 0.9859 - categorical_accuracy: 0.9292 - f1_score: 0.9294 - fn: 313.0000 - fp: 307.0000 - loss: 0.2405 - precision: 0.9298 - recall: 0.9285 - tn: 8447.0000 - tp: 4064.0000 - val_accuracy: 0.8537 - val_auc: 0.9327 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7920 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.5265 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 234/500\n",
      "3/3 - 1s - 183ms/step - accuracy: 0.9287 - auc: 0.9855 - categorical_accuracy: 0.9287 - f1_score: 0.9289 - fn: 315.0000 - fp: 311.0000 - loss: 0.2391 - precision: 0.9289 - recall: 0.9280 - tn: 8443.0000 - tp: 4062.0000 - val_accuracy: 0.8415 - val_auc: 0.9242 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7822 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5844 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 235/500\n",
      "3/3 - 1s - 251ms/step - accuracy: 0.9269 - auc: 0.9865 - categorical_accuracy: 0.9269 - f1_score: 0.9270 - fn: 325.0000 - fp: 317.0000 - loss: 0.2359 - precision: 0.9274 - recall: 0.9257 - tn: 8437.0000 - tp: 4052.0000 - val_accuracy: 0.8496 - val_auc: 0.9312 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7873 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5275 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 236/500\n",
      "3/3 - 1s - 191ms/step - accuracy: 0.9267 - auc: 0.9858 - categorical_accuracy: 0.9267 - f1_score: 0.9269 - fn: 323.0000 - fp: 321.0000 - loss: 0.2402 - precision: 0.9266 - recall: 0.9262 - tn: 8433.0000 - tp: 4054.0000 - val_accuracy: 0.8537 - val_auc: 0.9269 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7921 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5451 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 237/500\n",
      "3/3 - 1s - 226ms/step - accuracy: 0.9319 - auc: 0.9863 - categorical_accuracy: 0.9319 - f1_score: 0.9320 - fn: 303.0000 - fp: 295.0000 - loss: 0.2344 - precision: 0.9325 - recall: 0.9308 - tn: 8459.0000 - tp: 4074.0000 - val_accuracy: 0.8089 - val_auc: 0.9208 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7488 - val_fn: 47.0000 - val_fp: 47.0000 - val_loss: 0.5923 - val_precision: 0.8089 - val_recall: 0.8089 - val_tn: 445.0000 - val_tp: 199.0000\n",
      "Epoch 238/500\n",
      "3/3 - 1s - 171ms/step - accuracy: 0.9305 - auc: 0.9866 - categorical_accuracy: 0.9305 - f1_score: 0.9307 - fn: 309.0000 - fp: 300.0000 - loss: 0.2364 - precision: 0.9313 - recall: 0.9294 - tn: 8454.0000 - tp: 4068.0000 - val_accuracy: 0.8415 - val_auc: 0.9356 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7817 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5139 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 239/500\n",
      "3/3 - 0s - 166ms/step - accuracy: 0.9324 - auc: 0.9870 - categorical_accuracy: 0.9324 - f1_score: 0.9326 - fn: 298.0000 - fp: 293.0000 - loss: 0.2275 - precision: 0.9330 - recall: 0.9319 - tn: 8461.0000 - tp: 4079.0000 - val_accuracy: 0.8171 - val_auc: 0.9307 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7591 - val_fn: 46.0000 - val_fp: 44.0000 - val_loss: 0.5494 - val_precision: 0.8197 - val_recall: 0.8130 - val_tn: 448.0000 - val_tp: 200.0000\n",
      "Epoch 240/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.9321 - auc: 0.9864 - categorical_accuracy: 0.9321 - f1_score: 0.9322 - fn: 306.0000 - fp: 296.0000 - loss: 0.2304 - precision: 0.9322 - recall: 0.9301 - tn: 8458.0000 - tp: 4071.0000 - val_accuracy: 0.8130 - val_auc: 0.9299 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7529 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.5461 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 241/500\n",
      "3/3 - 0s - 154ms/step - accuracy: 0.9289 - auc: 0.9870 - categorical_accuracy: 0.9289 - f1_score: 0.9289 - fn: 313.0000 - fp: 307.0000 - loss: 0.2283 - precision: 0.9298 - recall: 0.9285 - tn: 8447.0000 - tp: 4064.0000 - val_accuracy: 0.8333 - val_auc: 0.9310 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7718 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5379 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 242/500\n",
      "3/3 - 1s - 193ms/step - accuracy: 0.9257 - auc: 0.9865 - categorical_accuracy: 0.9257 - f1_score: 0.9262 - fn: 327.0000 - fp: 322.0000 - loss: 0.2327 - precision: 0.9263 - recall: 0.9253 - tn: 8432.0000 - tp: 4050.0000 - val_accuracy: 0.8415 - val_auc: 0.9329 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7829 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5256 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 243/500\n",
      "3/3 - 1s - 351ms/step - accuracy: 0.9287 - auc: 0.9858 - categorical_accuracy: 0.9287 - f1_score: 0.9289 - fn: 314.0000 - fp: 310.0000 - loss: 0.2362 - precision: 0.9291 - recall: 0.9283 - tn: 8444.0000 - tp: 4063.0000 - val_accuracy: 0.8496 - val_auc: 0.9329 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7917 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5215 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 244/500\n",
      "3/3 - 1s - 234ms/step - accuracy: 0.9305 - auc: 0.9866 - categorical_accuracy: 0.9305 - f1_score: 0.9308 - fn: 306.0000 - fp: 300.0000 - loss: 0.2288 - precision: 0.9314 - recall: 0.9301 - tn: 8454.0000 - tp: 4071.0000 - val_accuracy: 0.8496 - val_auc: 0.9371 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7924 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.4942 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 245/500\n",
      "3/3 - 1s - 201ms/step - accuracy: 0.9244 - auc: 0.9867 - categorical_accuracy: 0.9244 - f1_score: 0.9245 - fn: 332.0000 - fp: 327.0000 - loss: 0.2339 - precision: 0.9252 - recall: 0.9241 - tn: 8427.0000 - tp: 4045.0000 - val_accuracy: 0.8455 - val_auc: 0.9318 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7901 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5322 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 246/500\n",
      "3/3 - 1s - 206ms/step - accuracy: 0.9308 - auc: 0.9862 - categorical_accuracy: 0.9308 - f1_score: 0.9310 - fn: 307.0000 - fp: 300.0000 - loss: 0.2385 - precision: 0.9314 - recall: 0.9299 - tn: 8454.0000 - tp: 4070.0000 - val_accuracy: 0.8455 - val_auc: 0.9306 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7867 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5523 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 247/500\n",
      "3/3 - 1s - 236ms/step - accuracy: 0.9328 - auc: 0.9865 - categorical_accuracy: 0.9328 - f1_score: 0.9330 - fn: 295.0000 - fp: 293.0000 - loss: 0.2296 - precision: 0.9330 - recall: 0.9326 - tn: 8461.0000 - tp: 4082.0000 - val_accuracy: 0.8496 - val_auc: 0.9331 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7888 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5421 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 248/500\n",
      "3/3 - 1s - 246ms/step - accuracy: 0.9292 - auc: 0.9863 - categorical_accuracy: 0.9292 - f1_score: 0.9296 - fn: 313.0000 - fp: 310.0000 - loss: 0.2329 - precision: 0.9291 - recall: 0.9285 - tn: 8444.0000 - tp: 4064.0000 - val_accuracy: 0.8455 - val_auc: 0.9323 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7853 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5314 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 249/500\n",
      "3/3 - 1s - 168ms/step - accuracy: 0.9264 - auc: 0.9870 - categorical_accuracy: 0.9264 - f1_score: 0.9265 - fn: 324.0000 - fp: 320.0000 - loss: 0.2302 - precision: 0.9268 - recall: 0.9260 - tn: 8434.0000 - tp: 4053.0000 - val_accuracy: 0.8252 - val_auc: 0.9329 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7700 - val_fn: 44.0000 - val_fp: 42.0000 - val_loss: 0.5226 - val_precision: 0.8279 - val_recall: 0.8211 - val_tn: 450.0000 - val_tp: 202.0000\n",
      "Epoch 250/500\n",
      "3/3 - 1s - 228ms/step - accuracy: 0.9271 - auc: 0.9864 - categorical_accuracy: 0.9271 - f1_score: 0.9271 - fn: 323.0000 - fp: 318.0000 - loss: 0.2327 - precision: 0.9273 - recall: 0.9262 - tn: 8436.0000 - tp: 4054.0000 - val_accuracy: 0.8455 - val_auc: 0.9370 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7863 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5002 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 251/500\n",
      "3/3 - 1s - 364ms/step - accuracy: 0.9253 - auc: 0.9867 - categorical_accuracy: 0.9253 - f1_score: 0.9255 - fn: 331.0000 - fp: 325.0000 - loss: 0.2332 - precision: 0.9256 - recall: 0.9244 - tn: 8429.0000 - tp: 4046.0000 - val_accuracy: 0.8496 - val_auc: 0.9355 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7955 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5335 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 252/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9267 - auc: 0.9863 - categorical_accuracy: 0.9267 - f1_score: 0.9270 - fn: 324.0000 - fp: 317.0000 - loss: 0.2332 - precision: 0.9275 - recall: 0.9260 - tn: 8437.0000 - tp: 4053.0000 - val_accuracy: 0.8537 - val_auc: 0.9353 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7942 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5360 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 253/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9278 - auc: 0.9864 - categorical_accuracy: 0.9278 - f1_score: 0.9281 - fn: 321.0000 - fp: 315.0000 - loss: 0.2337 - precision: 0.9279 - recall: 0.9267 - tn: 8439.0000 - tp: 4056.0000 - val_accuracy: 0.8374 - val_auc: 0.9267 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7877 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5863 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 254/500\n",
      "3/3 - 0s - 154ms/step - accuracy: 0.9221 - auc: 0.9854 - categorical_accuracy: 0.9221 - f1_score: 0.9220 - fn: 342.0000 - fp: 339.0000 - loss: 0.2407 - precision: 0.9225 - recall: 0.9219 - tn: 8415.0000 - tp: 4035.0000 - val_accuracy: 0.8333 - val_auc: 0.9243 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7834 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.6040 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 255/500\n",
      "3/3 - 0s - 163ms/step - accuracy: 0.9255 - auc: 0.9855 - categorical_accuracy: 0.9255 - f1_score: 0.9254 - fn: 329.0000 - fp: 321.0000 - loss: 0.2399 - precision: 0.9265 - recall: 0.9248 - tn: 8433.0000 - tp: 4048.0000 - val_accuracy: 0.8374 - val_auc: 0.9309 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7860 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5503 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 256/500\n",
      "3/3 - 0s - 166ms/step - accuracy: 0.9276 - auc: 0.9871 - categorical_accuracy: 0.9276 - f1_score: 0.9277 - fn: 320.0000 - fp: 313.0000 - loss: 0.2298 - precision: 0.9284 - recall: 0.9269 - tn: 8441.0000 - tp: 4057.0000 - val_accuracy: 0.8415 - val_auc: 0.9313 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7900 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5752 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 257/500\n",
      "3/3 - 1s - 176ms/step - accuracy: 0.9294 - auc: 0.9862 - categorical_accuracy: 0.9294 - f1_score: 0.9294 - fn: 310.0000 - fp: 308.0000 - loss: 0.2341 - precision: 0.9296 - recall: 0.9292 - tn: 8446.0000 - tp: 4067.0000 - val_accuracy: 0.8415 - val_auc: 0.9321 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7856 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5432 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 258/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9278 - auc: 0.9869 - categorical_accuracy: 0.9278 - f1_score: 0.9280 - fn: 317.0000 - fp: 315.0000 - loss: 0.2311 - precision: 0.9280 - recall: 0.9276 - tn: 8439.0000 - tp: 4060.0000 - val_accuracy: 0.8171 - val_auc: 0.9294 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7633 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.5398 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 259/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9294 - auc: 0.9866 - categorical_accuracy: 0.9294 - f1_score: 0.9292 - fn: 313.0000 - fp: 307.0000 - loss: 0.2341 - precision: 0.9298 - recall: 0.9285 - tn: 8447.0000 - tp: 4064.0000 - val_accuracy: 0.8415 - val_auc: 0.9353 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7786 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.4949 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 260/500\n",
      "3/3 - 0s - 134ms/step - accuracy: 0.9289 - auc: 0.9857 - categorical_accuracy: 0.9289 - f1_score: 0.9292 - fn: 314.0000 - fp: 310.0000 - loss: 0.2382 - precision: 0.9291 - recall: 0.9283 - tn: 8444.0000 - tp: 4063.0000 - val_accuracy: 0.8293 - val_auc: 0.9222 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7744 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.5740 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 261/500\n",
      "3/3 - 0s - 148ms/step - accuracy: 0.9267 - auc: 0.9858 - categorical_accuracy: 0.9267 - f1_score: 0.9269 - fn: 322.0000 - fp: 319.0000 - loss: 0.2463 - precision: 0.9271 - recall: 0.9264 - tn: 8435.0000 - tp: 4055.0000 - val_accuracy: 0.8374 - val_auc: 0.9347 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7814 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5469 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 262/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9289 - auc: 0.9852 - categorical_accuracy: 0.9289 - f1_score: 0.9291 - fn: 315.0000 - fp: 310.0000 - loss: 0.2390 - precision: 0.9291 - recall: 0.9280 - tn: 8444.0000 - tp: 4062.0000 - val_accuracy: 0.8415 - val_auc: 0.9388 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7839 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5006 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 263/500\n",
      "3/3 - 0s - 132ms/step - accuracy: 0.9253 - auc: 0.9851 - categorical_accuracy: 0.9253 - f1_score: 0.9254 - fn: 331.0000 - fp: 324.0000 - loss: 0.2422 - precision: 0.9259 - recall: 0.9244 - tn: 8430.0000 - tp: 4046.0000 - val_accuracy: 0.8008 - val_auc: 0.9258 - val_categorical_accuracy: 0.8008 - val_f1_score: 0.7530 - val_fn: 49.0000 - val_fp: 48.0000 - val_loss: 0.5766 - val_precision: 0.8041 - val_recall: 0.8008 - val_tn: 444.0000 - val_tp: 197.0000\n",
      "Epoch 264/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9237 - auc: 0.9850 - categorical_accuracy: 0.9237 - f1_score: 0.9231 - fn: 344.0000 - fp: 329.0000 - loss: 0.2501 - precision: 0.9246 - recall: 0.9214 - tn: 8425.0000 - tp: 4033.0000 - val_accuracy: 0.8415 - val_auc: 0.9324 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7874 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5538 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 265/500\n",
      "3/3 - 0s - 161ms/step - accuracy: 0.9287 - auc: 0.9850 - categorical_accuracy: 0.9287 - f1_score: 0.9287 - fn: 320.0000 - fp: 305.0000 - loss: 0.2444 - precision: 0.9301 - recall: 0.9269 - tn: 8449.0000 - tp: 4057.0000 - val_accuracy: 0.8455 - val_auc: 0.9329 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7893 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5403 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 266/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9283 - auc: 0.9866 - categorical_accuracy: 0.9283 - f1_score: 0.9284 - fn: 319.0000 - fp: 310.0000 - loss: 0.2383 - precision: 0.9290 - recall: 0.9271 - tn: 8444.0000 - tp: 4058.0000 - val_accuracy: 0.8333 - val_auc: 0.9247 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7789 - val_fn: 41.0000 - val_fp: 41.0000 - val_loss: 0.6144 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 451.0000 - val_tp: 205.0000\n",
      "Epoch 267/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9317 - auc: 0.9859 - categorical_accuracy: 0.9317 - f1_score: 0.9316 - fn: 303.0000 - fp: 293.0000 - loss: 0.2421 - precision: 0.9329 - recall: 0.9308 - tn: 8461.0000 - tp: 4074.0000 - val_accuracy: 0.8537 - val_auc: 0.9294 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8012 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.5567 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 268/500\n",
      "3/3 - 1s - 276ms/step - accuracy: 0.9248 - auc: 0.9853 - categorical_accuracy: 0.9248 - f1_score: 0.9252 - fn: 337.0000 - fp: 314.0000 - loss: 0.2445 - precision: 0.9279 - recall: 0.9230 - tn: 8440.0000 - tp: 4040.0000 - val_accuracy: 0.8455 - val_auc: 0.9262 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7915 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.6100 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 269/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9271 - auc: 0.9859 - categorical_accuracy: 0.9271 - f1_score: 0.9269 - fn: 322.0000 - fp: 312.0000 - loss: 0.2380 - precision: 0.9286 - recall: 0.9264 - tn: 8442.0000 - tp: 4055.0000 - val_accuracy: 0.8496 - val_auc: 0.9300 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7940 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5910 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 270/500\n",
      "3/3 - 1s - 167ms/step - accuracy: 0.9310 - auc: 0.9869 - categorical_accuracy: 0.9310 - f1_score: 0.9312 - fn: 302.0000 - fp: 301.0000 - loss: 0.2301 - precision: 0.9312 - recall: 0.9310 - tn: 8453.0000 - tp: 4075.0000 - val_accuracy: 0.8496 - val_auc: 0.9332 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7906 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5539 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 271/500\n",
      "3/3 - 1s - 199ms/step - accuracy: 0.9303 - auc: 0.9860 - categorical_accuracy: 0.9303 - f1_score: 0.9307 - fn: 310.0000 - fp: 304.0000 - loss: 0.2362 - precision: 0.9305 - recall: 0.9292 - tn: 8450.0000 - tp: 4067.0000 - val_accuracy: 0.8049 - val_auc: 0.9284 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7510 - val_fn: 48.0000 - val_fp: 48.0000 - val_loss: 0.5686 - val_precision: 0.8049 - val_recall: 0.8049 - val_tn: 444.0000 - val_tp: 198.0000\n",
      "Epoch 272/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9255 - auc: 0.9860 - categorical_accuracy: 0.9255 - f1_score: 0.9252 - fn: 327.0000 - fp: 322.0000 - loss: 0.2394 - precision: 0.9263 - recall: 0.9253 - tn: 8432.0000 - tp: 4050.0000 - val_accuracy: 0.8455 - val_auc: 0.9380 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7828 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.4960 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 273/500\n",
      "3/3 - 0s - 165ms/step - accuracy: 0.9269 - auc: 0.9865 - categorical_accuracy: 0.9269 - f1_score: 0.9270 - fn: 321.0000 - fp: 318.0000 - loss: 0.2382 - precision: 0.9273 - recall: 0.9267 - tn: 8436.0000 - tp: 4056.0000 - val_accuracy: 0.8211 - val_auc: 0.9333 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7643 - val_fn: 44.0000 - val_fp: 44.0000 - val_loss: 0.5398 - val_precision: 0.8211 - val_recall: 0.8211 - val_tn: 448.0000 - val_tp: 202.0000\n",
      "Epoch 274/500\n",
      "3/3 - 1s - 207ms/step - accuracy: 0.9251 - auc: 0.9864 - categorical_accuracy: 0.9251 - f1_score: 0.9250 - fn: 333.0000 - fp: 323.0000 - loss: 0.2358 - precision: 0.9260 - recall: 0.9239 - tn: 8431.0000 - tp: 4044.0000 - val_accuracy: 0.8496 - val_auc: 0.9347 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7888 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5418 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 275/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9278 - auc: 0.9861 - categorical_accuracy: 0.9278 - f1_score: 0.9284 - fn: 317.0000 - fp: 316.0000 - loss: 0.2377 - precision: 0.9278 - recall: 0.9276 - tn: 8438.0000 - tp: 4060.0000 - val_accuracy: 0.8415 - val_auc: 0.9329 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7839 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5609 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 276/500\n",
      "3/3 - 0s - 138ms/step - accuracy: 0.9269 - auc: 0.9865 - categorical_accuracy: 0.9269 - f1_score: 0.9268 - fn: 325.0000 - fp: 319.0000 - loss: 0.2346 - precision: 0.9270 - recall: 0.9257 - tn: 8435.0000 - tp: 4052.0000 - val_accuracy: 0.8171 - val_auc: 0.9326 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7622 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.5674 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 277/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9296 - auc: 0.9865 - categorical_accuracy: 0.9296 - f1_score: 0.9296 - fn: 309.0000 - fp: 306.0000 - loss: 0.2332 - precision: 0.9300 - recall: 0.9294 - tn: 8448.0000 - tp: 4068.0000 - val_accuracy: 0.8374 - val_auc: 0.9366 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7797 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5379 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 278/500\n",
      "3/3 - 1s - 192ms/step - accuracy: 0.9299 - auc: 0.9862 - categorical_accuracy: 0.9299 - f1_score: 0.9300 - fn: 312.0000 - fp: 305.0000 - loss: 0.2328 - precision: 0.9302 - recall: 0.9287 - tn: 8449.0000 - tp: 4065.0000 - val_accuracy: 0.8415 - val_auc: 0.9375 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7886 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5268 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 279/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9292 - auc: 0.9868 - categorical_accuracy: 0.9292 - f1_score: 0.9293 - fn: 310.0000 - fp: 308.0000 - loss: 0.2307 - precision: 0.9296 - recall: 0.9292 - tn: 8446.0000 - tp: 4067.0000 - val_accuracy: 0.8415 - val_auc: 0.9380 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7805 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5168 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 280/500\n",
      "3/3 - 0s - 150ms/step - accuracy: 0.9301 - auc: 0.9872 - categorical_accuracy: 0.9301 - f1_score: 0.9302 - fn: 309.0000 - fp: 304.0000 - loss: 0.2266 - precision: 0.9305 - recall: 0.9294 - tn: 8450.0000 - tp: 4068.0000 - val_accuracy: 0.8455 - val_auc: 0.9417 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7824 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.4926 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 281/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9223 - auc: 0.9857 - categorical_accuracy: 0.9223 - f1_score: 0.9226 - fn: 344.0000 - fp: 336.0000 - loss: 0.2412 - precision: 0.9231 - recall: 0.9214 - tn: 8418.0000 - tp: 4033.0000 - val_accuracy: 0.8496 - val_auc: 0.9372 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7895 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5126 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 282/500\n",
      "3/3 - 0s - 154ms/step - accuracy: 0.9310 - auc: 0.9861 - categorical_accuracy: 0.9310 - f1_score: 0.9313 - fn: 304.0000 - fp: 295.0000 - loss: 0.2355 - precision: 0.9325 - recall: 0.9305 - tn: 8459.0000 - tp: 4073.0000 - val_accuracy: 0.8333 - val_auc: 0.9298 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7829 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5822 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 283/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9267 - auc: 0.9852 - categorical_accuracy: 0.9267 - f1_score: 0.9265 - fn: 325.0000 - fp: 319.0000 - loss: 0.2393 - precision: 0.9270 - recall: 0.9257 - tn: 8435.0000 - tp: 4052.0000 - val_accuracy: 0.8415 - val_auc: 0.9367 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7821 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5170 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 284/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9303 - auc: 0.9865 - categorical_accuracy: 0.9303 - f1_score: 0.9306 - fn: 309.0000 - fp: 302.0000 - loss: 0.2339 - precision: 0.9309 - recall: 0.9294 - tn: 8452.0000 - tp: 4068.0000 - val_accuracy: 0.8537 - val_auc: 0.9369 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7906 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5185 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 285/500\n",
      "3/3 - 1s - 288ms/step - accuracy: 0.9278 - auc: 0.9862 - categorical_accuracy: 0.9278 - f1_score: 0.9281 - fn: 323.0000 - fp: 311.0000 - loss: 0.2348 - precision: 0.9288 - recall: 0.9262 - tn: 8443.0000 - tp: 4054.0000 - val_accuracy: 0.8496 - val_auc: 0.9361 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7887 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5354 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 286/500\n",
      "3/3 - 1s - 172ms/step - accuracy: 0.9253 - auc: 0.9859 - categorical_accuracy: 0.9253 - f1_score: 0.9255 - fn: 335.0000 - fp: 325.0000 - loss: 0.2427 - precision: 0.9256 - recall: 0.9235 - tn: 8429.0000 - tp: 4042.0000 - val_accuracy: 0.8496 - val_auc: 0.9385 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7816 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5046 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 287/500\n",
      "3/3 - 0s - 135ms/step - accuracy: 0.9285 - auc: 0.9864 - categorical_accuracy: 0.9285 - f1_score: 0.9288 - fn: 316.0000 - fp: 306.0000 - loss: 0.2341 - precision: 0.9299 - recall: 0.9278 - tn: 8448.0000 - tp: 4061.0000 - val_accuracy: 0.8455 - val_auc: 0.9325 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7864 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5408 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 288/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9294 - auc: 0.9851 - categorical_accuracy: 0.9294 - f1_score: 0.9293 - fn: 314.0000 - fp: 302.0000 - loss: 0.2429 - precision: 0.9308 - recall: 0.9283 - tn: 8452.0000 - tp: 4063.0000 - val_accuracy: 0.8496 - val_auc: 0.9354 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7940 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5261 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 289/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9244 - auc: 0.9864 - categorical_accuracy: 0.9244 - f1_score: 0.9244 - fn: 334.0000 - fp: 328.0000 - loss: 0.2355 - precision: 0.9250 - recall: 0.9237 - tn: 8426.0000 - tp: 4043.0000 - val_accuracy: 0.8455 - val_auc: 0.9396 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7855 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.4981 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 290/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9308 - auc: 0.9855 - categorical_accuracy: 0.9308 - f1_score: 0.9310 - fn: 311.0000 - fp: 296.0000 - loss: 0.2371 - precision: 0.9321 - recall: 0.9289 - tn: 8458.0000 - tp: 4066.0000 - val_accuracy: 0.8049 - val_auc: 0.9362 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7510 - val_fn: 48.0000 - val_fp: 48.0000 - val_loss: 0.5307 - val_precision: 0.8049 - val_recall: 0.8049 - val_tn: 444.0000 - val_tp: 198.0000\n",
      "Epoch 291/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9299 - auc: 0.9877 - categorical_accuracy: 0.9299 - f1_score: 0.9297 - fn: 311.0000 - fp: 302.0000 - loss: 0.2254 - precision: 0.9309 - recall: 0.9289 - tn: 8452.0000 - tp: 4066.0000 - val_accuracy: 0.8211 - val_auc: 0.9312 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7715 - val_fn: 45.0000 - val_fp: 41.0000 - val_loss: 0.5756 - val_precision: 0.8306 - val_recall: 0.8171 - val_tn: 451.0000 - val_tp: 201.0000\n",
      "Epoch 292/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9230 - auc: 0.9855 - categorical_accuracy: 0.9230 - f1_score: 0.9229 - fn: 338.0000 - fp: 330.0000 - loss: 0.2423 - precision: 0.9245 - recall: 0.9228 - tn: 8424.0000 - tp: 4039.0000 - val_accuracy: 0.8455 - val_auc: 0.9381 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7881 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5427 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 293/500\n",
      "3/3 - 1s - 177ms/step - accuracy: 0.9287 - auc: 0.9854 - categorical_accuracy: 0.9287 - f1_score: 0.9293 - fn: 314.0000 - fp: 311.0000 - loss: 0.2466 - precision: 0.9289 - recall: 0.9283 - tn: 8443.0000 - tp: 4063.0000 - val_accuracy: 0.8252 - val_auc: 0.9298 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7719 - val_fn: 44.0000 - val_fp: 43.0000 - val_loss: 0.6046 - val_precision: 0.8245 - val_recall: 0.8211 - val_tn: 449.0000 - val_tp: 202.0000\n",
      "Epoch 294/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9317 - auc: 0.9859 - categorical_accuracy: 0.9317 - f1_score: 0.9317 - fn: 302.0000 - fp: 293.0000 - loss: 0.2388 - precision: 0.9329 - recall: 0.9310 - tn: 8461.0000 - tp: 4075.0000 - val_accuracy: 0.8455 - val_auc: 0.9275 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7943 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.6207 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 295/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9285 - auc: 0.9860 - categorical_accuracy: 0.9285 - f1_score: 0.9286 - fn: 318.0000 - fp: 306.0000 - loss: 0.2381 - precision: 0.9299 - recall: 0.9273 - tn: 8448.0000 - tp: 4059.0000 - val_accuracy: 0.8537 - val_auc: 0.9329 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8012 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5735 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 296/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9251 - auc: 0.9864 - categorical_accuracy: 0.9251 - f1_score: 0.9253 - fn: 328.0000 - fp: 322.0000 - loss: 0.2345 - precision: 0.9263 - recall: 0.9251 - tn: 8432.0000 - tp: 4049.0000 - val_accuracy: 0.8211 - val_auc: 0.9310 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7681 - val_fn: 44.0000 - val_fp: 42.0000 - val_loss: 0.6122 - val_precision: 0.8279 - val_recall: 0.8211 - val_tn: 450.0000 - val_tp: 202.0000\n",
      "Epoch 297/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9289 - auc: 0.9862 - categorical_accuracy: 0.9289 - f1_score: 0.9290 - fn: 315.0000 - fp: 308.0000 - loss: 0.2385 - precision: 0.9295 - recall: 0.9280 - tn: 8446.0000 - tp: 4062.0000 - val_accuracy: 0.8496 - val_auc: 0.9351 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7924 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5632 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 298/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9267 - auc: 0.9856 - categorical_accuracy: 0.9267 - f1_score: 0.9271 - fn: 327.0000 - fp: 318.0000 - loss: 0.2422 - precision: 0.9272 - recall: 0.9253 - tn: 8436.0000 - tp: 4050.0000 - val_accuracy: 0.8455 - val_auc: 0.9366 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7881 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5235 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 299/500\n",
      "3/3 - 0s - 134ms/step - accuracy: 0.9269 - auc: 0.9860 - categorical_accuracy: 0.9269 - f1_score: 0.9272 - fn: 324.0000 - fp: 314.0000 - loss: 0.2385 - precision: 0.9281 - recall: 0.9260 - tn: 8440.0000 - tp: 4053.0000 - val_accuracy: 0.8293 - val_auc: 0.9317 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7816 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.5615 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 300/500\n",
      "3/3 - 0s - 163ms/step - accuracy: 0.9276 - auc: 0.9861 - categorical_accuracy: 0.9276 - f1_score: 0.9274 - fn: 322.0000 - fp: 312.0000 - loss: 0.2374 - precision: 0.9286 - recall: 0.9264 - tn: 8442.0000 - tp: 4055.0000 - val_accuracy: 0.8455 - val_auc: 0.9385 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7864 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5178 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 301/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9278 - auc: 0.9861 - categorical_accuracy: 0.9278 - f1_score: 0.9280 - fn: 318.0000 - fp: 312.0000 - loss: 0.2334 - precision: 0.9286 - recall: 0.9273 - tn: 8442.0000 - tp: 4059.0000 - val_accuracy: 0.8293 - val_auc: 0.9353 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7714 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.5184 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 302/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9255 - auc: 0.9869 - categorical_accuracy: 0.9255 - f1_score: 0.9256 - fn: 332.0000 - fp: 322.0000 - loss: 0.2325 - precision: 0.9263 - recall: 0.9241 - tn: 8432.0000 - tp: 4045.0000 - val_accuracy: 0.8374 - val_auc: 0.9330 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7745 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5338 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 303/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9262 - auc: 0.9871 - categorical_accuracy: 0.9262 - f1_score: 0.9266 - fn: 324.0000 - fp: 321.0000 - loss: 0.2310 - precision: 0.9266 - recall: 0.9260 - tn: 8433.0000 - tp: 4053.0000 - val_accuracy: 0.8374 - val_auc: 0.9372 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7759 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5390 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 304/500\n",
      "3/3 - 0s - 145ms/step - accuracy: 0.9262 - auc: 0.9851 - categorical_accuracy: 0.9262 - f1_score: 0.9265 - fn: 325.0000 - fp: 323.0000 - loss: 0.2413 - precision: 0.9262 - recall: 0.9257 - tn: 8431.0000 - tp: 4052.0000 - val_accuracy: 0.8293 - val_auc: 0.9372 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7730 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5349 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 305/500\n",
      "3/3 - 0s - 146ms/step - accuracy: 0.9267 - auc: 0.9856 - categorical_accuracy: 0.9267 - f1_score: 0.9270 - fn: 322.0000 - fp: 320.0000 - loss: 0.2363 - precision: 0.9269 - recall: 0.9264 - tn: 8434.0000 - tp: 4055.0000 - val_accuracy: 0.7846 - val_auc: 0.9111 - val_categorical_accuracy: 0.7846 - val_f1_score: 0.7460 - val_fn: 53.0000 - val_fp: 53.0000 - val_loss: 0.6869 - val_precision: 0.7846 - val_recall: 0.7846 - val_tn: 439.0000 - val_tp: 193.0000\n",
      "Epoch 306/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9184 - auc: 0.9835 - categorical_accuracy: 0.9184 - f1_score: 0.9178 - fn: 360.0000 - fp: 352.0000 - loss: 0.2570 - precision: 0.9194 - recall: 0.9178 - tn: 8402.0000 - tp: 4017.0000 - val_accuracy: 0.8333 - val_auc: 0.9329 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7805 - val_fn: 41.0000 - val_fp: 41.0000 - val_loss: 0.5405 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 451.0000 - val_tp: 205.0000\n",
      "Epoch 307/500\n",
      "3/3 - 0s - 138ms/step - accuracy: 0.9260 - auc: 0.9826 - categorical_accuracy: 0.9260 - f1_score: 0.9262 - fn: 327.0000 - fp: 320.0000 - loss: 0.2577 - precision: 0.9268 - recall: 0.9253 - tn: 8434.0000 - tp: 4050.0000 - val_accuracy: 0.8496 - val_auc: 0.9339 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7909 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5260 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 308/500\n",
      "3/3 - 0s - 147ms/step - accuracy: 0.9308 - auc: 0.9859 - categorical_accuracy: 0.9308 - f1_score: 0.9310 - fn: 305.0000 - fp: 301.0000 - loss: 0.2362 - precision: 0.9312 - recall: 0.9303 - tn: 8453.0000 - tp: 4072.0000 - val_accuracy: 0.8130 - val_auc: 0.9210 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7645 - val_fn: 47.0000 - val_fp: 46.0000 - val_loss: 0.6192 - val_precision: 0.8122 - val_recall: 0.8089 - val_tn: 446.0000 - val_tp: 199.0000\n",
      "Epoch 309/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9273 - auc: 0.9851 - categorical_accuracy: 0.9273 - f1_score: 0.9271 - fn: 326.0000 - fp: 315.0000 - loss: 0.2456 - precision: 0.9279 - recall: 0.9255 - tn: 8439.0000 - tp: 4051.0000 - val_accuracy: 0.8415 - val_auc: 0.9316 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7840 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5278 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 310/500\n",
      "3/3 - 0s - 132ms/step - accuracy: 0.9230 - auc: 0.9859 - categorical_accuracy: 0.9230 - f1_score: 0.9234 - fn: 339.0000 - fp: 333.0000 - loss: 0.2423 - precision: 0.9238 - recall: 0.9225 - tn: 8421.0000 - tp: 4038.0000 - val_accuracy: 0.8537 - val_auc: 0.9327 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7950 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.5435 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 311/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9276 - auc: 0.9852 - categorical_accuracy: 0.9276 - f1_score: 0.9280 - fn: 317.0000 - fp: 314.0000 - loss: 0.2444 - precision: 0.9282 - recall: 0.9276 - tn: 8440.0000 - tp: 4060.0000 - val_accuracy: 0.8496 - val_auc: 0.9301 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7953 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5973 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 312/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9283 - auc: 0.9859 - categorical_accuracy: 0.9283 - f1_score: 0.9283 - fn: 316.0000 - fp: 309.0000 - loss: 0.2374 - precision: 0.9293 - recall: 0.9278 - tn: 8445.0000 - tp: 4061.0000 - val_accuracy: 0.8374 - val_auc: 0.9300 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7816 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5864 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 313/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9267 - auc: 0.9860 - categorical_accuracy: 0.9267 - f1_score: 0.9268 - fn: 325.0000 - fp: 318.0000 - loss: 0.2373 - precision: 0.9272 - recall: 0.9257 - tn: 8436.0000 - tp: 4052.0000 - val_accuracy: 0.8455 - val_auc: 0.9375 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7898 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5487 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 314/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9283 - auc: 0.9857 - categorical_accuracy: 0.9283 - f1_score: 0.9284 - fn: 316.0000 - fp: 313.0000 - loss: 0.2363 - precision: 0.9284 - recall: 0.9278 - tn: 8441.0000 - tp: 4061.0000 - val_accuracy: 0.8537 - val_auc: 0.9372 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8025 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5388 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 315/500\n",
      "3/3 - 0s - 137ms/step - accuracy: 0.9276 - auc: 0.9860 - categorical_accuracy: 0.9276 - f1_score: 0.9275 - fn: 320.0000 - fp: 314.0000 - loss: 0.2340 - precision: 0.9282 - recall: 0.9269 - tn: 8440.0000 - tp: 4057.0000 - val_accuracy: 0.8252 - val_auc: 0.9348 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7698 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5368 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 316/500\n",
      "3/3 - 0s - 149ms/step - accuracy: 0.9289 - auc: 0.9865 - categorical_accuracy: 0.9289 - f1_score: 0.9292 - fn: 317.0000 - fp: 308.0000 - loss: 0.2321 - precision: 0.9295 - recall: 0.9276 - tn: 8446.0000 - tp: 4060.0000 - val_accuracy: 0.8577 - val_auc: 0.9345 - val_categorical_accuracy: 0.8577 - val_f1_score: 0.8030 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.5332 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 317/500\n",
      "3/3 - 0s - 146ms/step - accuracy: 0.9271 - auc: 0.9853 - categorical_accuracy: 0.9271 - f1_score: 0.9271 - fn: 324.0000 - fp: 316.0000 - loss: 0.2414 - precision: 0.9277 - recall: 0.9260 - tn: 8438.0000 - tp: 4053.0000 - val_accuracy: 0.8537 - val_auc: 0.9353 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7942 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5337 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 318/500\n",
      "3/3 - 1s - 224ms/step - accuracy: 0.9251 - auc: 0.9862 - categorical_accuracy: 0.9251 - f1_score: 0.9252 - fn: 331.0000 - fp: 325.0000 - loss: 0.2346 - precision: 0.9256 - recall: 0.9244 - tn: 8429.0000 - tp: 4046.0000 - val_accuracy: 0.8374 - val_auc: 0.9339 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7813 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5681 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 319/500\n",
      "3/3 - 1s - 230ms/step - accuracy: 0.9299 - auc: 0.9866 - categorical_accuracy: 0.9299 - f1_score: 0.9299 - fn: 309.0000 - fp: 300.0000 - loss: 0.2308 - precision: 0.9313 - recall: 0.9294 - tn: 8454.0000 - tp: 4068.0000 - val_accuracy: 0.8333 - val_auc: 0.9324 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7790 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5886 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 320/500\n",
      "3/3 - 1s - 261ms/step - accuracy: 0.9273 - auc: 0.9861 - categorical_accuracy: 0.9273 - f1_score: 0.9273 - fn: 321.0000 - fp: 311.0000 - loss: 0.2366 - precision: 0.9288 - recall: 0.9267 - tn: 8443.0000 - tp: 4056.0000 - val_accuracy: 0.8455 - val_auc: 0.9341 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7863 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5445 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 321/500\n",
      "3/3 - 1s - 295ms/step - accuracy: 0.9333 - auc: 0.9873 - categorical_accuracy: 0.9333 - f1_score: 0.9333 - fn: 298.0000 - fp: 286.0000 - loss: 0.2259 - precision: 0.9345 - recall: 0.9319 - tn: 8468.0000 - tp: 4079.0000 - val_accuracy: 0.8415 - val_auc: 0.9352 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7821 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5452 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 322/500\n",
      "3/3 - 0s - 155ms/step - accuracy: 0.9296 - auc: 0.9849 - categorical_accuracy: 0.9296 - f1_score: 0.9298 - fn: 311.0000 - fp: 303.0000 - loss: 0.2389 - precision: 0.9306 - recall: 0.9289 - tn: 8451.0000 - tp: 4066.0000 - val_accuracy: 0.8455 - val_auc: 0.9369 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7799 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5109 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 323/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9264 - auc: 0.9870 - categorical_accuracy: 0.9264 - f1_score: 0.9267 - fn: 323.0000 - fp: 316.0000 - loss: 0.2334 - precision: 0.9277 - recall: 0.9262 - tn: 8438.0000 - tp: 4054.0000 - val_accuracy: 0.8415 - val_auc: 0.9341 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7902 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5362 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 324/500\n",
      "3/3 - 1s - 173ms/step - accuracy: 0.9269 - auc: 0.9864 - categorical_accuracy: 0.9269 - f1_score: 0.9267 - fn: 329.0000 - fp: 320.0000 - loss: 0.2331 - precision: 0.9267 - recall: 0.9248 - tn: 8434.0000 - tp: 4048.0000 - val_accuracy: 0.8211 - val_auc: 0.9294 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7753 - val_fn: 44.0000 - val_fp: 44.0000 - val_loss: 0.5621 - val_precision: 0.8211 - val_recall: 0.8211 - val_tn: 448.0000 - val_tp: 202.0000\n",
      "Epoch 325/500\n",
      "3/3 - 1s - 189ms/step - accuracy: 0.9251 - auc: 0.9847 - categorical_accuracy: 0.9251 - f1_score: 0.9249 - fn: 337.0000 - fp: 323.0000 - loss: 0.2485 - precision: 0.9260 - recall: 0.9230 - tn: 8431.0000 - tp: 4040.0000 - val_accuracy: 0.8496 - val_auc: 0.9343 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7931 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5477 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 326/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9246 - auc: 0.9860 - categorical_accuracy: 0.9246 - f1_score: 0.9247 - fn: 333.0000 - fp: 323.0000 - loss: 0.2388 - precision: 0.9260 - recall: 0.9239 - tn: 8431.0000 - tp: 4044.0000 - val_accuracy: 0.8455 - val_auc: 0.9376 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7844 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5135 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 327/500\n",
      "3/3 - 0s - 165ms/step - accuracy: 0.9269 - auc: 0.9863 - categorical_accuracy: 0.9269 - f1_score: 0.9274 - fn: 327.0000 - fp: 319.0000 - loss: 0.2375 - precision: 0.9270 - recall: 0.9253 - tn: 8435.0000 - tp: 4050.0000 - val_accuracy: 0.8455 - val_auc: 0.9340 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7882 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5512 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 328/500\n",
      "3/3 - 1s - 186ms/step - accuracy: 0.9278 - auc: 0.9863 - categorical_accuracy: 0.9278 - f1_score: 0.9278 - fn: 319.0000 - fp: 312.0000 - loss: 0.2359 - precision: 0.9286 - recall: 0.9271 - tn: 8442.0000 - tp: 4058.0000 - val_accuracy: 0.8537 - val_auc: 0.9286 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8012 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5759 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 329/500\n",
      "3/3 - 1s - 174ms/step - accuracy: 0.9289 - auc: 0.9864 - categorical_accuracy: 0.9289 - f1_score: 0.9289 - fn: 318.0000 - fp: 306.0000 - loss: 0.2325 - precision: 0.9299 - recall: 0.9273 - tn: 8448.0000 - tp: 4059.0000 - val_accuracy: 0.8333 - val_auc: 0.9288 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7816 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5548 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 330/500\n",
      "3/3 - 1s - 183ms/step - accuracy: 0.9264 - auc: 0.9867 - categorical_accuracy: 0.9264 - f1_score: 0.9261 - fn: 329.0000 - fp: 312.0000 - loss: 0.2318 - precision: 0.9284 - recall: 0.9248 - tn: 8442.0000 - tp: 4048.0000 - val_accuracy: 0.8496 - val_auc: 0.9340 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7940 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5345 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 331/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9312 - auc: 0.9866 - categorical_accuracy: 0.9312 - f1_score: 0.9314 - fn: 304.0000 - fp: 295.0000 - loss: 0.2300 - precision: 0.9325 - recall: 0.9305 - tn: 8459.0000 - tp: 4073.0000 - val_accuracy: 0.8455 - val_auc: 0.9327 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7898 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5435 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 332/500\n",
      "3/3 - 0s - 138ms/step - accuracy: 0.9262 - auc: 0.9860 - categorical_accuracy: 0.9262 - f1_score: 0.9261 - fn: 324.0000 - fp: 319.0000 - loss: 0.2368 - precision: 0.9270 - recall: 0.9260 - tn: 8435.0000 - tp: 4053.0000 - val_accuracy: 0.8455 - val_auc: 0.9361 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7928 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5150 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 333/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.9280 - auc: 0.9869 - categorical_accuracy: 0.9280 - f1_score: 0.9280 - fn: 319.0000 - fp: 311.0000 - loss: 0.2318 - precision: 0.9288 - recall: 0.9271 - tn: 8443.0000 - tp: 4058.0000 - val_accuracy: 0.8496 - val_auc: 0.9411 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7855 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.4845 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 334/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9287 - auc: 0.9857 - categorical_accuracy: 0.9287 - f1_score: 0.9291 - fn: 313.0000 - fp: 311.0000 - loss: 0.2334 - precision: 0.9289 - recall: 0.9285 - tn: 8443.0000 - tp: 4064.0000 - val_accuracy: 0.8496 - val_auc: 0.9384 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7884 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.4902 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 335/500\n",
      "3/3 - 1s - 174ms/step - accuracy: 0.9301 - auc: 0.9866 - categorical_accuracy: 0.9301 - f1_score: 0.9303 - fn: 309.0000 - fp: 299.0000 - loss: 0.2311 - precision: 0.9315 - recall: 0.9294 - tn: 8455.0000 - tp: 4068.0000 - val_accuracy: 0.8537 - val_auc: 0.9395 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7980 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.4782 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 336/500\n",
      "3/3 - 1s - 206ms/step - accuracy: 0.9305 - auc: 0.9859 - categorical_accuracy: 0.9305 - f1_score: 0.9305 - fn: 311.0000 - fp: 300.0000 - loss: 0.2357 - precision: 0.9313 - recall: 0.9289 - tn: 8454.0000 - tp: 4066.0000 - val_accuracy: 0.8455 - val_auc: 0.9346 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7845 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5213 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 337/500\n",
      "3/3 - 1s - 201ms/step - accuracy: 0.9283 - auc: 0.9851 - categorical_accuracy: 0.9283 - f1_score: 0.9284 - fn: 314.0000 - fp: 314.0000 - loss: 0.2403 - precision: 0.9283 - recall: 0.9283 - tn: 8440.0000 - tp: 4063.0000 - val_accuracy: 0.8415 - val_auc: 0.9360 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7787 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5555 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 338/500\n",
      "3/3 - 1s - 170ms/step - accuracy: 0.9278 - auc: 0.9853 - categorical_accuracy: 0.9278 - f1_score: 0.9281 - fn: 319.0000 - fp: 316.0000 - loss: 0.2438 - precision: 0.9278 - recall: 0.9271 - tn: 8438.0000 - tp: 4058.0000 - val_accuracy: 0.8455 - val_auc: 0.9370 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7799 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5251 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 339/500\n",
      "3/3 - 0s - 166ms/step - accuracy: 0.9198 - auc: 0.9835 - categorical_accuracy: 0.9198 - f1_score: 0.9201 - fn: 354.0000 - fp: 348.0000 - loss: 0.2563 - precision: 0.9204 - recall: 0.9191 - tn: 8406.0000 - tp: 4023.0000 - val_accuracy: 0.8455 - val_auc: 0.9341 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7898 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5294 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 340/500\n",
      "3/3 - 1s - 281ms/step - accuracy: 0.9232 - auc: 0.9855 - categorical_accuracy: 0.9232 - f1_score: 0.9232 - fn: 338.0000 - fp: 332.0000 - loss: 0.2437 - precision: 0.9240 - recall: 0.9228 - tn: 8422.0000 - tp: 4039.0000 - val_accuracy: 0.8130 - val_auc: 0.9279 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7566 - val_fn: 47.0000 - val_fp: 45.0000 - val_loss: 0.6015 - val_precision: 0.8156 - val_recall: 0.8089 - val_tn: 447.0000 - val_tp: 199.0000\n",
      "Epoch 341/500\n",
      "3/3 - 1s - 336ms/step - accuracy: 0.9289 - auc: 0.9863 - categorical_accuracy: 0.9289 - f1_score: 0.9288 - fn: 312.0000 - fp: 308.0000 - loss: 0.2377 - precision: 0.9296 - recall: 0.9287 - tn: 8446.0000 - tp: 4065.0000 - val_accuracy: 0.8455 - val_auc: 0.9308 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7989 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5480 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 342/500\n",
      "3/3 - 1s - 241ms/step - accuracy: 0.9292 - auc: 0.9852 - categorical_accuracy: 0.9292 - f1_score: 0.9293 - fn: 313.0000 - fp: 309.0000 - loss: 0.2471 - precision: 0.9293 - recall: 0.9285 - tn: 8445.0000 - tp: 4064.0000 - val_accuracy: 0.8537 - val_auc: 0.9326 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7950 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5334 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 343/500\n",
      "3/3 - 1s - 188ms/step - accuracy: 0.9285 - auc: 0.9864 - categorical_accuracy: 0.9285 - f1_score: 0.9289 - fn: 319.0000 - fp: 309.0000 - loss: 0.2406 - precision: 0.9292 - recall: 0.9271 - tn: 8445.0000 - tp: 4058.0000 - val_accuracy: 0.8374 - val_auc: 0.9255 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7841 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.6147 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 344/500\n",
      "3/3 - 1s - 170ms/step - accuracy: 0.9310 - auc: 0.9864 - categorical_accuracy: 0.9310 - f1_score: 0.9310 - fn: 304.0000 - fp: 299.0000 - loss: 0.2352 - precision: 0.9316 - recall: 0.9305 - tn: 8455.0000 - tp: 4073.0000 - val_accuracy: 0.8415 - val_auc: 0.9283 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7913 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5738 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 345/500\n",
      "3/3 - 1s - 194ms/step - accuracy: 0.9324 - auc: 0.9856 - categorical_accuracy: 0.9324 - f1_score: 0.9324 - fn: 303.0000 - fp: 291.0000 - loss: 0.2394 - precision: 0.9333 - recall: 0.9308 - tn: 8463.0000 - tp: 4074.0000 - val_accuracy: 0.8415 - val_auc: 0.9375 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7786 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.4927 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 346/500\n",
      "3/3 - 0s - 162ms/step - accuracy: 0.9292 - auc: 0.9875 - categorical_accuracy: 0.9292 - f1_score: 0.9294 - fn: 319.0000 - fp: 305.0000 - loss: 0.2337 - precision: 0.9301 - recall: 0.9271 - tn: 8449.0000 - tp: 4058.0000 - val_accuracy: 0.8089 - val_auc: 0.9307 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7594 - val_fn: 47.0000 - val_fp: 47.0000 - val_loss: 0.5607 - val_precision: 0.8089 - val_recall: 0.8089 - val_tn: 445.0000 - val_tp: 199.0000\n",
      "Epoch 347/500\n",
      "3/3 - 0s - 160ms/step - accuracy: 0.9312 - auc: 0.9856 - categorical_accuracy: 0.9312 - f1_score: 0.9310 - fn: 308.0000 - fp: 297.0000 - loss: 0.2426 - precision: 0.9320 - recall: 0.9296 - tn: 8457.0000 - tp: 4069.0000 - val_accuracy: 0.8537 - val_auc: 0.9396 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8010 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5055 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 348/500\n",
      "3/3 - 1s - 214ms/step - accuracy: 0.9312 - auc: 0.9849 - categorical_accuracy: 0.9312 - f1_score: 0.9316 - fn: 301.0000 - fp: 299.0000 - loss: 0.2442 - precision: 0.9317 - recall: 0.9312 - tn: 8455.0000 - tp: 4076.0000 - val_accuracy: 0.8618 - val_auc: 0.9411 - val_categorical_accuracy: 0.8618 - val_f1_score: 0.8088 - val_fn: 34.0000 - val_fp: 34.0000 - val_loss: 0.4817 - val_precision: 0.8618 - val_recall: 0.8618 - val_tn: 458.0000 - val_tp: 212.0000\n",
      "Epoch 349/500\n",
      "3/3 - 2s - 505ms/step - accuracy: 0.9319 - auc: 0.9866 - categorical_accuracy: 0.9319 - f1_score: 0.9320 - fn: 301.0000 - fp: 294.0000 - loss: 0.2356 - precision: 0.9327 - recall: 0.9312 - tn: 8460.0000 - tp: 4076.0000 - val_accuracy: 0.8211 - val_auc: 0.9222 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7623 - val_fn: 44.0000 - val_fp: 43.0000 - val_loss: 0.5775 - val_precision: 0.8245 - val_recall: 0.8211 - val_tn: 449.0000 - val_tp: 202.0000\n",
      "Epoch 350/500\n",
      "3/3 - 3s - 877ms/step - accuracy: 0.9267 - auc: 0.9846 - categorical_accuracy: 0.9267 - f1_score: 0.9269 - fn: 326.0000 - fp: 318.0000 - loss: 0.2516 - precision: 0.9272 - recall: 0.9255 - tn: 8436.0000 - tp: 4051.0000 - val_accuracy: 0.8455 - val_auc: 0.9338 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7829 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5488 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 351/500\n",
      "3/3 - 1s - 284ms/step - accuracy: 0.9239 - auc: 0.9839 - categorical_accuracy: 0.9239 - f1_score: 0.9244 - fn: 338.0000 - fp: 331.0000 - loss: 0.2571 - precision: 0.9243 - recall: 0.9228 - tn: 8423.0000 - tp: 4039.0000 - val_accuracy: 0.8455 - val_auc: 0.9310 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7846 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5814 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 352/500\n",
      "3/3 - 1s - 215ms/step - accuracy: 0.9301 - auc: 0.9854 - categorical_accuracy: 0.9301 - f1_score: 0.9303 - fn: 310.0000 - fp: 302.0000 - loss: 0.2417 - precision: 0.9309 - recall: 0.9292 - tn: 8452.0000 - tp: 4067.0000 - val_accuracy: 0.8252 - val_auc: 0.9297 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7703 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.6183 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 353/500\n",
      "3/3 - 0s - 158ms/step - accuracy: 0.9271 - auc: 0.9857 - categorical_accuracy: 0.9271 - f1_score: 0.9272 - fn: 323.0000 - fp: 315.0000 - loss: 0.2434 - precision: 0.9279 - recall: 0.9262 - tn: 8439.0000 - tp: 4054.0000 - val_accuracy: 0.8537 - val_auc: 0.9310 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8025 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.6241 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 354/500\n",
      "3/3 - 1s - 169ms/step - accuracy: 0.9305 - auc: 0.9854 - categorical_accuracy: 0.9305 - f1_score: 0.9306 - fn: 304.0000 - fp: 304.0000 - loss: 0.2490 - precision: 0.9305 - recall: 0.9305 - tn: 8450.0000 - tp: 4073.0000 - val_accuracy: 0.8293 - val_auc: 0.9354 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7742 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.5664 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 355/500\n",
      "3/3 - 1s - 182ms/step - accuracy: 0.9283 - auc: 0.9840 - categorical_accuracy: 0.9283 - f1_score: 0.9287 - fn: 317.0000 - fp: 310.0000 - loss: 0.2557 - precision: 0.9291 - recall: 0.9276 - tn: 8444.0000 - tp: 4060.0000 - val_accuracy: 0.8374 - val_auc: 0.9365 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7860 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5608 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 356/500\n",
      "3/3 - 1s - 218ms/step - accuracy: 0.9244 - auc: 0.9851 - categorical_accuracy: 0.9244 - f1_score: 0.9245 - fn: 335.0000 - fp: 324.0000 - loss: 0.2496 - precision: 0.9258 - recall: 0.9235 - tn: 8430.0000 - tp: 4042.0000 - val_accuracy: 0.8333 - val_auc: 0.9343 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7820 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5656 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 357/500\n",
      "3/3 - 1s - 175ms/step - accuracy: 0.9244 - auc: 0.9865 - categorical_accuracy: 0.9244 - f1_score: 0.9243 - fn: 341.0000 - fp: 324.0000 - loss: 0.2410 - precision: 0.9257 - recall: 0.9221 - tn: 8430.0000 - tp: 4036.0000 - val_accuracy: 0.8293 - val_auc: 0.9309 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7754 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5635 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 358/500\n",
      "3/3 - 1s - 184ms/step - accuracy: 0.9303 - auc: 0.9868 - categorical_accuracy: 0.9303 - f1_score: 0.9308 - fn: 310.0000 - fp: 298.0000 - loss: 0.2388 - precision: 0.9317 - recall: 0.9292 - tn: 8456.0000 - tp: 4067.0000 - val_accuracy: 0.8496 - val_auc: 0.9304 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7940 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.6088 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 359/500\n",
      "3/3 - 0s - 140ms/step - accuracy: 0.9278 - auc: 0.9850 - categorical_accuracy: 0.9278 - f1_score: 0.9281 - fn: 321.0000 - fp: 310.0000 - loss: 0.2535 - precision: 0.9290 - recall: 0.9267 - tn: 8444.0000 - tp: 4056.0000 - val_accuracy: 0.8455 - val_auc: 0.9335 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7864 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5514 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 360/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9278 - auc: 0.9859 - categorical_accuracy: 0.9278 - f1_score: 0.9282 - fn: 323.0000 - fp: 310.0000 - loss: 0.2428 - precision: 0.9290 - recall: 0.9262 - tn: 8444.0000 - tp: 4054.0000 - val_accuracy: 0.8211 - val_auc: 0.9321 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7692 - val_fn: 45.0000 - val_fp: 43.0000 - val_loss: 0.5559 - val_precision: 0.8238 - val_recall: 0.8171 - val_tn: 449.0000 - val_tp: 201.0000\n",
      "Epoch 361/500\n",
      "3/3 - 1s - 263ms/step - accuracy: 0.9303 - auc: 0.9867 - categorical_accuracy: 0.9303 - f1_score: 0.9302 - fn: 309.0000 - fp: 301.0000 - loss: 0.2345 - precision: 0.9311 - recall: 0.9294 - tn: 8453.0000 - tp: 4068.0000 - val_accuracy: 0.8455 - val_auc: 0.9343 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7941 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.6001 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 362/500\n",
      "3/3 - 1s - 190ms/step - accuracy: 0.9292 - auc: 0.9837 - categorical_accuracy: 0.9292 - f1_score: 0.9293 - fn: 314.0000 - fp: 308.0000 - loss: 0.2499 - precision: 0.9295 - recall: 0.9283 - tn: 8446.0000 - tp: 4063.0000 - val_accuracy: 0.8333 - val_auc: 0.9313 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7804 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5656 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 363/500\n",
      "3/3 - 1s - 178ms/step - accuracy: 0.9283 - auc: 0.9852 - categorical_accuracy: 0.9283 - f1_score: 0.9281 - fn: 317.0000 - fp: 311.0000 - loss: 0.2404 - precision: 0.9288 - recall: 0.9276 - tn: 8443.0000 - tp: 4060.0000 - val_accuracy: 0.8374 - val_auc: 0.9322 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7830 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5260 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 364/500\n",
      "3/3 - 1s - 206ms/step - accuracy: 0.9283 - auc: 0.9868 - categorical_accuracy: 0.9283 - f1_score: 0.9282 - fn: 317.0000 - fp: 312.0000 - loss: 0.2360 - precision: 0.9286 - recall: 0.9276 - tn: 8442.0000 - tp: 4060.0000 - val_accuracy: 0.8455 - val_auc: 0.9376 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7881 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.4956 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 365/500\n",
      "3/3 - 1s - 281ms/step - accuracy: 0.9271 - auc: 0.9865 - categorical_accuracy: 0.9271 - f1_score: 0.9273 - fn: 319.0000 - fp: 316.0000 - loss: 0.2338 - precision: 0.9278 - recall: 0.9271 - tn: 8438.0000 - tp: 4058.0000 - val_accuracy: 0.8171 - val_auc: 0.9305 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7589 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.5658 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 366/500\n",
      "3/3 - 1s - 256ms/step - accuracy: 0.9299 - auc: 0.9862 - categorical_accuracy: 0.9299 - f1_score: 0.9298 - fn: 311.0000 - fp: 306.0000 - loss: 0.2401 - precision: 0.9300 - recall: 0.9289 - tn: 8448.0000 - tp: 4066.0000 - val_accuracy: 0.8455 - val_auc: 0.9364 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7882 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5437 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 367/500\n",
      "3/3 - 0s - 161ms/step - accuracy: 0.9271 - auc: 0.9843 - categorical_accuracy: 0.9271 - f1_score: 0.9272 - fn: 319.0000 - fp: 317.0000 - loss: 0.2461 - precision: 0.9275 - recall: 0.9271 - tn: 8437.0000 - tp: 4058.0000 - val_accuracy: 0.8496 - val_auc: 0.9370 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7917 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5221 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 368/500\n",
      "3/3 - 1s - 176ms/step - accuracy: 0.9287 - auc: 0.9854 - categorical_accuracy: 0.9287 - f1_score: 0.9290 - fn: 319.0000 - fp: 306.0000 - loss: 0.2398 - precision: 0.9299 - recall: 0.9271 - tn: 8448.0000 - tp: 4058.0000 - val_accuracy: 0.8333 - val_auc: 0.9320 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7757 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5601 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 369/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9310 - auc: 0.9862 - categorical_accuracy: 0.9310 - f1_score: 0.9310 - fn: 306.0000 - fp: 298.0000 - loss: 0.2334 - precision: 0.9318 - recall: 0.9301 - tn: 8456.0000 - tp: 4071.0000 - val_accuracy: 0.8415 - val_auc: 0.9383 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7801 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.4983 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 370/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9292 - auc: 0.9866 - categorical_accuracy: 0.9292 - f1_score: 0.9295 - fn: 315.0000 - fp: 306.0000 - loss: 0.2375 - precision: 0.9299 - recall: 0.9280 - tn: 8448.0000 - tp: 4062.0000 - val_accuracy: 0.8537 - val_auc: 0.9369 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7998 - val_fn: 37.0000 - val_fp: 35.0000 - val_loss: 0.4983 - val_precision: 0.8566 - val_recall: 0.8496 - val_tn: 457.0000 - val_tp: 209.0000\n",
      "Epoch 371/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9283 - auc: 0.9868 - categorical_accuracy: 0.9283 - f1_score: 0.9280 - fn: 321.0000 - fp: 310.0000 - loss: 0.2357 - precision: 0.9290 - recall: 0.9267 - tn: 8444.0000 - tp: 4056.0000 - val_accuracy: 0.8415 - val_auc: 0.9331 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7886 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5615 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 372/500\n",
      "3/3 - 0s - 151ms/step - accuracy: 0.9319 - auc: 0.9871 - categorical_accuracy: 0.9319 - f1_score: 0.9318 - fn: 300.0000 - fp: 295.0000 - loss: 0.2281 - precision: 0.9325 - recall: 0.9315 - tn: 8459.0000 - tp: 4077.0000 - val_accuracy: 0.8415 - val_auc: 0.9364 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7689 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5522 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 373/500\n",
      "3/3 - 1s - 210ms/step - accuracy: 0.9255 - auc: 0.9853 - categorical_accuracy: 0.9255 - f1_score: 0.9261 - fn: 331.0000 - fp: 324.0000 - loss: 0.2429 - precision: 0.9259 - recall: 0.9244 - tn: 8430.0000 - tp: 4046.0000 - val_accuracy: 0.8415 - val_auc: 0.9349 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7776 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5381 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 374/500\n",
      "3/3 - 1s - 300ms/step - accuracy: 0.9299 - auc: 0.9867 - categorical_accuracy: 0.9299 - f1_score: 0.9300 - fn: 310.0000 - fp: 303.0000 - loss: 0.2304 - precision: 0.9307 - recall: 0.9292 - tn: 8451.0000 - tp: 4067.0000 - val_accuracy: 0.8252 - val_auc: 0.9374 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7707 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5101 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 375/500\n",
      "3/3 - 1s - 193ms/step - accuracy: 0.9253 - auc: 0.9862 - categorical_accuracy: 0.9253 - f1_score: 0.9250 - fn: 328.0000 - fp: 323.0000 - loss: 0.2378 - precision: 0.9261 - recall: 0.9251 - tn: 8431.0000 - tp: 4049.0000 - val_accuracy: 0.8496 - val_auc: 0.9400 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7825 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.4918 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 376/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.9235 - auc: 0.9851 - categorical_accuracy: 0.9235 - f1_score: 0.9242 - fn: 337.0000 - fp: 331.0000 - loss: 0.2461 - precision: 0.9243 - recall: 0.9230 - tn: 8423.0000 - tp: 4040.0000 - val_accuracy: 0.8496 - val_auc: 0.9315 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7913 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5317 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 377/500\n",
      "3/3 - 0s - 132ms/step - accuracy: 0.9262 - auc: 0.9864 - categorical_accuracy: 0.9262 - f1_score: 0.9263 - fn: 328.0000 - fp: 320.0000 - loss: 0.2348 - precision: 0.9268 - recall: 0.9251 - tn: 8434.0000 - tp: 4049.0000 - val_accuracy: 0.8415 - val_auc: 0.9209 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7916 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.7063 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 378/500\n",
      "3/3 - 0s - 130ms/step - accuracy: 0.9237 - auc: 0.9837 - categorical_accuracy: 0.9237 - f1_score: 0.9235 - fn: 335.0000 - fp: 330.0000 - loss: 0.2624 - precision: 0.9245 - recall: 0.9235 - tn: 8424.0000 - tp: 4042.0000 - val_accuracy: 0.8415 - val_auc: 0.9384 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7902 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5343 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 379/500\n",
      "3/3 - 1s - 169ms/step - accuracy: 0.9310 - auc: 0.9861 - categorical_accuracy: 0.9310 - f1_score: 0.9309 - fn: 306.0000 - fp: 299.0000 - loss: 0.2350 - precision: 0.9316 - recall: 0.9301 - tn: 8455.0000 - tp: 4071.0000 - val_accuracy: 0.8455 - val_auc: 0.9369 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7941 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5226 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 380/500\n",
      "3/3 - 1s - 176ms/step - accuracy: 0.9271 - auc: 0.9854 - categorical_accuracy: 0.9271 - f1_score: 0.9271 - fn: 321.0000 - fp: 316.0000 - loss: 0.2411 - precision: 0.9277 - recall: 0.9267 - tn: 8438.0000 - tp: 4056.0000 - val_accuracy: 0.8374 - val_auc: 0.9319 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7778 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5918 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 381/500\n",
      "3/3 - 0s - 166ms/step - accuracy: 0.9269 - auc: 0.9863 - categorical_accuracy: 0.9269 - f1_score: 0.9270 - fn: 322.0000 - fp: 316.0000 - loss: 0.2361 - precision: 0.9277 - recall: 0.9264 - tn: 8438.0000 - tp: 4055.0000 - val_accuracy: 0.8252 - val_auc: 0.9344 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7686 - val_fn: 43.0000 - val_fp: 43.0000 - val_loss: 0.5443 - val_precision: 0.8252 - val_recall: 0.8252 - val_tn: 449.0000 - val_tp: 203.0000\n",
      "Epoch 382/500\n",
      "3/3 - 0s - 146ms/step - accuracy: 0.9225 - auc: 0.9844 - categorical_accuracy: 0.9225 - f1_score: 0.9224 - fn: 344.0000 - fp: 338.0000 - loss: 0.2515 - precision: 0.9227 - recall: 0.9214 - tn: 8416.0000 - tp: 4033.0000 - val_accuracy: 0.8496 - val_auc: 0.9319 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7970 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5812 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 383/500\n",
      "3/3 - 0s - 148ms/step - accuracy: 0.9301 - auc: 0.9854 - categorical_accuracy: 0.9301 - f1_score: 0.9302 - fn: 307.0000 - fp: 302.0000 - loss: 0.2376 - precision: 0.9309 - recall: 0.9299 - tn: 8452.0000 - tp: 4070.0000 - val_accuracy: 0.8496 - val_auc: 0.9356 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7924 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5305 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 384/500\n",
      "3/3 - 1s - 282ms/step - accuracy: 0.9303 - auc: 0.9868 - categorical_accuracy: 0.9303 - f1_score: 0.9306 - fn: 310.0000 - fp: 302.0000 - loss: 0.2318 - precision: 0.9309 - recall: 0.9292 - tn: 8452.0000 - tp: 4067.0000 - val_accuracy: 0.8130 - val_auc: 0.9330 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7548 - val_fn: 46.0000 - val_fp: 46.0000 - val_loss: 0.5405 - val_precision: 0.8130 - val_recall: 0.8130 - val_tn: 446.0000 - val_tp: 200.0000\n",
      "Epoch 385/500\n",
      "3/3 - 0s - 146ms/step - accuracy: 0.9267 - auc: 0.9865 - categorical_accuracy: 0.9267 - f1_score: 0.9267 - fn: 328.0000 - fp: 315.0000 - loss: 0.2340 - precision: 0.9278 - recall: 0.9251 - tn: 8439.0000 - tp: 4049.0000 - val_accuracy: 0.8333 - val_auc: 0.9334 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7771 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5741 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 386/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9207 - auc: 0.9851 - categorical_accuracy: 0.9207 - f1_score: 0.9207 - fn: 349.0000 - fp: 345.0000 - loss: 0.2467 - precision: 0.9211 - recall: 0.9203 - tn: 8409.0000 - tp: 4028.0000 - val_accuracy: 0.8537 - val_auc: 0.9376 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7983 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5285 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 387/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9285 - auc: 0.9850 - categorical_accuracy: 0.9285 - f1_score: 0.9289 - fn: 319.0000 - fp: 312.0000 - loss: 0.2471 - precision: 0.9286 - recall: 0.9271 - tn: 8442.0000 - tp: 4058.0000 - val_accuracy: 0.8537 - val_auc: 0.9369 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7950 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5157 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 388/500\n",
      "3/3 - 1s - 186ms/step - accuracy: 0.9289 - auc: 0.9855 - categorical_accuracy: 0.9289 - f1_score: 0.9294 - fn: 314.0000 - fp: 308.0000 - loss: 0.2393 - precision: 0.9295 - recall: 0.9283 - tn: 8446.0000 - tp: 4063.0000 - val_accuracy: 0.8171 - val_auc: 0.9291 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7622 - val_fn: 45.0000 - val_fp: 43.0000 - val_loss: 0.5600 - val_precision: 0.8238 - val_recall: 0.8171 - val_tn: 449.0000 - val_tp: 201.0000\n",
      "Epoch 389/500\n",
      "3/3 - 1s - 181ms/step - accuracy: 0.9289 - auc: 0.9861 - categorical_accuracy: 0.9289 - f1_score: 0.9288 - fn: 315.0000 - fp: 310.0000 - loss: 0.2365 - precision: 0.9291 - recall: 0.9280 - tn: 8444.0000 - tp: 4062.0000 - val_accuracy: 0.8130 - val_auc: 0.9245 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7651 - val_fn: 48.0000 - val_fp: 46.0000 - val_loss: 0.5726 - val_precision: 0.8115 - val_recall: 0.8049 - val_tn: 446.0000 - val_tp: 198.0000\n",
      "Epoch 390/500\n",
      "3/3 - 1s - 238ms/step - accuracy: 0.9269 - auc: 0.9854 - categorical_accuracy: 0.9269 - f1_score: 0.9266 - fn: 327.0000 - fp: 318.0000 - loss: 0.2420 - precision: 0.9272 - recall: 0.9253 - tn: 8436.0000 - tp: 4050.0000 - val_accuracy: 0.8415 - val_auc: 0.9403 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7821 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.4949 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 391/500\n",
      "3/3 - 0s - 165ms/step - accuracy: 0.9303 - auc: 0.9852 - categorical_accuracy: 0.9303 - f1_score: 0.9306 - fn: 307.0000 - fp: 302.0000 - loss: 0.2387 - precision: 0.9309 - recall: 0.9299 - tn: 8452.0000 - tp: 4070.0000 - val_accuracy: 0.8211 - val_auc: 0.9329 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7722 - val_fn: 44.0000 - val_fp: 44.0000 - val_loss: 0.5825 - val_precision: 0.8211 - val_recall: 0.8211 - val_tn: 448.0000 - val_tp: 202.0000\n",
      "Epoch 392/500\n",
      "3/3 - 1s - 209ms/step - accuracy: 0.9271 - auc: 0.9862 - categorical_accuracy: 0.9271 - f1_score: 0.9267 - fn: 321.0000 - fp: 318.0000 - loss: 0.2389 - precision: 0.9273 - recall: 0.9267 - tn: 8436.0000 - tp: 4056.0000 - val_accuracy: 0.8333 - val_auc: 0.9362 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7737 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5270 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 393/500\n",
      "3/3 - 1s - 264ms/step - accuracy: 0.9264 - auc: 0.9844 - categorical_accuracy: 0.9264 - f1_score: 0.9271 - fn: 323.0000 - fp: 319.0000 - loss: 0.2510 - precision: 0.9271 - recall: 0.9262 - tn: 8435.0000 - tp: 4054.0000 - val_accuracy: 0.8455 - val_auc: 0.9410 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7829 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.4883 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 394/500\n",
      "3/3 - 1s - 298ms/step - accuracy: 0.9264 - auc: 0.9858 - categorical_accuracy: 0.9264 - f1_score: 0.9269 - fn: 328.0000 - fp: 318.0000 - loss: 0.2416 - precision: 0.9272 - recall: 0.9251 - tn: 8436.0000 - tp: 4049.0000 - val_accuracy: 0.8171 - val_auc: 0.9355 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7609 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.5434 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 395/500\n",
      "3/3 - 1s - 221ms/step - accuracy: 0.9246 - auc: 0.9858 - categorical_accuracy: 0.9246 - f1_score: 0.9245 - fn: 336.0000 - fp: 326.0000 - loss: 0.2402 - precision: 0.9253 - recall: 0.9232 - tn: 8428.0000 - tp: 4041.0000 - val_accuracy: 0.8455 - val_auc: 0.9385 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7863 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5228 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 396/500\n",
      "3/3 - 1s - 255ms/step - accuracy: 0.9262 - auc: 0.9863 - categorical_accuracy: 0.9262 - f1_score: 0.9263 - fn: 324.0000 - fp: 320.0000 - loss: 0.2352 - precision: 0.9268 - recall: 0.9260 - tn: 8434.0000 - tp: 4053.0000 - val_accuracy: 0.8455 - val_auc: 0.9351 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7914 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5176 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 397/500\n",
      "3/3 - 2s - 510ms/step - accuracy: 0.9273 - auc: 0.9852 - categorical_accuracy: 0.9273 - f1_score: 0.9273 - fn: 321.0000 - fp: 309.0000 - loss: 0.2430 - precision: 0.9292 - recall: 0.9267 - tn: 8445.0000 - tp: 4056.0000 - val_accuracy: 0.8333 - val_auc: 0.9300 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7773 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.5467 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 398/500\n",
      "3/3 - 1s - 344ms/step - accuracy: 0.9299 - auc: 0.9864 - categorical_accuracy: 0.9299 - f1_score: 0.9297 - fn: 309.0000 - fp: 299.0000 - loss: 0.2332 - precision: 0.9315 - recall: 0.9294 - tn: 8455.0000 - tp: 4068.0000 - val_accuracy: 0.8537 - val_auc: 0.9356 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7950 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5152 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 399/500\n",
      "3/3 - 1s - 258ms/step - accuracy: 0.9303 - auc: 0.9863 - categorical_accuracy: 0.9303 - f1_score: 0.9307 - fn: 307.0000 - fp: 303.0000 - loss: 0.2330 - precision: 0.9307 - recall: 0.9299 - tn: 8451.0000 - tp: 4070.0000 - val_accuracy: 0.8496 - val_auc: 0.9387 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7917 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5143 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 400/500\n",
      "3/3 - 2s - 507ms/step - accuracy: 0.9287 - auc: 0.9864 - categorical_accuracy: 0.9287 - f1_score: 0.9288 - fn: 317.0000 - fp: 308.0000 - loss: 0.2337 - precision: 0.9295 - recall: 0.9276 - tn: 8446.0000 - tp: 4060.0000 - val_accuracy: 0.8496 - val_auc: 0.9374 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7986 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5215 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 401/500\n",
      "3/3 - 1s - 249ms/step - accuracy: 0.9225 - auc: 0.9842 - categorical_accuracy: 0.9225 - f1_score: 0.9225 - fn: 340.0000 - fp: 336.0000 - loss: 0.2497 - precision: 0.9232 - recall: 0.9223 - tn: 8418.0000 - tp: 4037.0000 - val_accuracy: 0.8537 - val_auc: 0.9394 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7980 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.4928 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 402/500\n",
      "3/3 - 1s - 241ms/step - accuracy: 0.9253 - auc: 0.9855 - categorical_accuracy: 0.9253 - f1_score: 0.9259 - fn: 338.0000 - fp: 321.0000 - loss: 0.2484 - precision: 0.9264 - recall: 0.9228 - tn: 8433.0000 - tp: 4039.0000 - val_accuracy: 0.8415 - val_auc: 0.9301 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7853 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.5499 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 403/500\n",
      "3/3 - 1s - 409ms/step - accuracy: 0.9301 - auc: 0.9864 - categorical_accuracy: 0.9301 - f1_score: 0.9303 - fn: 313.0000 - fp: 300.0000 - loss: 0.2390 - precision: 0.9313 - recall: 0.9285 - tn: 8454.0000 - tp: 4064.0000 - val_accuracy: 0.8577 - val_auc: 0.9324 - val_categorical_accuracy: 0.8577 - val_f1_score: 0.8092 - val_fn: 36.0000 - val_fp: 35.0000 - val_loss: 0.5609 - val_precision: 0.8571 - val_recall: 0.8537 - val_tn: 457.0000 - val_tp: 210.0000\n",
      "Epoch 404/500\n",
      "3/3 - 2s - 665ms/step - accuracy: 0.9257 - auc: 0.9857 - categorical_accuracy: 0.9257 - f1_score: 0.9259 - fn: 331.0000 - fp: 319.0000 - loss: 0.2404 - precision: 0.9269 - recall: 0.9244 - tn: 8435.0000 - tp: 4046.0000 - val_accuracy: 0.8415 - val_auc: 0.9326 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7843 - val_fn: 41.0000 - val_fp: 39.0000 - val_loss: 0.5661 - val_precision: 0.8402 - val_recall: 0.8333 - val_tn: 453.0000 - val_tp: 205.0000\n",
      "Epoch 405/500\n",
      "3/3 - 2s - 656ms/step - accuracy: 0.9232 - auc: 0.9853 - categorical_accuracy: 0.9232 - f1_score: 0.9235 - fn: 344.0000 - fp: 332.0000 - loss: 0.2460 - precision: 0.9239 - recall: 0.9214 - tn: 8422.0000 - tp: 4033.0000 - val_accuracy: 0.8252 - val_auc: 0.9360 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7681 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5603 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 406/500\n",
      "3/3 - 1s - 287ms/step - accuracy: 0.9324 - auc: 0.9866 - categorical_accuracy: 0.9324 - f1_score: 0.9323 - fn: 300.0000 - fp: 294.0000 - loss: 0.2331 - precision: 0.9327 - recall: 0.9315 - tn: 8460.0000 - tp: 4077.0000 - val_accuracy: 0.8496 - val_auc: 0.9400 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7953 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5150 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 407/500\n",
      "3/3 - 1s - 246ms/step - accuracy: 0.9257 - auc: 0.9852 - categorical_accuracy: 0.9257 - f1_score: 0.9258 - fn: 329.0000 - fp: 323.0000 - loss: 0.2445 - precision: 0.9261 - recall: 0.9248 - tn: 8431.0000 - tp: 4048.0000 - val_accuracy: 0.8496 - val_auc: 0.9416 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7987 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.4945 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 408/500\n",
      "3/3 - 1s - 177ms/step - accuracy: 0.9299 - auc: 0.9868 - categorical_accuracy: 0.9299 - f1_score: 0.9299 - fn: 308.0000 - fp: 302.0000 - loss: 0.2345 - precision: 0.9309 - recall: 0.9296 - tn: 8452.0000 - tp: 4069.0000 - val_accuracy: 0.8171 - val_auc: 0.9347 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7627 - val_fn: 46.0000 - val_fp: 45.0000 - val_loss: 0.5431 - val_precision: 0.8163 - val_recall: 0.8130 - val_tn: 447.0000 - val_tp: 200.0000\n",
      "Epoch 409/500\n",
      "3/3 - 1s - 190ms/step - accuracy: 0.9308 - auc: 0.9863 - categorical_accuracy: 0.9308 - f1_score: 0.9306 - fn: 307.0000 - fp: 298.0000 - loss: 0.2338 - precision: 0.9318 - recall: 0.9299 - tn: 8456.0000 - tp: 4070.0000 - val_accuracy: 0.8415 - val_auc: 0.9374 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7840 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5494 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 410/500\n",
      "3/3 - 1s - 186ms/step - accuracy: 0.9280 - auc: 0.9856 - categorical_accuracy: 0.9280 - f1_score: 0.9284 - fn: 317.0000 - fp: 309.0000 - loss: 0.2373 - precision: 0.9293 - recall: 0.9276 - tn: 8445.0000 - tp: 4060.0000 - val_accuracy: 0.8496 - val_auc: 0.9323 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7955 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5894 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 411/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9292 - auc: 0.9864 - categorical_accuracy: 0.9292 - f1_score: 0.9293 - fn: 313.0000 - fp: 307.0000 - loss: 0.2337 - precision: 0.9298 - recall: 0.9285 - tn: 8447.0000 - tp: 4064.0000 - val_accuracy: 0.8496 - val_auc: 0.9282 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7931 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.6547 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 412/500\n",
      "3/3 - 0s - 148ms/step - accuracy: 0.9260 - auc: 0.9861 - categorical_accuracy: 0.9260 - f1_score: 0.9262 - fn: 326.0000 - fp: 322.0000 - loss: 0.2393 - precision: 0.9264 - recall: 0.9255 - tn: 8432.0000 - tp: 4051.0000 - val_accuracy: 0.8537 - val_auc: 0.9332 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7959 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5688 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 413/500\n",
      "3/3 - 1s - 175ms/step - accuracy: 0.9187 - auc: 0.9853 - categorical_accuracy: 0.9187 - f1_score: 0.9183 - fn: 363.0000 - fp: 341.0000 - loss: 0.2502 - precision: 0.9217 - recall: 0.9171 - tn: 8413.0000 - tp: 4014.0000 - val_accuracy: 0.8333 - val_auc: 0.9316 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7767 - val_fn: 41.0000 - val_fp: 41.0000 - val_loss: 0.6179 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 451.0000 - val_tp: 205.0000\n",
      "Epoch 414/500\n",
      "3/3 - 0s - 146ms/step - accuracy: 0.9246 - auc: 0.9849 - categorical_accuracy: 0.9246 - f1_score: 0.9247 - fn: 339.0000 - fp: 329.0000 - loss: 0.2441 - precision: 0.9247 - recall: 0.9225 - tn: 8425.0000 - tp: 4038.0000 - val_accuracy: 0.8537 - val_auc: 0.9299 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8025 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.6154 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 415/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9305 - auc: 0.9868 - categorical_accuracy: 0.9305 - f1_score: 0.9308 - fn: 306.0000 - fp: 301.0000 - loss: 0.2338 - precision: 0.9312 - recall: 0.9301 - tn: 8453.0000 - tp: 4071.0000 - val_accuracy: 0.8293 - val_auc: 0.9208 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7778 - val_fn: 44.0000 - val_fp: 42.0000 - val_loss: 0.6587 - val_precision: 0.8279 - val_recall: 0.8211 - val_tn: 450.0000 - val_tp: 202.0000\n",
      "Epoch 416/500\n",
      "3/3 - 0s - 143ms/step - accuracy: 0.9321 - auc: 0.9860 - categorical_accuracy: 0.9321 - f1_score: 0.9324 - fn: 300.0000 - fp: 296.0000 - loss: 0.2388 - precision: 0.9323 - recall: 0.9315 - tn: 8458.0000 - tp: 4077.0000 - val_accuracy: 0.8577 - val_auc: 0.9357 - val_categorical_accuracy: 0.8577 - val_f1_score: 0.8042 - val_fn: 35.0000 - val_fp: 35.0000 - val_loss: 0.5330 - val_precision: 0.8577 - val_recall: 0.8577 - val_tn: 457.0000 - val_tp: 211.0000\n",
      "Epoch 417/500\n",
      "3/3 - 0s - 147ms/step - accuracy: 0.9244 - auc: 0.9844 - categorical_accuracy: 0.9244 - f1_score: 0.9247 - fn: 331.0000 - fp: 328.0000 - loss: 0.2535 - precision: 0.9250 - recall: 0.9244 - tn: 8426.0000 - tp: 4046.0000 - val_accuracy: 0.8537 - val_auc: 0.9395 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8045 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5316 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 418/500\n",
      "3/3 - 1s - 189ms/step - accuracy: 0.9246 - auc: 0.9855 - categorical_accuracy: 0.9246 - f1_score: 0.9245 - fn: 332.0000 - fp: 323.0000 - loss: 0.2452 - precision: 0.9261 - recall: 0.9241 - tn: 8431.0000 - tp: 4045.0000 - val_accuracy: 0.8089 - val_auc: 0.9282 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7593 - val_fn: 50.0000 - val_fp: 47.0000 - val_loss: 0.6199 - val_precision: 0.8066 - val_recall: 0.7967 - val_tn: 445.0000 - val_tp: 196.0000\n",
      "Epoch 419/500\n",
      "3/3 - 1s - 189ms/step - accuracy: 0.9241 - auc: 0.9862 - categorical_accuracy: 0.9241 - f1_score: 0.9239 - fn: 337.0000 - fp: 324.0000 - loss: 0.2412 - precision: 0.9258 - recall: 0.9230 - tn: 8430.0000 - tp: 4040.0000 - val_accuracy: 0.8496 - val_auc: 0.9376 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7941 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5470 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 420/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9246 - auc: 0.9847 - categorical_accuracy: 0.9246 - f1_score: 0.9251 - fn: 334.0000 - fp: 327.0000 - loss: 0.2488 - precision: 0.9252 - recall: 0.9237 - tn: 8427.0000 - tp: 4043.0000 - val_accuracy: 0.8415 - val_auc: 0.9425 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7809 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5068 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 421/500\n",
      "3/3 - 0s - 155ms/step - accuracy: 0.9225 - auc: 0.9858 - categorical_accuracy: 0.9225 - f1_score: 0.9228 - fn: 343.0000 - fp: 336.0000 - loss: 0.2475 - precision: 0.9231 - recall: 0.9216 - tn: 8418.0000 - tp: 4034.0000 - val_accuracy: 0.8293 - val_auc: 0.9342 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7820 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5646 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 422/500\n",
      "3/3 - 1s - 269ms/step - accuracy: 0.9278 - auc: 0.9863 - categorical_accuracy: 0.9278 - f1_score: 0.9276 - fn: 320.0000 - fp: 313.0000 - loss: 0.2393 - precision: 0.9284 - recall: 0.9269 - tn: 8441.0000 - tp: 4057.0000 - val_accuracy: 0.8089 - val_auc: 0.9317 - val_categorical_accuracy: 0.8089 - val_f1_score: 0.7561 - val_fn: 48.0000 - val_fp: 47.0000 - val_loss: 0.6240 - val_precision: 0.8082 - val_recall: 0.8049 - val_tn: 445.0000 - val_tp: 198.0000\n",
      "Epoch 423/500\n",
      "3/3 - 1s - 248ms/step - accuracy: 0.9292 - auc: 0.9865 - categorical_accuracy: 0.9292 - f1_score: 0.9291 - fn: 314.0000 - fp: 307.0000 - loss: 0.2361 - precision: 0.9297 - recall: 0.9283 - tn: 8447.0000 - tp: 4063.0000 - val_accuracy: 0.8496 - val_auc: 0.9363 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7916 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5851 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 424/500\n",
      "3/3 - 0s - 161ms/step - accuracy: 0.9303 - auc: 0.9861 - categorical_accuracy: 0.9303 - f1_score: 0.9305 - fn: 310.0000 - fp: 298.0000 - loss: 0.2348 - precision: 0.9317 - recall: 0.9292 - tn: 8456.0000 - tp: 4067.0000 - val_accuracy: 0.8455 - val_auc: 0.9383 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7830 - val_fn: 39.0000 - val_fp: 37.0000 - val_loss: 0.5279 - val_precision: 0.8484 - val_recall: 0.8415 - val_tn: 455.0000 - val_tp: 207.0000\n",
      "Epoch 425/500\n",
      "3/3 - 0s - 149ms/step - accuracy: 0.9225 - auc: 0.9867 - categorical_accuracy: 0.9225 - f1_score: 0.9228 - fn: 344.0000 - fp: 335.0000 - loss: 0.2368 - precision: 0.9233 - recall: 0.9214 - tn: 8419.0000 - tp: 4033.0000 - val_accuracy: 0.8211 - val_auc: 0.9341 - val_categorical_accuracy: 0.8211 - val_f1_score: 0.7731 - val_fn: 44.0000 - val_fp: 43.0000 - val_loss: 0.5460 - val_precision: 0.8245 - val_recall: 0.8211 - val_tn: 449.0000 - val_tp: 202.0000\n",
      "Epoch 426/500\n",
      "3/3 - 1s - 171ms/step - accuracy: 0.9287 - auc: 0.9865 - categorical_accuracy: 0.9287 - f1_score: 0.9285 - fn: 320.0000 - fp: 308.0000 - loss: 0.2374 - precision: 0.9294 - recall: 0.9269 - tn: 8446.0000 - tp: 4057.0000 - val_accuracy: 0.8537 - val_auc: 0.9389 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7997 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5207 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 427/500\n",
      "3/3 - 0s - 165ms/step - accuracy: 0.9301 - auc: 0.9866 - categorical_accuracy: 0.9301 - f1_score: 0.9304 - fn: 310.0000 - fp: 300.0000 - loss: 0.2299 - precision: 0.9313 - recall: 0.9292 - tn: 8454.0000 - tp: 4067.0000 - val_accuracy: 0.8455 - val_auc: 0.9351 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7913 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5639 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 428/500\n",
      "3/3 - 1s - 183ms/step - accuracy: 0.9276 - auc: 0.9867 - categorical_accuracy: 0.9276 - f1_score: 0.9272 - fn: 319.0000 - fp: 314.0000 - loss: 0.2344 - precision: 0.9282 - recall: 0.9271 - tn: 8440.0000 - tp: 4058.0000 - val_accuracy: 0.8130 - val_auc: 0.9352 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7572 - val_fn: 46.0000 - val_fp: 44.0000 - val_loss: 0.5422 - val_precision: 0.8197 - val_recall: 0.8130 - val_tn: 448.0000 - val_tp: 200.0000\n",
      "Epoch 429/500\n",
      "3/3 - 1s - 226ms/step - accuracy: 0.9280 - auc: 0.9855 - categorical_accuracy: 0.9280 - f1_score: 0.9281 - fn: 317.0000 - fp: 314.0000 - loss: 0.2380 - precision: 0.9282 - recall: 0.9276 - tn: 8440.0000 - tp: 4060.0000 - val_accuracy: 0.8496 - val_auc: 0.9386 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7825 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5147 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 430/500\n",
      "3/3 - 0s - 153ms/step - accuracy: 0.9246 - auc: 0.9854 - categorical_accuracy: 0.9246 - f1_score: 0.9250 - fn: 331.0000 - fp: 327.0000 - loss: 0.2418 - precision: 0.9252 - recall: 0.9244 - tn: 8427.0000 - tp: 4046.0000 - val_accuracy: 0.8374 - val_auc: 0.9377 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7741 - val_fn: 40.0000 - val_fp: 38.0000 - val_loss: 0.5340 - val_precision: 0.8443 - val_recall: 0.8374 - val_tn: 454.0000 - val_tp: 206.0000\n",
      "Epoch 431/500\n",
      "3/3 - 1s - 323ms/step - accuracy: 0.9305 - auc: 0.9867 - categorical_accuracy: 0.9305 - f1_score: 0.9308 - fn: 312.0000 - fp: 304.0000 - loss: 0.2357 - precision: 0.9304 - recall: 0.9287 - tn: 8450.0000 - tp: 4065.0000 - val_accuracy: 0.8171 - val_auc: 0.9328 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7605 - val_fn: 45.0000 - val_fp: 44.0000 - val_loss: 0.5557 - val_precision: 0.8204 - val_recall: 0.8171 - val_tn: 448.0000 - val_tp: 201.0000\n",
      "Epoch 432/500\n",
      "3/3 - 1s - 306ms/step - accuracy: 0.9287 - auc: 0.9858 - categorical_accuracy: 0.9287 - f1_score: 0.9287 - fn: 320.0000 - fp: 307.0000 - loss: 0.2412 - precision: 0.9297 - recall: 0.9269 - tn: 8447.0000 - tp: 4057.0000 - val_accuracy: 0.8455 - val_auc: 0.9358 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7882 - val_fn: 39.0000 - val_fp: 38.0000 - val_loss: 0.5647 - val_precision: 0.8449 - val_recall: 0.8415 - val_tn: 454.0000 - val_tp: 207.0000\n",
      "Epoch 433/500\n",
      "3/3 - 1s - 209ms/step - accuracy: 0.9308 - auc: 0.9865 - categorical_accuracy: 0.9308 - f1_score: 0.9307 - fn: 309.0000 - fp: 300.0000 - loss: 0.2308 - precision: 0.9313 - recall: 0.9294 - tn: 8454.0000 - tp: 4068.0000 - val_accuracy: 0.8455 - val_auc: 0.9358 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7811 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5193 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 434/500\n",
      "3/3 - 1s - 273ms/step - accuracy: 0.9271 - auc: 0.9871 - categorical_accuracy: 0.9271 - f1_score: 0.9273 - fn: 322.0000 - fp: 312.0000 - loss: 0.2310 - precision: 0.9286 - recall: 0.9264 - tn: 8442.0000 - tp: 4055.0000 - val_accuracy: 0.8496 - val_auc: 0.9373 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7906 - val_fn: 37.0000 - val_fp: 36.0000 - val_loss: 0.5109 - val_precision: 0.8531 - val_recall: 0.8496 - val_tn: 456.0000 - val_tp: 209.0000\n",
      "Epoch 435/500\n",
      "3/3 - 1s - 221ms/step - accuracy: 0.9310 - auc: 0.9866 - categorical_accuracy: 0.9310 - f1_score: 0.9310 - fn: 305.0000 - fp: 298.0000 - loss: 0.2296 - precision: 0.9318 - recall: 0.9303 - tn: 8456.0000 - tp: 4072.0000 - val_accuracy: 0.8374 - val_auc: 0.9349 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7771 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5209 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 436/500\n",
      "3/3 - 1s - 194ms/step - accuracy: 0.9271 - auc: 0.9854 - categorical_accuracy: 0.9271 - f1_score: 0.9272 - fn: 324.0000 - fp: 313.0000 - loss: 0.2448 - precision: 0.9283 - recall: 0.9260 - tn: 8441.0000 - tp: 4053.0000 - val_accuracy: 0.8455 - val_auc: 0.9402 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7750 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.4998 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 437/500\n",
      "3/3 - 0s - 157ms/step - accuracy: 0.9230 - auc: 0.9853 - categorical_accuracy: 0.9230 - f1_score: 0.9237 - fn: 339.0000 - fp: 331.0000 - loss: 0.2410 - precision: 0.9242 - recall: 0.9225 - tn: 8423.0000 - tp: 4038.0000 - val_accuracy: 0.8618 - val_auc: 0.9381 - val_categorical_accuracy: 0.8618 - val_f1_score: 0.8073 - val_fn: 37.0000 - val_fp: 34.0000 - val_loss: 0.5389 - val_precision: 0.8601 - val_recall: 0.8496 - val_tn: 458.0000 - val_tp: 209.0000\n",
      "Epoch 438/500\n",
      "3/3 - 1s - 176ms/step - accuracy: 0.9230 - auc: 0.9851 - categorical_accuracy: 0.9230 - f1_score: 0.9228 - fn: 340.0000 - fp: 329.0000 - loss: 0.2384 - precision: 0.9246 - recall: 0.9223 - tn: 8425.0000 - tp: 4037.0000 - val_accuracy: 0.8049 - val_auc: 0.9318 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7589 - val_fn: 49.0000 - val_fp: 47.0000 - val_loss: 0.5747 - val_precision: 0.8074 - val_recall: 0.8008 - val_tn: 445.0000 - val_tp: 197.0000\n",
      "Epoch 439/500\n",
      "3/3 - 0s - 160ms/step - accuracy: 0.9225 - auc: 0.9855 - categorical_accuracy: 0.9225 - f1_score: 0.9225 - fn: 347.0000 - fp: 325.0000 - loss: 0.2423 - precision: 0.9254 - recall: 0.9207 - tn: 8429.0000 - tp: 4030.0000 - val_accuracy: 0.8333 - val_auc: 0.9374 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7792 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5350 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 440/500\n",
      "3/3 - 0s - 145ms/step - accuracy: 0.9289 - auc: 0.9856 - categorical_accuracy: 0.9289 - f1_score: 0.9292 - fn: 319.0000 - fp: 305.0000 - loss: 0.2370 - precision: 0.9301 - recall: 0.9271 - tn: 8449.0000 - tp: 4058.0000 - val_accuracy: 0.8293 - val_auc: 0.9326 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7826 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5430 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 441/500\n",
      "3/3 - 0s - 146ms/step - accuracy: 0.9244 - auc: 0.9852 - categorical_accuracy: 0.9244 - f1_score: 0.9243 - fn: 334.0000 - fp: 323.0000 - loss: 0.2391 - precision: 0.9260 - recall: 0.9237 - tn: 8431.0000 - tp: 4043.0000 - val_accuracy: 0.8293 - val_auc: 0.9277 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7805 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5692 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 442/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9283 - auc: 0.9861 - categorical_accuracy: 0.9283 - f1_score: 0.9283 - fn: 320.0000 - fp: 311.0000 - loss: 0.2342 - precision: 0.9288 - recall: 0.9269 - tn: 8443.0000 - tp: 4057.0000 - val_accuracy: 0.8537 - val_auc: 0.9361 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8036 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5322 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 443/500\n",
      "3/3 - 1s - 172ms/step - accuracy: 0.9301 - auc: 0.9871 - categorical_accuracy: 0.9301 - f1_score: 0.9302 - fn: 309.0000 - fp: 303.0000 - loss: 0.2257 - precision: 0.9307 - recall: 0.9294 - tn: 8451.0000 - tp: 4068.0000 - val_accuracy: 0.8374 - val_auc: 0.9365 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7893 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5653 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 444/500\n",
      "3/3 - 1s - 170ms/step - accuracy: 0.9303 - auc: 0.9871 - categorical_accuracy: 0.9303 - f1_score: 0.9302 - fn: 310.0000 - fp: 301.0000 - loss: 0.2300 - precision: 0.9311 - recall: 0.9292 - tn: 8453.0000 - tp: 4067.0000 - val_accuracy: 0.8415 - val_auc: 0.9371 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7836 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.5312 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 445/500\n",
      "3/3 - 0s - 145ms/step - accuracy: 0.9248 - auc: 0.9860 - categorical_accuracy: 0.9248 - f1_score: 0.9251 - fn: 331.0000 - fp: 327.0000 - loss: 0.2371 - precision: 0.9252 - recall: 0.9244 - tn: 8427.0000 - tp: 4046.0000 - val_accuracy: 0.8537 - val_auc: 0.9389 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.8024 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5109 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 446/500\n",
      "3/3 - 0s - 147ms/step - accuracy: 0.9262 - auc: 0.9860 - categorical_accuracy: 0.9262 - f1_score: 0.9263 - fn: 329.0000 - fp: 317.0000 - loss: 0.2377 - precision: 0.9274 - recall: 0.9248 - tn: 8437.0000 - tp: 4048.0000 - val_accuracy: 0.8374 - val_auc: 0.9333 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7907 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5582 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 447/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9257 - auc: 0.9863 - categorical_accuracy: 0.9257 - f1_score: 0.9259 - fn: 327.0000 - fp: 322.0000 - loss: 0.2343 - precision: 0.9263 - recall: 0.9253 - tn: 8432.0000 - tp: 4050.0000 - val_accuracy: 0.8537 - val_auc: 0.9366 - val_categorical_accuracy: 0.8537 - val_f1_score: 0.7898 - val_fn: 36.0000 - val_fp: 36.0000 - val_loss: 0.5284 - val_precision: 0.8537 - val_recall: 0.8537 - val_tn: 456.0000 - val_tp: 210.0000\n",
      "Epoch 448/500\n",
      "3/3 - 0s - 164ms/step - accuracy: 0.9262 - auc: 0.9861 - categorical_accuracy: 0.9262 - f1_score: 0.9268 - fn: 324.0000 - fp: 323.0000 - loss: 0.2414 - precision: 0.9262 - recall: 0.9260 - tn: 8431.0000 - tp: 4053.0000 - val_accuracy: 0.8333 - val_auc: 0.9314 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7805 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.5735 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 449/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9276 - auc: 0.9854 - categorical_accuracy: 0.9276 - f1_score: 0.9275 - fn: 323.0000 - fp: 312.0000 - loss: 0.2405 - precision: 0.9285 - recall: 0.9262 - tn: 8442.0000 - tp: 4054.0000 - val_accuracy: 0.8374 - val_auc: 0.9312 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7832 - val_fn: 40.0000 - val_fp: 39.0000 - val_loss: 0.5434 - val_precision: 0.8408 - val_recall: 0.8374 - val_tn: 453.0000 - val_tp: 206.0000\n",
      "Epoch 450/500\n",
      "3/3 - 0s - 148ms/step - accuracy: 0.9271 - auc: 0.9861 - categorical_accuracy: 0.9271 - f1_score: 0.9275 - fn: 325.0000 - fp: 312.0000 - loss: 0.2413 - precision: 0.9285 - recall: 0.9257 - tn: 8442.0000 - tp: 4052.0000 - val_accuracy: 0.8415 - val_auc: 0.9382 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7821 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5181 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 451/500\n",
      "3/3 - 0s - 150ms/step - accuracy: 0.9287 - auc: 0.9864 - categorical_accuracy: 0.9287 - f1_score: 0.9287 - fn: 317.0000 - fp: 309.0000 - loss: 0.2339 - precision: 0.9293 - recall: 0.9276 - tn: 8445.0000 - tp: 4060.0000 - val_accuracy: 0.8455 - val_auc: 0.9317 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7928 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.6066 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 452/500\n",
      "3/3 - 1s - 170ms/step - accuracy: 0.9278 - auc: 0.9855 - categorical_accuracy: 0.9278 - f1_score: 0.9278 - fn: 318.0000 - fp: 313.0000 - loss: 0.2397 - precision: 0.9284 - recall: 0.9273 - tn: 8441.0000 - tp: 4059.0000 - val_accuracy: 0.8496 - val_auc: 0.9336 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7906 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5707 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 453/500\n",
      "3/3 - 1s - 169ms/step - accuracy: 0.9308 - auc: 0.9859 - categorical_accuracy: 0.9308 - f1_score: 0.9309 - fn: 308.0000 - fp: 301.0000 - loss: 0.2347 - precision: 0.9311 - recall: 0.9296 - tn: 8453.0000 - tp: 4069.0000 - val_accuracy: 0.8415 - val_auc: 0.9328 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7902 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5840 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 454/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9212 - auc: 0.9861 - categorical_accuracy: 0.9212 - f1_score: 0.9210 - fn: 352.0000 - fp: 342.0000 - loss: 0.2417 - precision: 0.9217 - recall: 0.9196 - tn: 8412.0000 - tp: 4025.0000 - val_accuracy: 0.8496 - val_auc: 0.9351 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7970 - val_fn: 38.0000 - val_fp: 35.0000 - val_loss: 0.5491 - val_precision: 0.8560 - val_recall: 0.8455 - val_tn: 457.0000 - val_tp: 208.0000\n",
      "Epoch 455/500\n",
      "3/3 - 0s - 159ms/step - accuracy: 0.9239 - auc: 0.9855 - categorical_accuracy: 0.9239 - f1_score: 0.9238 - fn: 339.0000 - fp: 325.0000 - loss: 0.2391 - precision: 0.9255 - recall: 0.9225 - tn: 8429.0000 - tp: 4038.0000 - val_accuracy: 0.8130 - val_auc: 0.9326 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7604 - val_fn: 46.0000 - val_fp: 46.0000 - val_loss: 0.5572 - val_precision: 0.8130 - val_recall: 0.8130 - val_tn: 446.0000 - val_tp: 200.0000\n",
      "Epoch 456/500\n",
      "3/3 - 0s - 151ms/step - accuracy: 0.9248 - auc: 0.9859 - categorical_accuracy: 0.9248 - f1_score: 0.9244 - fn: 335.0000 - fp: 325.0000 - loss: 0.2389 - precision: 0.9256 - recall: 0.9235 - tn: 8429.0000 - tp: 4042.0000 - val_accuracy: 0.8374 - val_auc: 0.9278 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7795 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5908 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 457/500\n",
      "3/3 - 0s - 146ms/step - accuracy: 0.9216 - auc: 0.9845 - categorical_accuracy: 0.9216 - f1_score: 0.9217 - fn: 345.0000 - fp: 337.0000 - loss: 0.2507 - precision: 0.9229 - recall: 0.9212 - tn: 8417.0000 - tp: 4032.0000 - val_accuracy: 0.8374 - val_auc: 0.9352 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7757 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5292 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 458/500\n",
      "3/3 - 1s - 177ms/step - accuracy: 0.9315 - auc: 0.9867 - categorical_accuracy: 0.9315 - f1_score: 0.9318 - fn: 304.0000 - fp: 296.0000 - loss: 0.2394 - precision: 0.9322 - recall: 0.9305 - tn: 8458.0000 - tp: 4073.0000 - val_accuracy: 0.8496 - val_auc: 0.9320 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7956 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5732 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 459/500\n",
      "3/3 - 0s - 138ms/step - accuracy: 0.9301 - auc: 0.9863 - categorical_accuracy: 0.9301 - f1_score: 0.9303 - fn: 311.0000 - fp: 299.0000 - loss: 0.2360 - precision: 0.9315 - recall: 0.9289 - tn: 8455.0000 - tp: 4066.0000 - val_accuracy: 0.8415 - val_auc: 0.9301 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7902 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.6428 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 460/500\n",
      "3/3 - 0s - 142ms/step - accuracy: 0.9319 - auc: 0.9844 - categorical_accuracy: 0.9319 - f1_score: 0.9320 - fn: 301.0000 - fp: 297.0000 - loss: 0.2452 - precision: 0.9321 - recall: 0.9312 - tn: 8457.0000 - tp: 4076.0000 - val_accuracy: 0.8130 - val_auc: 0.9282 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7645 - val_fn: 46.0000 - val_fp: 46.0000 - val_loss: 0.5933 - val_precision: 0.8130 - val_recall: 0.8130 - val_tn: 446.0000 - val_tp: 200.0000\n",
      "Epoch 461/500\n",
      "3/3 - 0s - 141ms/step - accuracy: 0.9248 - auc: 0.9851 - categorical_accuracy: 0.9248 - f1_score: 0.9245 - fn: 333.0000 - fp: 328.0000 - loss: 0.2503 - precision: 0.9250 - recall: 0.9239 - tn: 8426.0000 - tp: 4044.0000 - val_accuracy: 0.8455 - val_auc: 0.9326 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7943 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5337 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 462/500\n",
      "3/3 - 1s - 182ms/step - accuracy: 0.9305 - auc: 0.9854 - categorical_accuracy: 0.9305 - f1_score: 0.9308 - fn: 308.0000 - fp: 302.0000 - loss: 0.2453 - precision: 0.9309 - recall: 0.9296 - tn: 8452.0000 - tp: 4069.0000 - val_accuracy: 0.8496 - val_auc: 0.9334 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7940 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5515 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 463/500\n",
      "3/3 - 0s - 145ms/step - accuracy: 0.9287 - auc: 0.9854 - categorical_accuracy: 0.9287 - f1_score: 0.9291 - fn: 313.0000 - fp: 311.0000 - loss: 0.2421 - precision: 0.9289 - recall: 0.9285 - tn: 8443.0000 - tp: 4064.0000 - val_accuracy: 0.8130 - val_auc: 0.9280 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7626 - val_fn: 46.0000 - val_fp: 45.0000 - val_loss: 0.6302 - val_precision: 0.8163 - val_recall: 0.8130 - val_tn: 447.0000 - val_tp: 200.0000\n",
      "Epoch 464/500\n",
      "3/3 - 0s - 144ms/step - accuracy: 0.9301 - auc: 0.9858 - categorical_accuracy: 0.9301 - f1_score: 0.9300 - fn: 311.0000 - fp: 303.0000 - loss: 0.2372 - precision: 0.9306 - recall: 0.9289 - tn: 8451.0000 - tp: 4066.0000 - val_accuracy: 0.8252 - val_auc: 0.9312 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7762 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.6435 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 465/500\n",
      "3/3 - 0s - 136ms/step - accuracy: 0.9267 - auc: 0.9847 - categorical_accuracy: 0.9267 - f1_score: 0.9266 - fn: 327.0000 - fp: 319.0000 - loss: 0.2463 - precision: 0.9270 - recall: 0.9253 - tn: 8435.0000 - tp: 4050.0000 - val_accuracy: 0.7927 - val_auc: 0.9258 - val_categorical_accuracy: 0.7927 - val_f1_score: 0.7519 - val_fn: 52.0000 - val_fp: 51.0000 - val_loss: 0.6129 - val_precision: 0.7918 - val_recall: 0.7886 - val_tn: 441.0000 - val_tp: 194.0000\n",
      "Epoch 466/500\n",
      "3/3 - 1s - 322ms/step - accuracy: 0.9214 - auc: 0.9862 - categorical_accuracy: 0.9214 - f1_score: 0.9210 - fn: 346.0000 - fp: 339.0000 - loss: 0.2413 - precision: 0.9224 - recall: 0.9210 - tn: 8415.0000 - tp: 4031.0000 - val_accuracy: 0.8171 - val_auc: 0.9304 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7706 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.5675 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 467/500\n",
      "3/3 - 1s - 194ms/step - accuracy: 0.9333 - auc: 0.9859 - categorical_accuracy: 0.9333 - f1_score: 0.9334 - fn: 293.0000 - fp: 287.0000 - loss: 0.2384 - precision: 0.9343 - recall: 0.9331 - tn: 8467.0000 - tp: 4084.0000 - val_accuracy: 0.8130 - val_auc: 0.9229 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7644 - val_fn: 46.0000 - val_fp: 46.0000 - val_loss: 0.6639 - val_precision: 0.8130 - val_recall: 0.8130 - val_tn: 446.0000 - val_tp: 200.0000\n",
      "Epoch 468/500\n",
      "3/3 - 1s - 202ms/step - accuracy: 0.9260 - auc: 0.9857 - categorical_accuracy: 0.9260 - f1_score: 0.9261 - fn: 326.0000 - fp: 322.0000 - loss: 0.2460 - precision: 0.9264 - recall: 0.9255 - tn: 8432.0000 - tp: 4051.0000 - val_accuracy: 0.8130 - val_auc: 0.9204 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7564 - val_fn: 46.0000 - val_fp: 46.0000 - val_loss: 0.7243 - val_precision: 0.8130 - val_recall: 0.8130 - val_tn: 446.0000 - val_tp: 200.0000\n",
      "Epoch 469/500\n",
      "3/3 - 1s - 373ms/step - accuracy: 0.9257 - auc: 0.9849 - categorical_accuracy: 0.9257 - f1_score: 0.9260 - fn: 325.0000 - fp: 325.0000 - loss: 0.2469 - precision: 0.9257 - recall: 0.9257 - tn: 8429.0000 - tp: 4052.0000 - val_accuracy: 0.8293 - val_auc: 0.9191 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7800 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.6619 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 470/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9308 - auc: 0.9857 - categorical_accuracy: 0.9308 - f1_score: 0.9310 - fn: 304.0000 - fp: 301.0000 - loss: 0.2403 - precision: 0.9312 - recall: 0.9305 - tn: 8453.0000 - tp: 4073.0000 - val_accuracy: 0.8455 - val_auc: 0.9291 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7941 - val_fn: 38.0000 - val_fp: 36.0000 - val_loss: 0.5833 - val_precision: 0.8525 - val_recall: 0.8455 - val_tn: 456.0000 - val_tp: 208.0000\n",
      "Epoch 471/500\n",
      "3/3 - 1s - 201ms/step - accuracy: 0.9155 - auc: 0.9800 - categorical_accuracy: 0.9155 - f1_score: 0.9155 - fn: 386.0000 - fp: 348.0000 - loss: 0.2937 - precision: 0.9198 - recall: 0.9118 - tn: 8406.0000 - tp: 3991.0000 - val_accuracy: 0.8049 - val_auc: 0.9224 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7567 - val_fn: 48.0000 - val_fp: 48.0000 - val_loss: 0.6450 - val_precision: 0.8049 - val_recall: 0.8049 - val_tn: 444.0000 - val_tp: 198.0000\n",
      "Epoch 472/500\n",
      "3/3 - 0s - 151ms/step - accuracy: 0.9244 - auc: 0.9843 - categorical_accuracy: 0.9244 - f1_score: 0.9243 - fn: 333.0000 - fp: 326.0000 - loss: 0.2689 - precision: 0.9254 - recall: 0.9239 - tn: 8428.0000 - tp: 4044.0000 - val_accuracy: 0.8374 - val_auc: 0.9328 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7863 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.5872 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 473/500\n",
      "3/3 - 1s - 169ms/step - accuracy: 0.9257 - auc: 0.9851 - categorical_accuracy: 0.9257 - f1_score: 0.9259 - fn: 326.0000 - fp: 324.0000 - loss: 0.2751 - precision: 0.9259 - recall: 0.9255 - tn: 8430.0000 - tp: 4051.0000 - val_accuracy: 0.8333 - val_auc: 0.9334 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7773 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.5864 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 474/500\n",
      "3/3 - 1s - 235ms/step - accuracy: 0.9271 - auc: 0.9859 - categorical_accuracy: 0.9271 - f1_score: 0.9276 - fn: 321.0000 - fp: 318.0000 - loss: 0.2856 - precision: 0.9273 - recall: 0.9267 - tn: 8436.0000 - tp: 4056.0000 - val_accuracy: 0.8333 - val_auc: 0.9307 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7818 - val_fn: 42.0000 - val_fp: 40.0000 - val_loss: 0.6247 - val_precision: 0.8361 - val_recall: 0.8293 - val_tn: 452.0000 - val_tp: 204.0000\n",
      "Epoch 475/500\n",
      "3/3 - 1s - 240ms/step - accuracy: 0.9285 - auc: 0.9853 - categorical_accuracy: 0.9285 - f1_score: 0.9286 - fn: 314.0000 - fp: 312.0000 - loss: 0.2833 - precision: 0.9287 - recall: 0.9283 - tn: 8442.0000 - tp: 4063.0000 - val_accuracy: 0.8455 - val_auc: 0.9388 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7898 - val_fn: 38.0000 - val_fp: 38.0000 - val_loss: 0.5650 - val_precision: 0.8455 - val_recall: 0.8455 - val_tn: 454.0000 - val_tp: 208.0000\n",
      "Epoch 476/500\n",
      "3/3 - 1s - 202ms/step - accuracy: 0.9244 - auc: 0.9852 - categorical_accuracy: 0.9244 - f1_score: 0.9251 - fn: 333.0000 - fp: 327.0000 - loss: 0.2906 - precision: 0.9252 - recall: 0.9239 - tn: 8427.0000 - tp: 4044.0000 - val_accuracy: 0.8333 - val_auc: 0.9294 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7840 - val_fn: 41.0000 - val_fp: 40.0000 - val_loss: 0.6030 - val_precision: 0.8367 - val_recall: 0.8333 - val_tn: 452.0000 - val_tp: 205.0000\n",
      "Epoch 477/500\n",
      "3/3 - 1s - 193ms/step - accuracy: 0.9305 - auc: 0.9864 - categorical_accuracy: 0.9305 - f1_score: 0.9307 - fn: 310.0000 - fp: 300.0000 - loss: 0.2828 - precision: 0.9313 - recall: 0.9292 - tn: 8454.0000 - tp: 4067.0000 - val_accuracy: 0.8049 - val_auc: 0.9189 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7588 - val_fn: 48.0000 - val_fp: 47.0000 - val_loss: 0.6912 - val_precision: 0.8082 - val_recall: 0.8049 - val_tn: 445.0000 - val_tp: 198.0000\n",
      "Epoch 478/500\n",
      "3/3 - 1s - 180ms/step - accuracy: 0.9216 - auc: 0.9834 - categorical_accuracy: 0.9216 - f1_score: 0.9216 - fn: 350.0000 - fp: 340.0000 - loss: 0.3043 - precision: 0.9221 - recall: 0.9200 - tn: 8414.0000 - tp: 4027.0000 - val_accuracy: 0.8130 - val_auc: 0.9321 - val_categorical_accuracy: 0.8130 - val_f1_score: 0.7597 - val_fn: 46.0000 - val_fp: 46.0000 - val_loss: 0.6201 - val_precision: 0.8130 - val_recall: 0.8130 - val_tn: 446.0000 - val_tp: 200.0000\n",
      "Epoch 479/500\n",
      "3/3 - 0s - 166ms/step - accuracy: 0.9278 - auc: 0.9833 - categorical_accuracy: 0.9278 - f1_score: 0.9279 - fn: 322.0000 - fp: 313.0000 - loss: 0.2969 - precision: 0.9283 - recall: 0.9264 - tn: 8441.0000 - tp: 4055.0000 - val_accuracy: 0.7683 - val_auc: 0.9163 - val_categorical_accuracy: 0.7683 - val_f1_score: 0.7352 - val_fn: 58.0000 - val_fp: 57.0000 - val_loss: 0.6815 - val_precision: 0.7673 - val_recall: 0.7642 - val_tn: 435.0000 - val_tp: 188.0000\n",
      "Epoch 480/500\n",
      "3/3 - 0s - 161ms/step - accuracy: 0.9253 - auc: 0.9843 - categorical_accuracy: 0.9253 - f1_score: 0.9247 - fn: 330.0000 - fp: 323.0000 - loss: 0.2904 - precision: 0.9261 - recall: 0.9246 - tn: 8431.0000 - tp: 4047.0000 - val_accuracy: 0.8293 - val_auc: 0.9210 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7790 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.6467 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 481/500\n",
      "3/3 - 1s - 196ms/step - accuracy: 0.9244 - auc: 0.9828 - categorical_accuracy: 0.9244 - f1_score: 0.9246 - fn: 336.0000 - fp: 329.0000 - loss: 0.3017 - precision: 0.9247 - recall: 0.9232 - tn: 8425.0000 - tp: 4041.0000 - val_accuracy: 0.8415 - val_auc: 0.9289 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7902 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.6087 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n",
      "Epoch 482/500\n",
      "3/3 - 0s - 152ms/step - accuracy: 0.9292 - auc: 0.9849 - categorical_accuracy: 0.9292 - f1_score: 0.9296 - fn: 313.0000 - fp: 308.0000 - loss: 0.2858 - precision: 0.9296 - recall: 0.9285 - tn: 8446.0000 - tp: 4064.0000 - val_accuracy: 0.8293 - val_auc: 0.9257 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7802 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.6411 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 483/500\n",
      "3/3 - 1s - 264ms/step - accuracy: 0.9299 - auc: 0.9853 - categorical_accuracy: 0.9299 - f1_score: 0.9300 - fn: 312.0000 - fp: 302.0000 - loss: 0.2791 - precision: 0.9308 - recall: 0.9287 - tn: 8452.0000 - tp: 4065.0000 - val_accuracy: 0.8293 - val_auc: 0.9333 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7802 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.6172 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 484/500\n",
      "3/3 - 1s - 183ms/step - accuracy: 0.9285 - auc: 0.9855 - categorical_accuracy: 0.9285 - f1_score: 0.9287 - fn: 317.0000 - fp: 310.0000 - loss: 0.2775 - precision: 0.9291 - recall: 0.9276 - tn: 8444.0000 - tp: 4060.0000 - val_accuracy: 0.8293 - val_auc: 0.9314 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7777 - val_fn: 42.0000 - val_fp: 41.0000 - val_loss: 0.6181 - val_precision: 0.8327 - val_recall: 0.8293 - val_tn: 451.0000 - val_tp: 204.0000\n",
      "Epoch 485/500\n",
      "3/3 - 1s - 177ms/step - accuracy: 0.9308 - auc: 0.9849 - categorical_accuracy: 0.9308 - f1_score: 0.9307 - fn: 307.0000 - fp: 300.0000 - loss: 0.2736 - precision: 0.9314 - recall: 0.9299 - tn: 8454.0000 - tp: 4070.0000 - val_accuracy: 0.8293 - val_auc: 0.9267 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7800 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.6218 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 486/500\n",
      "3/3 - 0s - 147ms/step - accuracy: 0.9214 - auc: 0.9853 - categorical_accuracy: 0.9214 - f1_score: 0.9213 - fn: 346.0000 - fp: 341.0000 - loss: 0.2797 - precision: 0.9220 - recall: 0.9210 - tn: 8413.0000 - tp: 4031.0000 - val_accuracy: 0.8496 - val_auc: 0.9378 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7906 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5391 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 487/500\n",
      "3/3 - 0s - 133ms/step - accuracy: 0.9253 - auc: 0.9869 - categorical_accuracy: 0.9253 - f1_score: 0.9258 - fn: 330.0000 - fp: 323.0000 - loss: 0.2646 - precision: 0.9261 - recall: 0.9246 - tn: 8431.0000 - tp: 4047.0000 - val_accuracy: 0.8293 - val_auc: 0.9320 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7758 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.6353 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 488/500\n",
      "3/3 - 0s - 139ms/step - accuracy: 0.9248 - auc: 0.9855 - categorical_accuracy: 0.9248 - f1_score: 0.9248 - fn: 330.0000 - fp: 327.0000 - loss: 0.2684 - precision: 0.9252 - recall: 0.9246 - tn: 8427.0000 - tp: 4047.0000 - val_accuracy: 0.8333 - val_auc: 0.9290 - val_categorical_accuracy: 0.8333 - val_f1_score: 0.7668 - val_fn: 41.0000 - val_fp: 41.0000 - val_loss: 0.6797 - val_precision: 0.8333 - val_recall: 0.8333 - val_tn: 451.0000 - val_tp: 205.0000\n",
      "Epoch 489/500\n",
      "3/3 - 1s - 202ms/step - accuracy: 0.9203 - auc: 0.9835 - categorical_accuracy: 0.9203 - f1_score: 0.9205 - fn: 350.0000 - fp: 347.0000 - loss: 0.2786 - precision: 0.9207 - recall: 0.9200 - tn: 8407.0000 - tp: 4027.0000 - val_accuracy: 0.8252 - val_auc: 0.9329 - val_categorical_accuracy: 0.8252 - val_f1_score: 0.7775 - val_fn: 43.0000 - val_fp: 43.0000 - val_loss: 0.5649 - val_precision: 0.8252 - val_recall: 0.8252 - val_tn: 449.0000 - val_tp: 203.0000\n",
      "Epoch 490/500\n",
      "3/3 - 1s - 172ms/step - accuracy: 0.9271 - auc: 0.9865 - categorical_accuracy: 0.9271 - f1_score: 0.9270 - fn: 325.0000 - fp: 317.0000 - loss: 0.2582 - precision: 0.9274 - recall: 0.9257 - tn: 8437.0000 - tp: 4052.0000 - val_accuracy: 0.7967 - val_auc: 0.9167 - val_categorical_accuracy: 0.7967 - val_f1_score: 0.7547 - val_fn: 50.0000 - val_fp: 49.0000 - val_loss: 0.6493 - val_precision: 0.8000 - val_recall: 0.7967 - val_tn: 443.0000 - val_tp: 196.0000\n",
      "Epoch 491/500\n",
      "3/3 - 1s - 180ms/step - accuracy: 0.9241 - auc: 0.9854 - categorical_accuracy: 0.9241 - f1_score: 0.9239 - fn: 337.0000 - fp: 327.0000 - loss: 0.2619 - precision: 0.9251 - recall: 0.9230 - tn: 8427.0000 - tp: 4040.0000 - val_accuracy: 0.8496 - val_auc: 0.9331 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7983 - val_fn: 38.0000 - val_fp: 37.0000 - val_loss: 0.5909 - val_precision: 0.8490 - val_recall: 0.8455 - val_tn: 455.0000 - val_tp: 208.0000\n",
      "Epoch 492/500\n",
      "3/3 - 1s - 177ms/step - accuracy: 0.9285 - auc: 0.9861 - categorical_accuracy: 0.9285 - f1_score: 0.9287 - fn: 314.0000 - fp: 312.0000 - loss: 0.2524 - precision: 0.9287 - recall: 0.9283 - tn: 8442.0000 - tp: 4063.0000 - val_accuracy: 0.8374 - val_auc: 0.9294 - val_categorical_accuracy: 0.8374 - val_f1_score: 0.7860 - val_fn: 40.0000 - val_fp: 40.0000 - val_loss: 0.6184 - val_precision: 0.8374 - val_recall: 0.8374 - val_tn: 452.0000 - val_tp: 206.0000\n",
      "Epoch 493/500\n",
      "3/3 - 1s - 195ms/step - accuracy: 0.9285 - auc: 0.9856 - categorical_accuracy: 0.9285 - f1_score: 0.9288 - fn: 313.0000 - fp: 313.0000 - loss: 0.2578 - precision: 0.9285 - recall: 0.9285 - tn: 8441.0000 - tp: 4064.0000 - val_accuracy: 0.8049 - val_auc: 0.9179 - val_categorical_accuracy: 0.8049 - val_f1_score: 0.7581 - val_fn: 48.0000 - val_fp: 48.0000 - val_loss: 0.7081 - val_precision: 0.8049 - val_recall: 0.8049 - val_tn: 444.0000 - val_tp: 198.0000\n",
      "Epoch 494/500\n",
      "3/3 - 0s - 149ms/step - accuracy: 0.9214 - auc: 0.9844 - categorical_accuracy: 0.9214 - f1_score: 0.9213 - fn: 346.0000 - fp: 340.0000 - loss: 0.2671 - precision: 0.9222 - recall: 0.9210 - tn: 8414.0000 - tp: 4031.0000 - val_accuracy: 0.8293 - val_auc: 0.9312 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7816 - val_fn: 43.0000 - val_fp: 42.0000 - val_loss: 0.5806 - val_precision: 0.8286 - val_recall: 0.8252 - val_tn: 450.0000 - val_tp: 203.0000\n",
      "Epoch 495/500\n",
      "3/3 - 0s - 152ms/step - accuracy: 0.9287 - auc: 0.9854 - categorical_accuracy: 0.9287 - f1_score: 0.9292 - fn: 313.0000 - fp: 310.0000 - loss: 0.2539 - precision: 0.9291 - recall: 0.9285 - tn: 8444.0000 - tp: 4064.0000 - val_accuracy: 0.8293 - val_auc: 0.9323 - val_categorical_accuracy: 0.8293 - val_f1_score: 0.7801 - val_fn: 42.0000 - val_fp: 42.0000 - val_loss: 0.5724 - val_precision: 0.8293 - val_recall: 0.8293 - val_tn: 450.0000 - val_tp: 204.0000\n",
      "Epoch 496/500\n",
      "3/3 - 0s - 158ms/step - accuracy: 0.9278 - auc: 0.9860 - categorical_accuracy: 0.9278 - f1_score: 0.9281 - fn: 317.0000 - fp: 314.0000 - loss: 0.2492 - precision: 0.9282 - recall: 0.9276 - tn: 8440.0000 - tp: 4060.0000 - val_accuracy: 0.7927 - val_auc: 0.9104 - val_categorical_accuracy: 0.7927 - val_f1_score: 0.7473 - val_fn: 51.0000 - val_fp: 51.0000 - val_loss: 0.7568 - val_precision: 0.7927 - val_recall: 0.7927 - val_tn: 441.0000 - val_tp: 195.0000\n",
      "Epoch 497/500\n",
      "3/3 - 1s - 183ms/step - accuracy: 0.9269 - auc: 0.9851 - categorical_accuracy: 0.9269 - f1_score: 0.9268 - fn: 322.0000 - fp: 318.0000 - loss: 0.2559 - precision: 0.9273 - recall: 0.9264 - tn: 8436.0000 - tp: 4055.0000 - val_accuracy: 0.8455 - val_auc: 0.9333 - val_categorical_accuracy: 0.8455 - val_f1_score: 0.7975 - val_fn: 40.0000 - val_fp: 37.0000 - val_loss: 0.5876 - val_precision: 0.8477 - val_recall: 0.8374 - val_tn: 455.0000 - val_tp: 206.0000\n",
      "Epoch 498/500\n",
      "3/3 - 1s - 168ms/step - accuracy: 0.9253 - auc: 0.9856 - categorical_accuracy: 0.9253 - f1_score: 0.9257 - fn: 330.0000 - fp: 324.0000 - loss: 0.2521 - precision: 0.9259 - recall: 0.9246 - tn: 8430.0000 - tp: 4047.0000 - val_accuracy: 0.8496 - val_auc: 0.9362 - val_categorical_accuracy: 0.8496 - val_f1_score: 0.7989 - val_fn: 37.0000 - val_fp: 37.0000 - val_loss: 0.5417 - val_precision: 0.8496 - val_recall: 0.8496 - val_tn: 455.0000 - val_tp: 209.0000\n",
      "Epoch 499/500\n",
      "3/3 - 0s - 151ms/step - accuracy: 0.9294 - auc: 0.9857 - categorical_accuracy: 0.9294 - f1_score: 0.9296 - fn: 313.0000 - fp: 308.0000 - loss: 0.2515 - precision: 0.9296 - recall: 0.9285 - tn: 8446.0000 - tp: 4064.0000 - val_accuracy: 0.8171 - val_auc: 0.9284 - val_categorical_accuracy: 0.8171 - val_f1_score: 0.7708 - val_fn: 45.0000 - val_fp: 45.0000 - val_loss: 0.6131 - val_precision: 0.8171 - val_recall: 0.8171 - val_tn: 447.0000 - val_tp: 201.0000\n",
      "Epoch 500/500\n",
      "3/3 - 0s - 156ms/step - accuracy: 0.9253 - auc: 0.9859 - categorical_accuracy: 0.9253 - f1_score: 0.9250 - fn: 331.0000 - fp: 325.0000 - loss: 0.2530 - precision: 0.9256 - recall: 0.9244 - tn: 8429.0000 - tp: 4046.0000 - val_accuracy: 0.8415 - val_auc: 0.9347 - val_categorical_accuracy: 0.8415 - val_f1_score: 0.7872 - val_fn: 39.0000 - val_fp: 39.0000 - val_loss: 0.5927 - val_precision: 0.8415 - val_recall: 0.8415 - val_tn: 453.0000 - val_tp: 207.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x150f5e15d60>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    \"accuracy\",\n",
    "    \"categorical_accuracy\",\n",
    "    \"f1_score\",\n",
    "    \"auc\"\n",
    "]\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"categorical_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "\n",
    "model2.fit(\n",
    "    X_train,\n",
    "    y_train_encoded,\n",
    "    batch_size=2048,\n",
    "    epochs=500,\n",
    "    verbose=2,\n",
    "    validation_data=(X_test, y_test_encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n",
      "[1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 2 0 0 0 2 0 1 1 0 0 1 0 0 0 0 0 0 0 2 0 0 0\n",
      " 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 2 0 0 0\n",
      " 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 2 2 2 0 0 0 2 0 2 2 2 2 2 2 0\n",
      " 2 2 0 0 2 0 1 2 0 2 1 2 2 0 2 2 0 2 2 0 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions_baseline = model.predict(X_test, batch_size=2048)\n",
    "y_pred = np.argmax(test_predictions_baseline, axis=1)\n",
    "# baseline_results = model.evaluate(X_test, y_test,\n",
    "#                                   batch_size=2048, verbose=0)\n",
    "# for name, value in zip(model.metrics_names, baseline_results):\n",
    "#   print(name, ': ', value)\n",
    "# print()\n",
    "\n",
    "# plot_cm(test_labels, test_predictions_baseline)\n",
    "print(y_pred)\n",
    "cm = confusion_matrix(y_pred_labels, y_val_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Gerente', 'Especialista', 'Director'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882261529320353"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_pred_labels, y_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
